[
{
	"uri": "http://localhost:53502/db-course/transacties/acid/",
	"title": "ACID",
	"tags": [],
	"description": "",
	"content": "ACID is een acronym dat we gebruiken binnen databases dat een lijst van voorwaarden omschrijft waar dat database systeem aan moet voldoen. De regels van ACID worden over het algemeen geïmplementeerd door het concept van Transacties. ACID omschrijft vier principes:\nAtomicity Consistency Isolation Durability Atomicity Transacties bestaan vaak uit meerdere statements. Atomicity verwacht dus dat al deze statements als één geheel worden beschouwd. Ofwel faalt alles, ofwel slaagt alles. Zo wordt er nooit slechts een deel van de changes bewaard.\nHet gevolg hiervan is dat de staat van een transactie niet gezien kan worden door andere gebruikers. Stel we hebben een typische bankoverschrijving die €10 gaat overschrijven van de rekening van Alice naar de rekening van Bob.\nsequenceDiagram\rNote over Application,DB: BEGIN TRANSACTION\rDB--\u003eDB: Rekening van Alice: €100\rDB--\u003eDB: Rekening van Bob: €150\rApplication-\u003e\u003eDB: UPDATE Account SET Amount -= 10 WHERE Owner = 'Alice'\rDB--\u003eDB: Rekening van Alice: €100\rDB--\u003eDB: Rekening van Bob: €150\rApplication-\u003e\u003eDB: UPDATE Account SET Amount += 10 WHERE Owner = 'Bob'\rNote over Application,DB: COMMIT TRANSACTION\rDB--\u003eDB: Rekening van Alice: €90\rDB--\u003eDB: Rekening van Bob: €160\rConsistency Consistency zorgt ervoor dat een database altijd in een consistente staat moet blijven. Met andere woorden, er moet altijd voldaan worden aan de constraints die op de database gedefinieerd zijn. Dit kan een referentiële constraint zijn, als er een rij wordt verwijderd die nog gebruikt wordt in een andere tabel waar onderliggend een referentiële constraint op ligt.\nNeem bovenstaand voorbeeld waarbij Alice geld overschrijft naar de rekening van Bob. Maar nu wil ze €150 overschrijven. We hebben op de Account tabel een CHECK CONSTRAINT gedefinieerd dat de Amount altijd groter of gelijk aan 0 moet zijn. Wat gebeurt er dan?\nsequenceDiagram\rNote over Application,DB: BEGIN TRANSACTION\rDB--\u003eDB: Rekening van Alice: €100\rDB--\u003eDB: Rekening van Bob: €150\rApplication-\u003e\u003eDB: UPDATE Account SET Amount -= 150 WHERE Owner = 'Alice'\rrect rgb(194, 24, 7)\rDB--\u003eDB: Error: Amount should be \u003e= 0\rend\rNote over Application,DB: ROLLBACK TRANSACTION\rDB--\u003eDB: Rekening van Alice: €100\rDB--\u003eDB: Rekening van Bob: €150\rDe transactie wordt teruggedraaid. Er werd geen geld afgehaald van de rekening van Alice en Bob heeft ook geen geld gekregen. We zitten opnieuw in een geldige consistente staat.\nIsolation Als je een query of transactie uitvoert op een database, ga je zelden als enige gebruiker actief zijn. Er zullen wellicht andere transacties uitgevoerd worden terwijl jij de jouwe uitvoert. Om ervoor te zorgen dat deze geen invloed hebben op elkaar worden er locks gelegd op een set van data. Daar bovenop worden isolation levels gedefinieerd die bepalen wat andere gebruikers mogen zien en lezen van andere transacties.\nDit komt meer detail aan bod in een volgend hoofdstuk.\nDurability Als we een transactie afronden en hij wordt gecommit dan is die nog steeds committed ook in het geval van een crash of stroomonderbreking. Veel DBMS providers lossen dit op door data weg te schrijven in non-volatile memory en door gebruik te maken van een transaction log in de write-ahead logging strategy.\nWrite-ahead logging is een strategie waarbij alle wijzigingen die op de database worden uitgevoerd, eerst worden vastgelegd in een transaction log voordat ze daadwerkelijk worden toegepast op de database. Dit logboek bevat een gedetailleerde lijst van alle acties die zijn uitgevoerd, zoals INSERT, UPDATE, en DELETE statements.\n"
},
{
	"uri": "http://localhost:53502/db-course/sql/rdbms-basics/",
	"title": "Database Basics",
	"tags": [],
	"description": "",
	"content": "Een database is niet meer dan een verzameling van gegevens. Een DBMS (DataBase Management System) is de software waarmee databases beheerd of aangemaakt kunnen worden.\n1. Waarom een database gebruiken? Een database wordt ook maar gewoon opgeslagen op een file system. Dus waarom kan ik dan niet zelf files gebruiken om mijn data op te slaan?\nDatabases bieden een aantal key features:\nPerformant (index management) Betere integratie met andere applicaties Uniform DBMS voor bewerken of ophalen van data Concurrency ondersteuning Security \u0026amp; Privacy van data \u0026hellip; In het tweedejaarsvak Besturingssystemen en C leerde je dat IO manipulatie heel dure operaties zijn. Een erg groot bestand openen of een seek() operatie uitvoeren daarop, duizenden bestanden tegelijkertijd openen voor data access, \u0026hellip;\u0026mdash;allemaal voorbeelden van nadelen waar een database de oplossing kan bieden. Achterliggend werkt het DBMS systeem nog steeds met files, maar dat is supergeoptimaliseerd door bijvoorbeeld gebruik te maken van verschillende niveaus van caching, file chunking, gedistribueerde modellen, \u0026hellip; De theorie en implementatie van een DBMS gaan we niet behandelen in deze cursus: de focus ligt op het gebruik van bestaande systemen.\n2. Database Model De data die zich in een database bevindt wordt op een specifieke manier opgeslagen. De structuur waarop deze data bijgehouden wordt, noemen we het database model.\nEen database model bestaat uit meerdere data modellen. Een data model beschrijft één specifiek object.\nWe zien hetzeflde eigenlijk terug als we denken aan Java of Kotlin. We definiëren hoe een klasse eruit ziet. Bijvoorbeeld volgende klasse:\ndata class Book(val isbn: string, val title: string, val author: string, val price: double) public class Book { String isbn; String title; String author; double price; public Book(isbn, title, author, price) { this.isbn = isbn; this.title = title; this.author = author; this.price = price; } } Dit kunnen we ook in een database bepalen. Daar zou het data model van de tabel Book er bijvoorbeeld als volgt kunnen uitzien:\nclassDiagram\rclass Book{\risbn: NVARCHAR(50)\rtitle: NVARCHAR (500)\rauthor: NVARCHAR (500)\rprice: DECIMAL(10,4)\r}\rNet als we in code state kunnen hebben wanneer we onze klasses instantiëren:\nvar book = Book(\u0026#34;0765326353\u0026#34;, \u0026#34;The Way of Kings\u0026#34;, \u0026#34;Brandon Sanderson\u0026#34;, 24.99) var book = new Book(\u0026#34;0765326353\u0026#34;, \u0026#34;The Way of Kings\u0026#34;, \u0026#34;Brandon Sanderson\u0026#34;, 24.99); Zo kunnen we ook state hebben in onze database:\nisbn title author price 0765326353 The Way of Kings Brandon Sanderson 24.99 Elk data model kan een aantal properties bevatten, zoals bovenstaande isbn en title, waarbij een type moet gedefiniëerd worden, zoals bovenstaande NVARCHAR(x). Dit zijn datatype namen die specifiek zijn voor elk DBMS.\nIn de oefeningen gaan wij SQLite gebruiken: zie ook datatypes in SQLite. SQLite\u0026rsquo;s types zijn loosely typed, wat wil zeggen dat er geen verschil is tussen VARCHAR (MSSQL\u0026rsquo;s ASCII) en NVARCHAR (MSSQL\u0026rsquo;s Unicode, UTF-16). Intern worden beide types gemapped naar TEXT. Raadpleeg dus telkens de manual om te controleren welke DBMS welke types ondersteund, en wat deze precies betekenen! Een Java/Kotlin String mapt dus niet altijd 100% op een RDBMS teksttype.\nEen voorbeeld van een simpel database model voor de inventaris van een bibliotheek zou er ongeveer als volgt kunnen uitzien:\nclassDiagram\rBook \"0..*\" --\u003e \"1..*\" Genre\rBook \"1..*\" --\u003e \"1\" Author\rclass Author{\rid: INT\rname: NVARCHAR\rfirstName: NVARCHAR\r}\rclass Genre{\rid: INT\rdescription: NVARCHAR\r}\rclass Book{\risbn: NVARCHAR\rtitle: NVARCHAR\rauthor: INT\rprice: DECIMAL\rgenre: INT\r}\rMerk op dat we hier relaties gebruiken: de DBMS systemen die we eerst behandelen, SQL-varianten, zijn RDBMS systemen: relationele database management systemen. De author in Book is een nummer dat verwijst naar de id van Author in een ander model of tabel. Op deze manier is het mogelijk om, voor elke rij in Author, meerdere Book rijen aan te maken:\ndata class Author(val id: int, val name: string, val books: List\u0026lt;Book\u0026gt;) public class Author { private final int id; private final String name; private final List\u0026lt;Book\u0026gt; books; public Author(int id, int name) { this.id = id; this.name = name; this.books = new ArrayList\u0026lt;\u0026gt;(); } } "
},
{
	"uri": "http://localhost:53502/db-course/sql-ddl-dml/ddl/",
	"title": "DDL",
	"tags": [],
	"description": "",
	"content": "Data Defintion Language is de taal die we gebruiken om de structuur van onze database te veranderen. We kunnen hiermee tabellen aanmaken, wijzigen of verwijderen. Maar ook indexen, views, triggers of stored procedures worden hiermee aangemaakt.\nZowat elke RDBMS heeft tooling om DDL te doen via een handige interface, in plaats van dit zelf uit te schrijven. In de praktijk ga je waarschijnlijk met beiden in contact komen. We gaan DB Browser for SQLite gebruiken tijdens onze lessen.\nKijk naar de Chinook database en maak een schematische voorstelling van hoe deze database eruit ziet. Je kan hiervoor Mermaid gebruiken, of een eigen tool of pen en papier.\nTabellen aanmaken en wijzigen Met DDL definiëer je structuur in SQL. Met DML wijzig of manipuleer je de inhoud ervan. De Chinook database bevat natuurlijk reeds tabellen, maar alles begint met een CREATE TABLE statement. Je kan in SQLite Browser rechtsklikken op tabellen en Copy Create Statement kiezen om te reverse-engineeren hoe de tabellen aangemaakt werden.\nBijvoorbeeld, voor albums:\nCREATE TABLE \u0026#34;albums\u0026#34; ( [AlbumId] INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL, [Title] NVARCHAR(160) NOT NULL, [ArtistId] INTEGER NOT NULL, FOREIGN KEY ([ArtistId]) REFERENCES \u0026#34;artists\u0026#34; ([ArtistId]) ON DELETE NO ACTION ON UPDATE NO ACTION ) Rekening houdend met de vereenvoudigde datatypes van SQLite, zou je het zelf waarschijnlijk ongeveer zo schrijven:\nCREATE TABLE album ( AlbumId INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL, Title TEXT NOT NULL, ArtistId INTEGER NOT NULL, FOREIGN KEY ArtistId REFERENCES artists (ArtistId) ) De NO ACTION statements zijn nutteloos. Namen hoeven, afhankelijk van het dialect, al dan niet escaped als [naam] of \u0026quot;naam\u0026quot;. Merk ook op dat bovenstaande SQL zal falen als de tabel artists niet eerst gemaakt wordt, anders kan de DB geen foreign key constraint controle uitvoeren. Meerdere statements worden gebruikelijk gescheiden door puntkomma ;.\nMerk op dat in SQL DDL we keywords met HOOFDLETTER schrijven en tabel of kolomnamen met kleine letter.\nProbleem met je structuur? Geen probleem: DROP TABLE album. Als hier data in zit ben je die ook onherroepelijk kwijt! Kolom vergeten? Geen probleem: ALTER TABLE album ADD COLUMN blah TEXT. Kolom te veel? Geen probleem: ALTER TABLE album DROP COLUMN blah. Not null constraint vergeten? Geen probleem: ALTER TABLE album ALTER COLUMN blah NOT NULL. Oei, syntaxfoutje? SQLite ondersteunt geen alter in alter, andere vendors wel. Check constraint vergeten? Geen probleem: ALTER TABLE album ADD CONSTRAINT my_constraint CHECK(len(blah) \u0026gt; 9) Oei, syntaxfoutje? Zelfde probleem\u0026mdash;enkel op te lossen door DROP en re-create. De CREATE en DROP statements kunnen ook gebruikt worden\u0026mdash;afhankelijk van de compatibiliteit van je RDBMS\u0026mdash;om indexen, aliases, tablespaces, synoniemen, sequenties, \u0026hellip; aan te maken en te verwijderen.\nMaak twee nieuwe tabellen aan: een licenses tabel, die per album (en dus ook artiest) licenties en hun kostprijs opslaat, en een memorabelia tabel die merchandise voor artiesten bevat om te verkopen. Denk goed na over het gebruik van constraints. Voeg daarna met ALTER TABLE kolommen toe om het (variërend) BTW percentage voor beide tabellen te bewaren.\nViews aanmaken Een view is eigenlijk een specifieke query die we een vaste naam geven.\nAls ik een view wil maken van alle tracks van het Rock genre, dan doe ik dat als volgt:\nCREATE VIEW rock_tracks AS SELECT * FROM tracks WHERE GenreId = 1 Vanaf dit punt kan ik in een nieuwe query het volgende uitvoeren:\nSELECT * FROM rock_tracks Merk op dat we vaak geen idee hebben welke ID het genre Rock heeft:\nSELECT * FROM genres WHERE Name = \u0026#39;Rock\u0026#39; In plaats van de resultaten te limiteren op GenreId, kunnen we beide tabellen joinen:\nCREATE VIEW rock_tracks AS SELECT tracks.* FROM tracks INNER JOIN genres ON genres.GenreId = tracks.GenreId WHERE genres.Name = \u0026#39;Rock\u0026#39; Dit kan ook met behulp van een subquery. Zie ook: DDML - JOIN operator en verder, subqueries.\nSchrijf een view die de naam van elke track geeft, alsook de naam van het album en de artiest, gesorteerd op artiest, album en dan track.\n"
},
{
	"uri": "http://localhost:53502/db-course/sql/",
	"title": "RDBMS",
	"tags": [],
	"description": "",
	"content": "RDBMS Zie menu links.\n"
},
{
	"uri": "http://localhost:53502/db-course/sql/rdbms-components/",
	"title": "Database Componenten",
	"tags": [],
	"description": "",
	"content": "1. Three Layer Architecture Logical Layer De Logical Layer is waar we bepalen hoe onze data gestructureerd wordt. Hier bepalen we wat voor data we bijhouden, hoe die data eruitziet en hoe die zich gedraagt ten op zichte van onze andere datamodellen.\nEnkele voorbeelden hiervan zijn:\nEen BOEK mag door maximum 0 of 1 PERSONEN ontleend worden. Een PERSOON mag meerdere BOEKEN ontlenen. Een PERSOON is een subtype van een GEBRUIKER. Oefening Hoe zou een database model van een bibliotheek eruit zien? Teken zelf eens uit hoe dit gemodelleerd zou kunnen worden. Hoe houdt ik bij dat een boek uitgeleend werd? Wat als ik ook andere dingen wil uitlenen uit de bibliotheek, zoals DVD\u0026rsquo;s of eBooks? Internal Layer De Internal Layer houdt zich bezig met alle details over hoe de data bewaard wordt. Sommige van de concepten die hier aan bod komen zijn de volgenden:\nIndex management Constraint definities (uniek, referentieel, \u0026hellip;) Gepartitioneerde tabellen \u0026hellip; Deze technologieën hebben allemaal te maken met performantie of data integriteit. We willen onze data op een zo\u0026rsquo;n performante manier opslaan én nog belangrijker op een zo performante manier terug ophalen.\nIndexatie Data wordt ongestructureerd bijgehouden in een tabel. Een tabel is eigenlijk niet meer dan een ongesorteerde lijst van gegevens. Bij elke nieuw element wordt dat aan het eind van de lijst toegevoegd.\nWat als we nu uit een lijst van miljoenen boeken de verzamelde werken van Tolkien willen ophalen? In plaats van door de hele lijst één voor één te gaan zoeken, kunnen we gelukkig gebruik maken van indexen.\nEen index is een inhoudstafel die we bijhouden van een bepaald aantal velden van onze tabel. Stel we hebben een Book tabel met miljoenen rijen, waaronder de volgende:\nid isbn title author price 1345 0765326353 The Way of Kings Brandon Sanderson 24.99 6789 0395177111 The Hobbit J.R.R. Tolkien 24.99 3240 0812511816 The Eye of the World Robert Jordan 24.99 8939 0358439191 The Lord of the Rings J.R.R. Tolkien 24.99 1230 0143111582 Dune Frank Herbert 24.99 Als we een index zouden leggen op de author kolom dan zou die volgende informatie kunnen bevatten:\nauthor id Brandon Sanderson 1345 Frank Herbert 1230 J.R.R. Tolkien 6789 J.R.R. Tolkien 8939 Robert Jordan 3240 Een index houdt een mini-tabel bij van de velden die aan de index worden toegevoegd in combinatie met het identity1 veld. Deze tabel is wel gesorteerd op de velden uit de index, wat zoekopdrachten versnelt.\nConstraints We kunnen onze tabellen behoeden van corrupte data te bevatten door constraints te gebruiken. Het ISBN veld is bijvoorbeeld een uniek veld en mag nooit een waarde bevatten die al gekend is in onze database. Hiervoor kunnen we een unique constraint toevoegen. Bij data insertion gaat de database zelf nakijken of deze value al bestaat en zo ja wordt het toevoegen van de record geblokkeerd. Zo behouden we onze data integriteit.\nAndere voorbeelden van constraints kunnen zijn:\nDe prijs van een boek moet groter dan 0 zijn Een boek kan niet verwijderd worden als het ooit werd uitgeleend Het ISBN-13 nummer moet 13 karakters hebben Het ISBN nummer moet - een aantal keren bevatten Een naam veld mag niet NULL (niet ingevuld) zijn Een email veld moet @ bevatten \u0026hellip; Hoe constraints in de praktijk worden toegevoegd aan data modellen wordt behandeld in het hoofdstuk SQL DDL \u0026amp; DML. Zie ook SQLite table-constraint syntax.\nGepartitioneerde tabellen Sommige tabellen in productie omgevingen bevatten immense hoeveelheden aan data. We spreken over een grootorde van meerdere miljarden rijen. Hoe groter een tabel wordt, hoe trager het wordt om data op te halen. Het maakt niet uit hoeveel indexen we hebben gelegd, of welke SSD schijven we onderliggend op de fysieke storage hebben zitten. Meer data gaat altijd gelijk staan aan tragere data retrieval.\nOm tegen te gaan dat we tabellen krijgen die té groot worden en we daar niet meer zinvol data van kunnen ophalen bestaan hier een paar oplossingen voor. Het partitioneren van tabellen is er eentje van. Archivatie is een andere oplossing.\nNeem als voorbeeld een bank, die elke overschrijving van een rekening moet bewaren. De overschrijving tabel zou kunnen gepartitioneerd worden op jaar. Zodat er nog steeds 1 tabel overschrijving is, maar waarbij we die op de fysieke schijf opsplitsen per jaar, en elke op bijvoorbeeld de recentste 3 jaren index management voor bijhouden. De andere jaren kunnen nog steeds opgevraagd worden maar niet met dezelfde performantie als de meest recente data.\nExternal Layer De External Layer is wat we van onze database laten zien aan de buitenwereld. Dit zijn views van data. Een view is een virtuele representatie van data. We schrijven een query op onze tabellen en bewaren deze query als een view. Op deze manier kunnen we garanderen aan integrerende applicaties dat onze data er steeds hetzelfde gaat uitzien en tevens beschermen van informatie die voor het integrerende systeem niet relevant is.\nIn onze bibliotheek kunnen we een aantal views osptellen op basis van de noden van de verschillende applicaties. In het online platform waar je boeken kan uitlenen is het niet nodig de informatie over een auteur als een aparte entiteit weer te geven. We kunnen de tabel van Authors dus verbergen en enkel een view aanbieden op niveau van Books die er als volgt zou uitzien:\nclassDiagram\rclass LendingAppBooks{\risbn: NVARCHAR\rtitle: NVARCHAR\rauthor: NVARCHAR\rprice: DECIMAL\rgenre: NVARCHAR\r}\rVoor de inventaris applicatie moeten we wel in staat zijn om nieuwe boeken en auteurs toe te voegen. Daar kunnen de views er dan als volgt uitzien:\nclassDiagram\rInventoryBooks \"1..*\" --\u003e \"1\" InventoryAuthors\rclass InventoryAuthors{\rid: INT\rname: NVARCHAR\rfirstName: NVARCHAR\r}\rclass InventoryBooks{\risbn: NVARCHAR\rtitle: NVARCHAR\rauthor: INT\rprice: DECIMAL\r}\r2. Catalog Dit is het hart van de de database. Dit bevat alle metadata die zich in de database bevindt. Onder andere, de tabellen; views; stored procedures; \u0026hellip;\nDe SQL standaard om deze informatie in te bewaren is in INFORMATION_SCHEMA. Niet alle SQL Database providers voldoen hier echter aan. SQLite doet dit niet en daar vind je die informatie in de tabel sqlite_master.\n3. Database Languages SQL is onderverdeeld in twee verschillende talen. Enerzijds heb je DDL (Data Definition Language). Dit gebruik je om de database structuur te wijzigen. Nieuwe tabellen toevoegen, indexen aanmaken, views verwijderen, \u0026hellip;\nAnderzijds heb je DML (Data Manipulation Language). Dit gebruik je voor alle CRUD (Create, Read, Update, Delete) acties op data. Hier gaan we in een volgend hoofdstuk verder op in gaan.\nEigenlijk niet het Identity veld, maar het veld dat in de Clustered Index zit van de tabel. Als er dan in de query meer informatie nodig is om op te halen kan die via die manier de rest van de data ophalen.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
},
{
	"uri": "http://localhost:53502/db-course/sql-ddl-dml/dml/",
	"title": "DML",
	"tags": [],
	"description": "",
	"content": "Data Modification Language is de taal die we gebruiken om de data van onze database te bekijken of aan te passen. Met DML kunnen we CRUD operaties uitvoeren. Create, Read, Update en Delete.\nSELECT SELECT is het commando dat we gebruiken om data op te vragen uit de database.\nSELECT { DISTINCT } expression\rFROM table\r{ WHERE condition } LIKE operator LIKE wordt gebruikt om wildcard searches uit te voeren. Deze kan enkel gebruikt worden op alfanumerieke velden.\n% is een match anything character voor een onbeperkt aantal karakters (0 tot n). Zo matcht Gen% met volgende waardes: Gen, Genk, Gent, Genève, Genua, \u0026hellip;\n_ is een match anything character voor één karakter. Zo matcht Gen_ met volgende waardes: Genk, Gent, \u0026hellip; Maar niet met volgende waardes: Gen, Genève, Genua, \u0026hellip;\nNULL NULL is het ontbreken van een waarde. Het is een onbekende. We kunnen in DML niet zomaar vergelijken met NULL. We kunnen namelijk niet zeggen dat een onbekende gelijk is aan een andere onbekende.\nHieronder een overzicht van een binary AND table met True, False en NULL waardes.\nAND True False NULL True True False NULL False False False False NULL NULL False NULL Denkvraag: Waarom is False == NULL gelijk aan False?\nHieronder vinden we de binary OR table met True, False en NULL waardes.\nOR True False NULL True True True True False True False NULL NULL True NULL NULL Als we willen vergelijken met NULL in queries, dan gebruiken we volgende code:\n\u0026lt;value\u0026gt; IS NULL\nen\n\u0026lt;value\u0026gt; IS NOT NULL\nSchrijf een query die alle Customers (volledige naam, customer ID en land) laat zien die niet wonen in de USA. Schrijf een query die enkel de Customers laat zien die in Brazilië wonen. Schrijf een query die alle Employees laat zien die werken in de Sales afdeling. Schrijf een query die een unieke lijst van landen laat zien uit de Invoices tabel. Schrijf een query die alle Tracks laat zien waarvoor er geen componist bekend is. Schrijf een query van alle unieke Componisten. Als de componist niet bekend is, dan moet er \u0026lsquo;Onbekend\u0026rsquo; weergegeven worden gesorteerd op naam. Schrijf een query die het maximumbedrag van alle Invoices laat zien. JOIN Wanneer we informatie willen ophalen uit meerdere tabellen dan gebruiken we daar een JOIN statement voor. Die syntax ziet er als volgt uit:\nSELECT { DISTINCT } expression\rFROM table\rINNER JOIN other_table ON join_condition\r{ WHERE condition } Hiermee matchen we alle data van de ene tabel met de andere tabel op de meegegeven conditie. Er bestaan drie verschillende types JOINs:\nINNER JOIN - Geeft alle resultaten die bestaan zowel in de ene als de andere tabel LEFT JOIN - Geeft alle resultaten die bestaan in de base tabel, ook al bestaan die niet in de tabel waarop we joinen RIGHT JOIN - Wordt in de praktijk zelden tot nooit gebruikt. Geeft alle resultaten die bestaan in de gejoinde tabel ook al bestaan ze niet in de base tabel. Schrijf een query die alle Invoices laat zien van alle Customers uit Brazilië. Het resultaat moet de volledige naam van de Customer, Invoice ID, Invoice Datum en Billing Country weergeven. Schrijf een query die alle Invoices laat zien voor elke Sales Agent. Het resultaat moet de volledige naam van de Sales Agent weergeven. Schrijf een query die het Invoice Totaal, de Customer naam en land en de naam van de Sales Agent weergeeft voor alle Invoices en Customers. Schrijf een query die het aantal invoice lijnen weergeeft voor Invoice ID 37. Schrijf een query die de track naam weergeeft langs elke invoice lijn. Schrijf een query die de track naam en de artiest naam weergeeft langs elke invoice lijn. Schrijf een query die alle tracks laat zien, maar geen ID\u0026rsquo;s. Het resultaat moet de album titel, het media type en het genre bevatten. Schrijf een query die alle genres weergeeft waarvoor er geen tracks bestaan. GROUP BY Soms willen we data aggregeren. In Basic Engineering Skills in Python werd aggregratie gebruikt om bijvoorbeeld de som van een lijst te nemen, of met funtools.reduce() een custom functie los te laten op een lijst. (Dit gaan we ook nog zien in het hoofdstuk rond NoSQL \u0026ndash; Advanced map-reduce queries).\nIn RDBMS bestaan hiervoor een aantal verschillende functies. De meest courante zijn hieronder te vinden:\nMAX() MIN() COUNT() AVG() SUM() Elke waarde die je extra selecteert in een query bovenop een aggregate function, moet in een GROUP BY clause komen. Hoe ziet dit er dan bijvoorbeeld uit?\nSELECT BillingCity, SUM(Total) FROM Invoices GROUP BY BillingCity Zonder GROUP BY statement krijg je ofwel een fout ofwel maar één record terug, zoals in SQLite.\nHAVING Als we willen filteren op een grouping function, dan gaat dat niet via een WHERE clause, dan krijg je namelijk een foutmelding:\nSELECT BillingCity, count(*) FROM invoices WHERE count(*) \u0026gt; 2 GROUP BY BillingCity Om te filteren op een grouping function schrijven we dit in een HAVING clause die de query gebruikerlijks afsluit:\nSELECT BillingCity, count(*) FROM invoices GROUP BY BillingCity HAVING count(*) \u0026gt; 2 Schrijf een query die het aantal Invoices laat zien voor 2009 en 2011. Schrijf een query die het aantal invoices per land laat zien. Schrijf een query die per Invoice ID het aantal invoice lijnen laat zien. Schrijf een query die de naam van elke playlist laat zien, alsook het aantal tracks in elke playlist. Schrijf een query die alle data uit de Invoices tabel laat zien, aangevuld met het aantal invoice lijnen. Schrijf een query die de totale verkoopcijfers per Sales Agent laat zien. Schrijf een query die laat zien welke Sales Agent de grootste verkoopcijfers heeft voor 2009. Schrijf een query die laat zien welke Sales Agent de grootste verkoopcijfers heeft voor 2010. Schrijf een query die laat zien welke Sales Agent de grootste verkoopcijfers heeft over alle jaren heen. Schrijf een query die het aantal Customers laat zien per Sales Agent. Schrijf een query die de totale verkoopcijfers per land laat zien. In welk land werd er het meest uitgegeven? Schrijf een query die laat zien welke track er in 2013 het meest werd verkocht. Schrijf een query die laat zien wat de top 5 tracks zijn die ooit werden verkocht. Schrijf een query die laat zien wie de top 3 artiesten zijn die het meest verkocht werden. Schrijf een query die laat zien welk media type het meest verkocht werd. Schrijf een query die de tracks laat zien die meer dan 4 keer verkocht zijn. Subqueries Een query die we uitvoeren geeft een set van resultaten terug. Die set kunnen we opnieuw gebruiken als input voor een nieuwe query. We kunnen die set op verschillende plaatsen gebruiken als input voor een nieuwe query. Hieronder een aantal voorbeelden.\nIn een WHERE clause SELECT * FROM invoice_items WHERE invoice_items.TrackId IN ( SELECT tracks.TrackId FROM tracks WHERE name LIKE \u0026#39;%hell%\u0026#39; ) In een FROM clause SELECT * FROM ( SELECT tracks.TrackId, tracks.Name FROM tracks WHERE name LIKE \u0026#39;%hell%\u0026#39; ) In een JOIN clause SELECT * FROM tracks INNER JOIN ( SELECT tracks.TrackId, tracks.Name FROM tracks WHERE name LIKE \u0026#39;%hell%\u0026#39; ) hell_tracks ON hell_tracks.TrackId = tracks.TrackId Subqueries in een WHERE IN statement worden geëvauleerd voor elke voor elke rij uit de outer query, dus zijn eigenlijk niet zo heel performant. We kunnen dat iets verbeteren door dat te herschrijven naar een WHERE EXISTS statement. Zie hieronder.\nSELECT * FROM invoice_items WHERE EXISTS ( SELECT 1 FROM tracks WHERE name LIKE \u0026#39;%hell%\u0026#39; AND tracks.TrackId = invoice_items.TrackId ) De IN clause gaat een subquery volledig ophalen om alle rijen te hebben om dan in die lijst van rijen te kunnen zoeken. Een EXISTS clause gaat een subquery maar zo lang uitvoeren tot er een resultaat gevonden is. Als de tabel uit de subquery 1000 rijen bevat en er wordt een match gevonden op rij 200, dan gaan de andere 800 niet meer geëvauleerd worden.\nDe meeste van deze queries kunnen ook geschreven worden met een JOIN statement. Dit is echter niet waar we hier op willen oefenen. Los dus volgende oefeningen op met minstens één subquery. Als je hier moeite mee hebt kan her handig zijn om eerst een werkende query te bekomen met JOIN en die dan om te vormen naar een subquery.\nSchrijf een query die alle invoices laat zien die een track bevatten van Iron Maiden. Schrijf een query die alle invoices laat zien die verkocht werden door Margaret Park. Schrijf een query die alle genres laat zien waarvoor er geen track bestaat. Schrijf een query die alle invoices laat zien waarvan de prijs groter is dan het gemiddelde van alle invoices. Schrijf een query die alle invoices laat zien waarin een Metallica track verkocht is, waarvan de prijs groter is dan het gemiddelde van alle invoices waarin een Metallica track verkocht is. Data manipulatie INSERT Met een INSERT Statement gaan we data toevoegen in de database. We gebruiken een column listing om aan te geven welke kolommen, in welke volgorde, we van een waarde kan voorzien. Kolommen die NULL values ondersteunen mogen uit de column listing gelaten worden.\nINSERT INTO Genres(Name) VALUES(\u0026#39;Rock\u0026#39;) Voeg je favoriete album (inclusief artiest en tracks) toe aan de database.\nUPDATE Met een UPDATE statement kunnen we één of meerdere waardes in een set van data aanpassen.\nUPDATE Tracks SET MediaTypeId = 1 WHERE AlbumId = 2 Wijzig de UnitPrice en de Composer voor de 3e track van je toegevoegde album. Wijzig de titel van je favoriete album (zie oefening hierboven).\nDELETE Hiermee kunnen we een set van data verwijderen.\nLET OP! Een DELETE statement zonder WHERE clause verwijdert alles uit de tabel!\nDELETE FROM Genre WHERE Name = \u0026#39;Rock\u0026#39; Verwijder het album (inclusief artiest en tracks) dat je hierboven hebt toegevoegd.\nWat is volgens jou het verschil tussen DELETE FROM zonder WHERE en DROP TABLE?\n"
},
{
	"uri": "http://localhost:53502/db-course/sql-ddl-dml/",
	"title": "SQL DDL &amp; DML",
	"tags": [],
	"description": "",
	"content": "SQL DDL \u0026amp; DML Zie menu links.\n"
},
{
	"uri": "http://localhost:53502/db-course/transacties/basics/",
	"title": "Transaction Mgmt. Basics",
	"tags": [],
	"description": "",
	"content": "Moesten de database systemen voornamelijk single-user systemen zijn, dan was er geen probleem geweest want dan werden alle opdrachten gewoon sequentieel uitgevoerd. SQL Database Management Systems (DBMS) systemen zijn echter vooral multi-user systemen. Om zowel verschillende gebruikers te kunnen behandelen als nog steeds de ACID regels ondersteunen, is er een systeem nodig dat soms gebruikers \u0026ldquo;in wacht\u0026rdquo; zet. Stel je voor dat Jens en Jolien tegelijkertijd data lezen én updaten\u0026mdash;in dezelfde tabel, hetzelfde record. Jens leest uit \u0026ldquo;de rekening staat op 100 EUR\u0026rdquo; en Jolien haalt er 10 EUR vanaf. Wie mag eerst? Kan dit tegelijkertijd? Jens krijgt te horen dat er 100 EUR op de rekening staat, terwijl in werkelijkheid dit 10 EUR minder is.\nWaarom transacties? Heel simpel:\nLinks: het verkeer zonder transacties, rechts: met transacties\rOm Atomicity, Consistency, Isolation, Durability te garanderen is er dus een transactie manager nodig die alles in goede banen leidt op het moment dat verschillende gebruikers data gaan raadplegen en/of manipuleren. Dit principe is ruwweg hetzelfde als task management van het vak Besturingssystemen en C\u0026mdash;maar dan op database-applicatie niveau.\nWat is een transactie? Een transactie is een set van database operaties (bij relationele databases dus een aantal SQL operaties), dat door één gebruiker of applicatie als één unit of work aanzien wordt. Bijvoorbeeld, Jens wilt geld overschrijven van zijn rekening naar die van Jolien. Dit gaat meestal in verschillende stappen:\nHaal €10 van balans van Jens; Stort €10 op balans van Jolien. graph LR;\rJN[Rekening van Jens]\rJL[Rekening van Jolien]\rJN --\u003e|10 EUR| JL\rDit is één transactie\u0026mdash;het zou nooit mogen gebeuren dat er €10 verdwijnt van Jens\u0026rsquo; account zonder dat Jolien dat geld ontvangt. Met andere woorden, er kan niets tussen stap 1 en stap 2 komen: geen systeem crash, geen andere gebruiker (bijvoorbeeld Marianne die Jens €20 voor zijn verjaardag stort op de rekening). Dit is één \u0026ldquo;unit of work\u0026rdquo;: als er iets misloopt zou alles teruggedraaid moeten worden. Dus, een transactie heeft als resultaat ofwel success, ofwel failure, maar niets tussenin. Indien dit succesvol wordt afgerond zou het DBMS systeem moeten garanderen dat het geld effectief op Jolien\u0026rsquo;s rekening staat. Indien het faalde zou het DBMS systeem moeten garanderen dat Jens zijn geld niet kwijt is.\nIn de praktijk worden veel verschillende transacties tegelijkertijd uitgevoerd\u0026mdash;eventueel door verschillende gebruikers. Er moet dus iemand zijn die dit beheert, en dat is de transactie manager. Wie beslist of Jens eerst zijn geld mag afhalen, of dat Marianne eerst zijn verjaardagscadeau mag overmaken op de rekening? Wie beslist dat tussen stap 1 en 2 bij de transfer van het geld van Jens naar Jolien niemand mag tussenkomen? Juist: de transactie manager. Hier zijn verschillende strategieën voor, zoals we later zullen zien in Concurrency Control.\nHet beheren van transacties Formeel gezien wordt er een transactie afgelijnd door aan te kondigen wanneer een transactie begint en wanneer hij stopt, zodat de manager de juiste acties kan doorvoeren. De gebruiker kan met SQL ook zelf een transactie terugdraaien als er een programmafout voorkomt, bijvoorbeeld met een try { ... } catch(Exception ex) { rollback }. Meer hierover in sectie failures/rollbacks.\nDe transactie manager, die afgelijnde transacties ontvangt, kan dit dan in een schedule zetten, om te beslissen welke (delen van) transacties wanneer moeten worden uitgevoerd, net zoals Round Robin CPU scheduling algoritmes. Uiteindelijk wordt er een status toegekend aan een transactie:\nCommitted\u0026mdash;het is gelukt en de data is permanent gepersisteerd. Aborted\u0026mdash;Een error tijdens het uitvoeren van de transactie. Indien er halverwege de abort data is gewijzigd moet dit worden teruggezet, of worden rollbacked. Vorige versies van data moeten dus ook worden bijgehouden. Jens\u0026rsquo; rekening kan bijvoorbeeld €90 zijn initieel, hij haalt er €10 af om over te maken wat dit tot €80 maakt, maar er loopt iets mis: de rollback triggert het terugdraaien van het getal 80 naar de originele 90.\nDit is een pseudocode voorbeeld van bovenstaande afgelijnde transactie:\nBEGIN TRANSACTION;\rUPDATE account SET waarde = waarde - :over_te_maken_bedrag\rWHERE eigenaar = \u0026#39;Jens\u0026#39;\rUPDATE account SET waarde = waarde + :over_te_maken_bedrag\rWHERE eigenaar = \u0026#39;Jolien\u0026#39;\rCOMMIT; Transacties kosten CPU en RAM en zijn configureerbaar maar dus gelimiteerd in aantal. De manager kan worden ingesteld tot bijvoorbeeld ondersteunen van maximum 10 transacties tegelijkertijd.\nDBMS Componenten bij een transactie Een voorbeeld van een transactie workflow (de nummers komen overeen met het schema):\nDBMS componenten aan het werk tijdens een transactie. src: pdbmbook.com\rDe manager waarschuwt de scheduler dat er een nieuwe transactie moet worden ingepland. Deze optimaliseert dit naar throughput (zie BESC); De recovery en stored data manager worden op de hoogte gebracht. Deze optimaliseert disk access: het zou kunnen dat DB reads/writes via een buffer verlopen omdat fysieke file operaties duur zijn; De scheduler is nu klaar om input te ontvangen en uit te voeren in de juiste volgorde; Dit triggert mogelijks interactie met de stored data manager (het effectief wegschrijven van wijzigingen); De uitkomst wordt doorgegevan via een output area: ofwel is het gelukt (5b), ofwel is het mislukt (5a), waardoor de recovery manager zijn werk moet doen om dingen terug te draaien. State transition diagram illustrating the states for transaction execution.\rBEGIN_TRANSACTION: Dit markeert het begin van de uitvoering van een transactie. READ of WRITE: Deze commando\u0026rsquo;s specificeren lees- of schrijfoperaties op de database-items die worden uitgevoerd als onderdeel van een transactie. END_TRANSACTION: Dit specificeert dat de lees- en schrijfoperaties van de transactie zijn beëindigd en markeert het einde van de uitvoering van de transactie. Op dit punt kan het nodig zijn om te controleren of de wijzigingen die door de transactie zijn geïntroduceerd permanent kunnen worden toegepast op de database (gecommit) of dat de transactie moet worden afgebroken vanwege schending van serialiseerbaarheid of om een andere reden. COMMIT_TRANSACTION: Dit signaleert een succesvol einde van de transactie, zodat alle wijzigingen (updates) die door de transactie zijn uitgevoerd veilig kunnen worden gecommit naar de database en niet ongedaan zullen worden gemaakt. Wat als er iet misgaat? Hoe werkt dat blokje \u0026ldquo;recovery manager\u0026rdquo; precies? Een DBMS systeem gebruikt achterliggend een logfile als belangrijk element om eventuele recoveries te kunnen doorvoeren. Een logfile bevat in principe redundante data: in het beste geval wordt dit nooit gebruikt. Maar in het geval dat er ook maar iets misloopt is het van groot belang dat de log entries kunnen worden gebruikt om de data terug te zetten.\nVoor elke transactie EN operatie wordt relevante informatie geregistreerd in de logfile als een log record. Deze bevat de volgende informatie:\nEen unieke Log ID; Een unieke Transactie identifier om de records te kunnen koppelen aan de transacties; Een markering voor de start van de transactie + tijd + type (read/write/read-write combo) aan te duiden; Database record identifiers en operaties (select/insert/\u0026hellip;.) die bij de transactie horen; before images: een snapshot van de data voordat de transactie werd doorgevoerd. Deze worden gebruikt om een undo uit te voeren; after images: een snapshot van de data nadat de transactie werd doorgevoerd. Deze worden gebruikt om een redo uit te voeren, moest bijvoorbeeld een fysieke file write mislukken en hier een retry op worden toegepast. Er wordt altijd eerst in de logfile geschreven: dit noemen we een write-ahead log strategy. Op die manier is de DBMS manager voorbereid op een mogelijke rollback. Alle updates worden dus eerst naar de logfile geschreven voordat er iets fysiek veranderd op de harde schijf. Merk op dat de \u0026ldquo;logFILE\u0026rdquo; ook (gedeeltelijk) in-memory kan zijn.\nWat kan er zoal misgaan? Failures worden in drie groepen opgedeeld:\nTransaction failures: fouten in de logica van de transactie, zoals verkeerde input, incorrecte variabelen, statements die niet kloppen, etc. Sommige applicaties vangen dit al op voordat het naar de DBMS gaat. System failures: DB of OS crashes op de server, bijvoorbeeld door stroomonderbrekingen of bugs in de database zelf. Het zou kunnen dat de DBMS buffer inhoud hierdoor leeg raakt en delen van data niet teruggezet kunnen worden. Media failures: Storage access fouten door bijvoorbeeld disk crashes, een storing in het netwerk, etc. Het zou kunnen dat de logfile niet toegankelijk is. Hoe werkt de write-ahead logging nu precies (WAL) Logging: Wanneer een transactie wordt gestart, worden alle bewerkingen eerst naar het transaction log geschreven. Dit logboek bevindt zich in non-volatile memory, zodat de gegevens veilig zijn. Commit: Zodra alle bewerkingen succesvol zijn uitgevoerd, wordt de transactie \u0026ldquo;gecommit\u0026rdquo; en worden de wijzigingen permanent toegepast op de database. Recovery: Als er een systeemfout optreedt, kan het DBMS het transaction log gebruiken om de database te herstellen naar een consistente staat. Het systeem voert de acties uit het logboek opnieuw uit om de database terug te brengen naar de laatste bekende goede staat. Stel je voor dat je een transactie hebt die een nieuwe bestelling toevoegt aan een e-commerce database. De stappen zouden als volgt zijn:\nLoggen van acties: INSERT INTO orders (order_id, customer_id, order_date) VALUES (1, 123, \u0026#39;2025-03-10\u0026#39;); UPDATE inventory SET stock = stock - 1 WHERE product_id = 456; INSERT INTO order_items (order_id, product_id, quantity) VALUES (1, 456, 1); Commit: Zodra alle acties zijn gelogd en succesvol uitgevoerd, wordt de transactie gecommit. Recovery: Als er een systeemcrash optreedt, gebruikt het DBMS het transaction log om de database te herstellen door de gelogde acties opnieuw uit te voeren, REDO. (Als een systeemcrash optreedt voordat de commit is geschreven, wordt de transactie als niet voltooid beschouwd en worden alle wijzigingen teruggedraaid tijdens het herstelproces. UNDO) Kortom, door de combinatie van write‐ahead logging, het gebruik van commitmarkers en het toepassen van zorgvuldig ontworpen herstelprocedures (die rekening houden met de exacte volgorde en status van logrecords), zorgt een DBMS ervoor dat acties niet dubbel worden uitgevoerd en dat gedeeltelijk uitgevoerde transacties volledig worden teruggedraaid.\nSystem Recovery Veronderstel dat er 5 transacties door de DBMS worden verwerkt. Tc duidt een checkpoint aan van de data in de buffer manager van de afbeelding hierboven. Er treedt een systeemfout op rechts bij Tf:\nUNDO/REDO operaties voor 5 \u0026#39;kapotte\u0026#39; transacties. src: pdbmbook.com\rWe bekijken de 5 transacties afzonderlijk:\nT1\u0026mdash;Aangezien deze succesvol werd gecommit voor de systeemfout én voor de snapshot Tc, hoeft hier niets voor te gebeuren na een crash. T2\u0026mdash;Deze transactie is ook compleet voor Tf, maar er zit nog data in de buffer van de snapshot Tc die niet naar disk geschreven werd. Hier is dus een REDO nodig. T3\u0026mdash;Deze transactie was nog bezig bij de crash van Tf. We hebben niet alle data in de buffer: er is dus transactie data verloren gegaan: een UNDO dus. T4\u0026mdash;Deze transactie is gelukt maar alle data is nog steeds pending to disk (bij T2 was dit een deel): REDO. T5\u0026mdash;De DBMS scheduler had deze net ingepland toen het systeem crashte. Het is niet nodig om hier is van terug te draaien omdat er niks pending was (na de Tc checkpoint). Meer info hier, maar is enkel ter info en moet niet in detail gekend zijn\nMedia Recovery Wat doe jij als er een harde schijf gerashed is van je computer? Bidden voor een werkende backup? Indien fysieke files niet meer toegankelijk zijn is een \u0026ldquo;media recovery\u0026rdquo; afhankelijk van data redundancy principes. Hopelijk heb je een backup strategie voorzien. Voor database systemen wordt dit streng toegepast en moeten we een recovery doorvoeren via een mirror op een andere HDD in RAID, op een cloud backup, een offline backup, \u0026hellip;\nOm de failover time te minimaliseren wordt dit vaak automatisch opgezet. Een harde schijf kan in een server in RAID-1 modus geplaatst worden: die functioneert als 100% clone van de andere. Indien er één van beide HDDs faalt, neemt onmiddellijk de andere het werk over, zodat gebruikers zo goed als geen last hebben van de media failure. Systemen als backup copies door iets te \u0026ldquo;archiveren\u0026rdquo; (een .tar.gz of .zip op bepaalde tijdstippen aan de kant zetten) vereist meestal meer werk om terug te zetten. Backups nemen betekent ook beslissen of het een full of incremental backup zal zijn, waarbij je (1) alle files apart zet, of (2) enkel de wijzigingen ten opzichte van vorige snapshots (denk aan git bijvoorbeeld).\nEen goede backup strategie\u0026mdash;dit geldt zowel voor databases als voor je eigen data!!\u0026mdash;volgt het 1-2-3 backup principe:\nZorg voor minstens drie backups van je data, waarvan twee lokaal maar op verschillende media (bvb, verschillende servers, op HDD en op USB, \u0026hellip;), en één off-site kopie, zoals cloud-based backup systemen als Dropbox, Google Drive, Backblaze\u0026rsquo;s Cloud Storage. En dan hebben we het nog niet over security gehad\u0026hellip;\nDenkvragen Waarom kan je niet gewoon media recovery strategieën toepassen bij systeemcrashes? Waarom wel, maar is dat misschien geen goed idee?\nSolution:\nMedia recovery strategieën (zoals herstel vanuit back-ups) zijn primair bedoeld voor fysieke schade aan opslagmedia. Bij een systeemcrash gaat het erom de consistente staat van de database snel te herstellen, wat met media recovery vaak te traag en omslachtig is. Bovendien kan een dergelijk herstel risico’s met zich meebrengen, zoals het herstellen van een oude, mogelijk inconsistente staat. In principe kan media recovery ingezet worden als laatste redmiddel. Echter, vanwege de langere hersteltijd en de kans op inconsistente data (bijvoorbeeld als sommige transacties al deels uitgevoerd waren) is het in de praktijk verstandiger om gespecialiseerde crash recovery technieken (zoals log-gebaseerde UNDO/REDO mechanismen) te gebruiken. Als er verschillende transacties tegelijkertijd aan één record iets wijzigen, welke problemen zie jij dan zoal? Hoe zou je dat door de transaction manager laten oplossen? Kan je zo twee verschillende oplossingen bedenken?\nSolution:\nEén transactie overschrijft de wijzigingen van een andere, waardoor data verloren gaat.\nEen transactie leest onvoltooide (nog niet gecommitte) data van een andere transactie.\nHerhaalde leesoperaties geven verschillende resultaten, wat leidt tot inconsistenties.\nEen record vergrendelen zodra een transactie eraan werkt. Andere transacties moeten wachten tot de vergrendeling wordt opgeheven, waardoor conflicten worden voorkomen.\nTransacties voeren wijzigingen uit zonder directe vergrendeling. Bij het committen controleert het systeem of er tussentijds wijzigingen hebben plaatsgevonden. Als er een conflict wordt gedetecteerd, wordt de transactie teruggedraaid.\nWat is alweer het verschil tussen UNDO en REDO recovery technieken?\nSolution:\nUNDO: Wordt gebruikt om de effecten van transacties die niet succesvol zijn afgerond of die foutief zijn uitgevoerd, ongedaan te maken. Dit zorgt ervoor dat de database terugkeert naar een consistente staat. REDO: Wordt toegepast om de wijzigingen van transacties die wel gecommit waren opnieuw toe te passen. Dit is vooral belangrijk na een crash wanneer sommige wijzigingen nog niet permanent op de schijf waren vastgelegd. Als ier iets misgaat op applicatieniveau, bijvoorbeeld een crash in je Java applicatie, moet de DBMS dan iets doen, of moet de programmeur dan iets doen, om ACID te blijven garanderen?\nSolution:\nHet DBMS is primair verantwoordelijk voor het waarborgen van ACID-eigenschappen via zijn transactie- en recoverymechanismen. Bij een crash op applicatieniveau (bijvoorbeeld in een Java-applicatie) zorgt het DBMS er met behulp van commit/rollback en log-based recovery voor dat de database in een consistente staat blijft. De programmeur moet wel zorgen voor een correcte afhandeling van transacties in de applicatie, zoals het op de juiste wijze starten, committen en, indien nodig, terugdraaien van transacties. Wat zou er volgens jou moeten gebeuren als twee personen tegelijkertijd op bol.com een item bestellen waarvan maar één hoeveelheid in stock is? Wie trekt hier aan het korte eind? Hoe vangen grote webwinkels dit probleem op?\nSolution:\nHet voorraadbeheersysteem (onderdeel van het DBMS of een gekoppeld systeem) moet atomische transacties gebruiken. Dit zorgt ervoor dat slechts één transactie succesvol het laatste item kan reserveren, terwijl de andere transactie een foutmelding krijgt of wordt teruggedraaid. "
},
{
	"uri": "http://localhost:53502/db-course/sql/rdbms-acid/",
	"title": "ACID",
	"tags": [],
	"description": "",
	"content": "ACID is een acronym die we gebruiken binnen databases dat een lijst van voorwaarden omschrijft waar dat database systeem aan moet voldoen. De regels van ACID worden over het algemeen geïmplementeerd door het concept van Transacties. ACID omschrijft vier principes:\nAtomicity Consistency Isolation Durability De ACID principes komen in de praktijk nog verder aan bod in het hoofdstuk over RDBMS transacties, dus geen paniek als onderstaande theorie nog niet onmiddellijk duidelijk is.\nAtomicity Transacties bestaan vaak uit meerdere statements. Atomicity verwacht dat al deze statements als één geheel worden beschouwd. Ofwel faalt alles, ofwel slaagt alles. Zo wordt er nooit slechts een deel van de changes bewaard.\nHet gevolg hiervan is dat de staat van een transactie niet gezien kan worden door andere gebruikers. Stel we hebben een typische bankoverschrijving die €10 gaat overschrijven van de rekening van Alice naar de rekening van Bob.\nsequenceDiagram\rNote over Application,DB: BEGIN TRANSACTION\rDB--\u003eDB: Rekening van Alice: €100\rDB--\u003eDB: Rekening van Bob: €150\rApplication-\u003e\u003eDB: UPDATE Account SET Amount -= 10 WHERE Owner = 'Alice'\rDB--\u003eDB: Rekening van Alice: €100\rDB--\u003eDB: Rekening van Bob: €150\rApplication-\u003e\u003eDB: UPDATE Account SET Amount += 10 WHERE Owner = 'Bob'\rNote over Application,DB: COMMIT TRANSACTION\rDB--\u003eDB: Rekening van Alice: €90\rDB--\u003eDB: Rekening van Bob: €160\rConsistency Consistency zorgt ervoor dat een database altijd in een consistente staat moet blijven. Met andere woorden, er moet altijd voldaan worden aan de constraints die op de database gedfinieerd zijn. Dit kan een referentiële constraint zijn, als er een rij wordt verwijderd die nog gebruikt wordt in een andere tabel waar onderliggend een referentiële constraint op ligt.\nNeem bovenstaand voorbeeld waarbij Alice geld overschrijft naar de rekening van Bob. Maar nu wil ze €150 overschrijven. We hebben op de Account tabel een CHECK CONSTRAINT gedefinieerd dat de Amount altijd groter of gelijk aan 0 moet zijn. Wat gebeurt er dan?\nsequenceDiagram\rNote over Application,DB: BEGIN TRANSACTION\rDB--\u003eDB: Rekening van Alice: €100\rDB--\u003eDB: Rekening van Bob: €150\rApplication-\u003e\u003eDB: UPDATE Account SET Amount -= 150 WHERE Owner = 'Alice'\rrect rgb(194, 24, 7)\rDB--\u003eDB: Error: Amount should be \u003e= 0\rend\rNote over Application,DB: ROLLBACK TRANSACTION\rDB--\u003eDB: Rekening van Alice: €100\rDB--\u003eDB: Rekening van Bob: €150\rDe transactie wordt teruggedraaid. Er werd geen geld afgehaald van de rekening van Alice en Bob heeft ook geen geld gekregen. We zitten opnieuw in een geldige consistente staat.\nIsolation Als je een query of transactie uitvoert op een database, ga je zelden als enige gebruiker actief zijn. Er zullen wellicht andere transacties uitgevoerd worden terwijl jij de jouwe uitvoert. Om ervoor te zorgen dat deze geen invloed hebben op elkaar worden er locks gelegd op een set van data. Daar bovenop worden isolation levels gedefinieerd die bepalen wat andere gebruikers mogen zien en lezen van andere transacties.\nDit komt meer detail aan bod in een volgend hoofdstuk.\nDurability Als we een transactie afronden en hij wordt gecommit dan is die nog steeds committed ook in het geval van een crash of stroomonderbreking. Veel DBMS providers lossen dit op door data weg te schrijven in non-volatile memory en door gebruik te maken van een transaction log.\nDat laatste is een logboek van alle acties die uitgevoerd werden op een database, die opnieuw uitgevoerd kunnen worden als een database gerestored moet worden vanaf een eerdere staat.\n"
},
{
	"uri": "http://localhost:53502/db-course/transacties/concurrency-control/",
	"title": "Concurrency Control",
	"tags": [],
	"description": "",
	"content": "De transactie management scheduler (zie transacties - basics) is verantwoordelijk om verschillende transacties correct in te plannen zonder dat er data problemen of clashes optreden.\nProblemen? Welke problemen? Denk terug aan het bank transfer probleem van de vorige sectie. Veronderstel dat deze keer zowel Jens als Marianne €10 willen overmaken naar Jolien. Als we dat als volgt doen:\nLees het huidige bedrag op de source rekening Verminder bedrag van source rekening Lees het huidige bedrag op de destination rekening Verhoog bedrag van destination rekening Dan zou het kunnen dat bij het uitlezen van #3, Jolien\u0026rsquo;s rekening bij de transactie van Marianne al €110 uitleest omdat Jens zijn verhoging al is doorgekomen. Maar net dan canceled de transactie van Jens en wordt de rekening van Jolien en van Jens (terecht) terug op de vorige waarde ingesteld (dus €100 voor Jolien). De transactie van Marjanne check nie nog eens het startbedrag en werkt dus nog altijd onder de veronderstelling dat er €10 bij €110 moet worden opgeteld en is op het einde het eindtotaal van Jolien toch €120 en Jens heeft geen geld verloren. Oeps!\ngraph LR;\rJN[Rekening van Jens]\rJL[Rekening van Jolien]\rML[Rekening van Marianne]\rJN --\u003e|10 EUR| JL\rML --\u003e|10 EUR| JL\rHieronder volgen een aantal veel voorkomende concurrency problemen die de transaction scheduler uitdagen.\nDirty Read Dit is exact bovenstaande situatie. Een dirty read probleem is het lezen van uncommited \u0026ldquo;dirty\u0026rdquo; data\u0026mdash;data die eigenlijk voor de andere transactie nog niet zichtbaar mag zijn omdat het hier over uncommitted data gaat. Als Marianne\u0026rsquo;s read(bedrag) toch het juiste bedrag zou inlezen (110), voordat Jens\u0026rsquo; transactie compleet is, maar op een of andere manier is die transactie teruggedraaid, dan spreken we over een dirty read, en krijgt Jolien onterecht toch €20, terwijl Jens zijn €10 mag houden. It prints money!\ntime T1 (Marianne) T2 (Jens) bedrag 1 begin trans 100 2 read(bedrag): 100 100 3 bedrag = bedrag + 10 100 4 begin trans write(bedrag) 110 5 read(bedrag): 110 110 6 bedrag = bedrag + 10 ROLLBACK! 120 (oeps) 7 write(bedrag) 120 8 commit 120 Lost Updates Stel je nu voor dat bij het uitlezen, tijdens het verhogen van het bedrag op de destination rekening, Jolien\u0026rsquo;s rekening op €100 staat. Maar als de transactie van Marianne dit ook leest als €100, en niet wacht tot de €110 die het zou moeten zijn na de commit van de transactie van Jens, dan gaat in totaal Marianne slechts €10 rijker zijn in plaats van twee keer dat bedrag. Weer een oepsie!\nHet UPDATE statement van Jens\u0026rsquo; transactie (verhoog Jolien\u0026rsquo;s rekening met 10) is eigenlijk \u0026ldquo;verloren\u0026rdquo; gegaan, omdat Marianne hier tussen komt, en haar UPDATE die terug ongedaan maakt:\ntime T1 (Marianne) T2 (Jens) bedrag 1 begin trans 100 2 begin trans read(bedrag): 100 100 3 read(bedrag): 100 bedrag = bedrag + 10 100 4 bedrag = bedrag + 10 write(bedrag) 110 5 write(bedrag) commit 110 (oeps) 6 commit 110 Dit voorbeeld illustreert dat, alhoewel beide transacties 100% correct zijn, er toch nog problemen kunnen optreden als transacties elkaar gaan storen. Het spreekt voor zich dat als T1 data zou lezen en schrijven uit een andere rij of tabel, dit geen probleem zou zijn\u0026mdash;in dit specifieke voorbeeld.\nEen lost update is dus een fout in een databasesysteem die optreedt wanneer twee of meer transacties tegelijkertijd eenzelfde record wijzigen, maar één van de wijzigingen onbedoeld wordt overschreven. Hierdoor gaat de update van één transactie \u0026ldquo;lost\u0026rdquo; of verloren, waardoor het eindresultaat niet alle beoogde wijzigingen bevat.\nNon-repeatable reads Er zijn nog verschillende andere mogelijkheden waarbij de scheduler de bal kan misslaan. Bijvoorbeeld door non-repeateable reads, dit doet zich voor wanneer een transactie dezelfde data meerdere keren leest en daarbij verschillende resultaten ontvangt, doordat een andere transactie in de tussentijd de data heeft gewijzigd en gecommit.\nAls we naar het voorbeeld van Jolien kijken. Stel dat ze een verslag wil uittrekken van haar jaaroverzicht en ze wil het totale bedrag op haar rekening en de interest (2%) die ze krijgt op haar totale bedrag, samen met nog andere statistieken. Stel nu dat ze haar totale bedrag van €120 krijgt te zien als totale bedrag, maar net voordat de interest berekend wordt wordt er een andere transactie uitgevoerd die €20 wegneemt van haar totale bedrag. Dan krijgt Jolien een verslag waar op staat: Totale bedrag = €120, interest = €2. Wees maar zeker dat Jolien een kwade email zal sturen!\nHet probleem hier is dat alles wat voor het verslag opgehaald moet worden consistent moet blijven voor dat hele verslag, er mogen tegelijk dus geen andere transacties updates doorvoeren.\ntime T1 (Verslag maken) T2 (20 euro wegnemen) bedrag 1 begin trans 120 2 read(bedrag): 120 [om totaal bedrag te weten] begin trans 120 3 \u0026hellip; bedrag = bedrag - 10 120 4 \u0026hellip; write(bedrag) 100 5 read(bedrag): 100 [om interest te berekenen, oeps] commit 100 6 commit 100 Phantom read Of wat dacht je van phantom reads: dit treedt op wanneer een transactie herhaaldelijk dezelfde query uitvoert en bij de tweede uitvoering extra records ziet (of juist records mist) die door een andere transactie zijn toegevoegd of verwijderd en al gecommit. Bijvoorbeeld: transactie T2 is bezig met rijen effectief te verwijderen, terwijl T1 deze toch nog inleest. Het zou kunnen dat hierdoor verschillende rijen ontstaan (T2 rollback, T1 die een nieuwe rij maakt), of dat voorgaande bestaande rijen verdwijnen door T2, waardoor de transactie van T1 mogelijks faalt.\nWeer teruggrijpende naar ons Jolien voorbeeld, stel dat Jens Jolien €5 wilt betalen per klusje dat ze gedaan heeft. Klusjes worden opgeslagen in een aparte tabel, maar ondertussen kan Jolien een nieuw klusje afvinken, waardoor Jens\u0026rsquo; transactie een phantom read krijgt:\ntime T1 (Jens) T2 (Jolien) klusjes 1 read 1: SELECT * FROM klusjes WHERE naam = 'Jolien' (2) 2 2 \u0026hellip; 2 3 \u0026hellip; INSERT INTO klusjes ... 3 4 \u0026hellip; 3 5 read 2: SELECT * FROM klusjes WHERE naam = 'Jolien' (3, oeps) 3 6 sort 3x5 op rekening (teveel) 3 7 commit Bijgevolg verkrijgt T1 inconsistente data: de ene keer 2, de andere keer 3\u0026mdash;vergeet niet dat het goed zou kunnen dat T2 nog teruggedraaid wordt.\nWat is het verschil tussen een non-repeatable read, een phantom read, en een dirty read? Dirty reads lezen foutieve uncommitted data van een andere transactie\u0026mdash;het lezen van \u0026lsquo;in progress\u0026rsquo; data. Non-repeateable reads en phantom reads lezen foutieve committed data van een andere transactie. Bij non-repeatable reads gaat het over UPDATEs, en bij phantom reads over INSERTs en/of DELETEs: rijen die plots verschijnen of zijn verdwenen sinds de transactie begon.\nMeerdere fouten tegelijk Bijvoorbeeld bij inconsistente analyse tussen twee transacties gaat het over een sequentie van verschillende dirty reads die de situatie alleen maar verergeren, zelfs zonder de eventuele rollback. Stel dat het over te schrijven bedrag in stukjes van €2 wordt overgeschreven, waarbij telkens tussenin een read(bedrag) plaats vindt\u0026mdash;die natuurlijk de data van de andere transactie inleest. Het resultaat is, opnieuw, een veel te grote som, en een mogelijks erg blije Jolien.\nWe laten een schematische voorstelling van dit probleem als oefening voor de student.\nScheduler oplossingen Wat is de simpelste manier om bovenstaande problemen allemaal integraal te vermijden? Juist ja\u0026mdash;sequentieel transacties verwerken.\nSerial scheduling Met serial scheduling is T2 verplicht te wachten op T1 totdat die zijn zaakje op orde heeft. De lost update transactie flow van hierboven ziet er dan als volgt uit:\ntime T1 (Marianne) T2 (Jens) bedrag 1 begin trans 100 2 read(bedrag): 100 100 3 bedrag = bedrag + 10 100 4 write(bedrag) 110 5 commit 110 6 begin trans 110 7 read(bedrag): 110 110 8 bedrag = bedrag + 10 120 9 write(bedrag) 120 10 commit 120 Wat valt je op als je naar de time kolom kijkt? Serial scheduling duurt nu 10 ticks t.o.v. 6 bij de potentiële lost update\u0026mdash;da\u0026rsquo;s een redelijk grote performance hit van 40%! Serial scheduling lost misschien wel alles op, maar daardoor verliezen we alle kracht van het woord parallel: dit is in essentie non-concurrency.\nWat zijn dan betere scheduling alternatieven?\nOptimistic scheduling Bij \u0026ldquo;optimistic\u0026rdquo; scheduling gaan we ervan uit dat conflicten tussen simultane transacties nauwelijks voorkomen. Met andere woorden, we benaderen het probleem (misschien te) optimistisch. Transacties mogen gerust tegelijkertijd lopen als ze bijvoorbeeld verschillende tabellen of stukken data in dezelfde tabel bewerken\u0026mdash;zolang er geen conflict is, geniet paralellisatie de voorkeur.\nBij optimistische schedulers worden alle transactie operaties doorgevoerd. Wanneer deze klaar zijn voor een eventuele COMMIT, wordt er gecontroleerd op potentiële conflicten. Indien geen, success. Indien wel, abort en ROLLBACK.\nMerk op dat rollback operaties erg dure operaties zijn: de manager moet graven in de logfile, moet beslissen of er UNDO/REDO operaties moeten worden uitgevoerd, er is mogelijke trage disc access (I/O), \u0026hellip; Als je vaak rollbacks hebt/verwacht is optimistic scheduling nog steeds geen performant alternatief.\nPessimistic scheduling Bij \u0026ldquo;pessimistic\u0026rdquo; scheduling gaan we van het omgekeerde uit: transacties gaan heel zeker conflicteren. De scheduler probeert transactie executies te verlaten om dit zo veel mogelijk te vermijden. Een serial scheduler is een extreem geval van een pessimistic scheduler.\nLocking In de praktijk wordt locking gebruikt op een pre-emptive manier (zie besturingssystemen: scheduling algorithms) om toch transacties waar mogelijk concurrent te laten doorlopen. Bij transacties die schrijven in plaats van die enkel lezen zullen locks eerder nodig zijn. Er bestaan uiteraard erg veel verschillende locking technieken/algoritmes.\nWe maken onderscheid tussen twee groepen:\nexclusive locks: als T1 een exclusieve lock neemt, kan er geen enkele andere transactie op die database worden uitgevoerd. Dit is een erg strict systeem, denk aan serial scheduling. shared locks: zolang T1 een lock neemt op een object (zie onder), krijgt het de garantie dat geen enkele andere transactie dat object kan manipuleren totdat de lock terug wordt vrijgegeven (eventueel ook door middel van een rollback). Locks worden \u0026ldquo;gedeeld\u0026rdquo;: T1 krijgt write access, en T2 moet wachten met schrijven, maar mag wel lezen. De database \u0026ldquo;objecten\u0026rdquo; waar een lock op genomen kan worden zijn onder andere (van kleine locks naar groot):\nrow locks; column locks; page locks (delen van een tabel zoals stored in files); table locks; databas locks (bvb een file lock in SQLite); Volgorde hierboven gaat ongeveer van minder wachttijd (1) naar meer wachttijd (2)\nEen lock op één rij in beslag genomen door T1 betekent dat voor diezelfde tabel T2 nog steeds bedragen kunnen wijzigen van een andere rekening. Column locks kunnen tot meer wachttijd leiden. Page locks zijn \u0026ldquo;stukken\u0026rdquo; van een tabel (rijen voor x en erna). Een page is een chunk van een tabel die op die manier wordt opgeslaan. Dit verschilt van DB implementatie tot implementatie. Tenslotte kan een hele tabel gelockt worden\u0026mdash;of de hele tablespace\u0026mdash;wat meer pessimistisch dan optimistisch is.\nLocks zijn onderhevig aan dezelfde nadelen als rollbacks: ze zijn duur. Als er erg veel row locks zijn op een bepaalde tabel kan dit veel CPU/RAM in beslag nemen. In dat geval kan de lock manager beslissen om aan lock escalation te doen: de 100 row locks worden één page of table lock. Dit vermindert resource gebruik drastisch\u0026mdash;maar zou transacties ook langer kunnen laten wachten. You win some, you lose some\u0026hellip;\nProblemen bij oplossen van problemen: deadlocks Stel dat Jens cash geld wilt deponeren, en Marianne hem ook geld wenst over te schrijven. Voordat Marianne dat doet koopt ze eerst nog een cinema ticket. Jens wil ook een ticket in dezelfde transactie. Het gevolg is dat T1 en T2 oneindig op elkaar blijven wachten. Dat ziet er zo uit:\ngraph LR;\rC{Cinema tabel}\rR{Rekening tabel}\rJ[Jens]\rM[Marianne]\rJ --\u003e|deposit 10| R\rM --\u003e|transfer 10| R\rM --\u003e|koop ticket| C\rJ --\u003e|koop ticket| C\rDe kruisende pijlen duiden al op een conflict:\ntime T1 (Jens) T2 (Marianne) 1 begin tarns 2 begin tarns 3 update rekening (acquire lock R) 4 update cinema (acquire lock C) 5 poging tot update cinema (WACHT) 6 poging tot update rekening (WACHT) Deze (simpele) deadlock kan gelukkig gedetecteerd worden door het DBMS systeem. Die zal één van beide transacties als \u0026ldquo;slachtoffer\u0026rdquo; kiezen en die transactie terugdraaien\u0026mdash;meestal gebaseerd op welke het makkelijkste is om terug te draaien. Het probleem is dat de meeste applicaties niet onmiddellijk voorzien zijn op zo\u0026rsquo;n onverwachte rollback. Dit resulteert meestal in een negatieve gebruikerservaring.\nDeadlocks en algoritmes om dit te detecteren en op te lossen zijn erg complexe materie. Het volstaat om bovenstaand eenvoudig voorbeeld te kennen, en te weten hoe dat aangepakt zou kunnen worden\u0026mdash;bijvoorbeeld met:\nstarvation: een transactie voortdurend als slachtoffer kiezen met als risico dat deze nooit de kans krijgt om succesvol af te ronden. In dit geval wordt de transactie steeds teruggedraaid terwijl andere transacties wel kunnen doorgaan, wat resulteert in oneerlijke behandeling en voortdurende vertraging van de starvende transactie. timeouts: een mechanisme om vastgelopen transacties op te sporen en af te breken. Wanneer een transactie langer dan een vooraf ingestelde tijd op een resource wacht, wordt deze afgebroken (rollback) om te voorkomen dat de deadlock het systeem blijft blokkeren. priority shift: een strategie waarbij de prioriteit van een transactie dynamisch wordt aangepast om deadlocks te helpen voorkomen of op te lossen. In plaats van dat een transactie telkens wordt gekozen als slachtoffer en teruggedraaid (wat kan leiden tot starvation), wordt de prioriteit verhoogd zodat deze transactie eerder de benodigde resources krijgt om haar bewerkingen af te ronden. Dit mechanisme zorgt ervoor dat starvende transacties uiteindelijk kunnen doorstromen en dat het systeem efficiënter functioneert bij het oplossen van conflicten. Deze concepten komen ook terug in schedulers voor besturingssystemen en zie ook A beginners guide to DB deadlocks.\nIsolation levels Pessimistic locking kan veel problemen opvangen, maar ten koste van performantie\u0026mdash;wat meestal belangrijker is. Voor veel transacties is het oké om met een minimum aan conflicten de throughput van transacties zo hoog mogelijk te houden. De meeste DBMS systemen zijn hier flexibel in: je kan wat we noemen isolation levels instellen, dat meestal bestaat uit de volgende vier opties (van low naar high isolation):\nRead uncommited\u0026mdash;Dit laat toe om \u0026ldquo;uncommited\u0026rdquo; data te lezen (dat problemen geeft, zie boven), en wordt meestal gebruikt in combinatie met read-only transacties. Read committed\u0026mdash;Gebruikt short-term read locks en long-term write locks, en lost zo het inconsistent analysis/lost update probleem op, maar is niet krachtig genoeg om phantom reads tegen te houden. Repeatable read\u0026mdash;Gebruikt long-term read \u0026amp; write locks. Een transactie kan zo dezelfde rij verschillende keren opnieuw lezen zonder conflicten van insert/updates van andere transacties. Het phantom read probleem is echter nog steeds niet opgelost. Serializable\u0026mdash;het krachtigste isolation level dat in theorie aansluit met serial scheduling. Een short-term lock wordt enkel vastgehouden gedurende het interval dat nodig is om een operatie af te ronden, terwijl long-term locks een protocol volgen en meestal tot de transactie commited/rollbacked is, vastgelegd zijn.\nVolgende tabel geeft een overzicht over wat elk Isolation level weer juist doet en welke read phenomena dit voorkomt. In de tabel gaat de snelheid omlaag hoe lager je gaat, maar stijgt wel de veiligheid!\nIsolation level\rDirty reads\rLost updates\rNon-repeatable reads\rPhantoms\rRead Uncommitted\nNo Isolation, any change from the outside is visible to the transaction\rmay occur\rmay occur\rmay occur\rmay occur\rRead Committed\nEach query in a transaction only sees committed stuff\rdon't occur\rmay occur\rmay occur\rmay occur\rRepeatable Read\nEach query in a transaction only sees committed updates at the beginning of transaction\rdon't occur\rdon't occur\rdon't occur\rmay occur\rSerializable\nTransactions are serialized\rdon't occur\rdon't occur\rdon't occur\rdon't occur\rMerk op dat voor elke database implementatie de selectie van een isolation level andere gevolgen kan hebben! Zie de tabellen in https://github.com/changemyminds/Transaction-Isolation-Level-Issue. Het is dus van belang de documentatie van je DB te raadplegen, zoals deze van Oracle, waarin de volgende beschrijving staat voor TRANSACTION_SERIALIZABLE: \u0026ldquo;Dirty reads, non-repeatable reads and phantom reads are prevented.\u0026rdquo;.\nWe komen hier nog later op terug in concurrency in practice wanneer we bijvoorbeeld bij JPA of Hibernate aangeven welk isolation level gewenst is.\nPessimistic Scheduling VS Isolation Levels:- Pessimistic Scheduling is een concrete strategie waarbij resources proactief worden vergrendeld om conflicten te vermijden.- Isolation Levels bepalen via configuratie-instellingen in welke mate transacties elkaars wijzigingen mogen zien en welke anomalieën geaccepteerd worden.\nOefeningen Geef voor onderstaande situaties welk read phenomena optreed. Geef ook twee mogelijke oplossingen waarmee je dit probleem kan oplossen en hoe die twee oplossingen van elkaar verschillen.\nOefening 1: In deze oefening wordt door transactie TX2 de quantity van product 1 aangepast van 10 naar 15 en transactie TX1 wil enerzijds de inkomsten berekenen op elk product apart maar ook in het totaal. Solution:\nread phenomena = Non-repeatable read. De quantity van product 1 wordt door eenzelfde transactie twee keer uitgelezen maar krijgt hier 2 verschillende waarden voor. oplossing: Twee mogelijke oplossingen hiervoor zijn de Repeatable Read en Serializable isolation levels. Bij Repeatable Read wordt ervoor gezorgd dat als een transactie een rij leest, geen andere transactie die rij kan wijzigen totdat de eerste transactie is voltooid. Dit voorkomt dat de waarde verandert tussen opeenvolgende leesoperaties binnen dezelfde transactie. Bij Serializable wordt een nog striktere controle toegepast, waarbij transacties volledig geïsoleerd worden uitgevoerd alsof ze sequentieel plaatsvinden, wat niet alleen non-repeatable reads voorkomt, maar ook andere problemen zoals phantom reads. Het belangrijkste verschil is dat Serializable een hogere mate van isolatie biedt, wat leidt tot betere gegevensintegriteit, maar mogelijk ook tot lagere prestaties door verhoogde kans op blocking en wachttijden. Oefening 2: In deze oefening wordt door transactie TX2 een product toegevoegd aan de SALES tabel en transactie TX1 wil enerzijds de inkomsten berekenen op elk product apart maar ook in het totaal.\nSolution:\nread phenomena = Phantom read. Het aantal producten waarvan de inkomsten worden berekend apart wordt uitgevoerd en daarna wordt de totaal inkomsten berekend op alle producten maar hiertussen is een extra product toegevoegd waardoor de waarden nu niet meer overeenkomen wat zou moeten aangezien de aparte inkomsten en totale inkomsten in 1 transactie berekend werden. (Waarom gebruik je nu niet gewoon de eerder berekende inkomsten om de totale inkomsten te berekenen. Als je aparte functies in je applicatie hebt geschreven om de aparte inkomsten en totale inkomsten queries uit te voeren zou dit voor meer werk zorgen als je nog een 3e functie moet schrijven die de totale inkomsten berekend op basis van de aparte queries. Dit is zot en moet het DBMS voor ons oplossen en moeten wij ons zo weinig mogelijk mee bezig houden bij het schrijven van onze applicatie: scheiding van verantwoordelijkheden) oplossing: Twee mogelijke oplossingen hiervoor zijn het gebruik van het Serializable isolatieniveau en het toepassen van range locks: Bij Serializable wordt strikte controle toegepast, waarbij transacties volledig geïsoleerd worden uitgevoerd alsof ze sequentieel plaatsvinden, wat non-repeatable reads voorkomt. Range locks daarentegen vergrendelen expliciet een specifiek bereik van rijen (bijv. WHERE id \u0026gt; 100), waardoor concurrente transacties worden geblokkeerd om binnen dat bereik in te voegen of te wijzigen, maar dit vereist handmatige implementatie en kan deadlocks bevorderen als niet nauwkeurig afgestemd. Het verschil ligt in de automatische vs. handmatige scope-beheersing en de balans tussen databasebrede consistentie (Serializable) versus gerichte controle (range locks) met bijbehorende prestatieafwegingen zoals throughput (het minste met Serializable). Oefening 3: In deze oefening wordt door transactie TX2 de quantity van product 1 aangepast van 10 naar 15 en transactie TX1 wil enerzijds de inkomsten berekenen op elk product apart maar ook in het totaal.\nSolution:\nread phenomena = Dirty read. De quantity van product 1 wordt geupdate tijdens transactie 1 maar is nog niet gecommit. De berekening van de totale inkomsten kan dus fout zijn in het geval dat TX2 wordt gererolled. oplossing: Twee mogelijke oplossingen hiervoor zijn de Read Committed en Repeatable Read isolation levels. Bij Read Committed worden dirty reads voorkomen door alleen gelezen data toe te staan die al is gecommit, wat automatisch werkt en transacties beperkt tot het lezen van stabiele gegevens, maar geen bescherming biedt tegen non-repeatable reads of phantom reads. Bij Repeatable Read wordt ervoor gezorgd dat als een transactie een rij leest, geen andere transactie die rij kan wijzigen totdat de eerste transactie is voltooid. Dit voorkomt dat een waarde wordt uitgelezen van een andere transactie die misschien gerollebacked wordt, aangezien die transactie moet wachten tot de eerste klaar is. Het belangrijkste verschil is dat Repeatable Read een hogere mate van isolatie biedt, wat leidt tot betere gegevensintegriteit, maar mogelijk ook tot lagere prestaties door verhoogde kans op blocking en wachttijden. Denkvragen Waarom is het phantom read probleem niet opgelost bij isolation level 3 (repeatable read)?\nSolution:\nHoewel het voorkomt dat rijen worden gewijzigd of verwijderd, staat het nog steeds toe dat nieuwe rijen worden toegevoegd die voldoen aan de zoekcriteria van een query. Als gevolg hiervan kan een transactie die herhaaldelijk een query uitvoert, verschillende resultaten zien vanwege toegevoegde rijen tussen de verschillende uitvoeringen van de query. Dit is het \u0026ldquo;phantom read\u0026rdquo; probleem. Hoe weet je wanneer je best optimistic vs pessimistic scheduling gebruikt?\nSolution:\nStart optimistisch door te vertrouwen op lage conflicten en minimale locks, maar als je merkt dat er frequent errors (zoals rollbacks of conflicten) optreden die de prestatie of data-integriteit schaden, schakel dan over naar een pessimistische aanpak door vooraf locks te plaatsen om concurrentie te beheersen en betere voorspelbaarheid te garanderen. Deze verschuiving is logisch bij schrijf-zware workloads of kritieke systemen waar preventie van conflicten prioriteit heeft boven flexibiliteit. Is het cruciaal voor je programma echter dat data-integriteit niet geschaad mag worden dan kies je best initieel al voor een pessimistische aanpak. Kan je nog andere situaties verzinnen waarin een deadlock kan voorkomen? Welk isolation level of scheduling algoritme lost dit op?\nSolution:\nStel, twee banktransacties gebeuren tegelijk: Transactie A wil €100 van rekening X naar Y overmaken (vergrendelt eerst X, dan Y). Transactie B wil €50 van Y naar X overmaken (vergrendelt eerst Y, dan X). Als beide transacties hun eerste lock hebben maar wachten op de tweede, ontstaat een deadlock: beide kunnen niet verder. Om deadlocks op te lossen, kunnen verschillende isolation levels en scheduling-algoritmen worden gebruikt zoals \u0026ldquo;Serializable\u0026rdquo;. Dit kan deadlocks helpen voorkomen door transacties te dwingen in een serialiseerbare volgorde te worden uitgevoerd, waarbij conflicten worden voorkomen en de kans op deadlocks wordt verminderd. Het nadeel is natuurlijk performantie. Algemeen: Deadlocks los je op met preventie (voorkom inconsistente lock-volgordes via isolation levels) of detectie (forceer een rollback op basis van time-outs). Wat is de verantwoordelijkheid van de DBMS\u0026rsquo;s transactie management systeem in verhouding tot de ACID eigenschappen?\nSolution:\nDoor het implementeren van transactiemanagementfunctionaliteiten zoals concurrency control, logging en herstelmechanismen, zorgt het systeem ervoor dat transacties consistent, geïsoleerd en duurzaam worden uitgevoerd, waardoor de betrouwbaarheid en integriteit van de database worden gewaarborgd. Atomicity en Durability: Transaction logs, herstelprocedures na crashes. Isolation: Pessimistische locks (bijv. SELECT FOR UPDATE), Isolation levels. (Consistency: Constraints (UNIQUE, FOREIGN KEY), triggers.) Welke impact heeft lock granulariteit op transactie throughput?\nSolution:\nThroughput is afhankelijk van het type fouten dat je gaat tegenkomen VS de isolation levels die rollbacks preventen maar ook wel traag kunnen zijn. Je moet dus steeds proberen de beste keuze te maken voor jouw specifieke geval. Bedenk en teken zelf een situatie waar een Lost Update voorkomt.\n"
},
{
	"uri": "http://localhost:53502/db-course/transacties/",
	"title": "RDBMS Transacties",
	"tags": [],
	"description": "",
	"content": "Transaction management Zie menu links.\n"
},
{
	"uri": "http://localhost:53502/db-course/apis/",
	"title": "Database APIs",
	"tags": [],
	"description": "",
	"content": "Casus: Tornooisysteem Tennis Tennis Vlaanderen organiseert tennistornooien over heel Vlaanderen. Deze casus werkt een voorbeeld uit van een soort systeembeheer voor die tornooien. Wat dat systeembeheer software pakket juist moet kunnen staat hieronder beschreven. (Dit is natuurlijk maar een beperkte versie van hoe zo een werkelijk systeem er zou uitzien bv. een datum en uur voor de wedstrijden ontbreken \u0026hellip;)\nMet de software moet je tennisspelers kunnen aanmaken. Elke tennisspeler heeft een globale ID bij Tennis Vlaanderen die gebruikt wordt als identifier wanneer een persoon zich inschrijft voor een toernooi. Een speler moet op zijn Tennis Vlaanderen-dashboard een globaal overzicht kunnen opvragen van het aantal gespeelde matchen, het aantal gewonnen matchen, verloren matchen en de hoogst bereikte plaats in een toernooi (bv. Finalist T.C.Ham reeks enkel Heren t.e.m. 5 punten OF Winnaar G.T.Tessenderlo reeks enkel Dames t.e.m. 10 punten).\nNaast de fysieke parameters van een tennisspeler zoals leeftijd, geslacht, \u0026hellip;, moet de applicatie ook de ranking van elke tennisspeler bijhouden. Deze ranking is een waarde van 1 tot en met 10 waarbij 1 de laagste ranking is en 10 de hoogste.\nDaarnaast kan een tennisspeler ook een rol als wedstrijdleider en/of scheidsrechter opnemen.\nEen wedstrijdleider regelt de planning van het toernooi, is het aanspreekpunt voor vragen en doet op de wedstrijddagen de inschrijvingen van de spelers. Aan elk toernooi moet minstens één wedstrijdleider gekoppeld zijn. Aan elke finalewedstrijd van een toernooi (= halve finales en grote + kleine finale) moet één scheidsrechter toegewezen worden. Een wedstrijdleider en scheidsrechter moeten ook wel een tennisspeler zijn! Je kan niet wedstrijdleider en scheidsrechter tegelijk zijn\nElk toernooi vindt plaats op een bepaalde Tennisclub (met een bepaald adres, telefoonnummer(s), email adres, \u0026hellip;) en bestaat uit minstens 4 reeksen waarvoor je kan inschrijven (\u0026ldquo;Enkel Heren t.e.m. 5 punten\u0026rdquo;, \u0026ldquo;enkel Heren t.e.m. 10 punten\u0026rdquo;, \u0026ldquo;enkel Dames t.e.m. 5 punten\u0026rdquo;, \u0026ldquo;enkel Dames t.e.m. 10 punten\u0026rdquo;). Een speler kan altijd voor een hogere reeks inschrijven maar niet voor een lagere (bv. speler met 3 punten kan inschrijven in de reeks t.e.m. 10 punten, maar een speler met 6 punten kan niet inschrijven voor de reeks t.e.m. 5 punten).\nEen toernooi wordt georganiseerd volgens het principe van rechtstreekse uitschakeling: de winnaar gaat door naar de volgende ronde (ronde wil zeggen: ronde 4 is 1/4 finale, ronde 16 is 1/16 finale en ronde 1 is finale \u0026hellip;); voor de verliezer eindigt het toernooi. Dit proces loopt door tot er per wedstrijdreeks één winnaar overblijft. Indien het aantal spelers in een wedstrijdreeks geen match van twee is, worden in de eerste ronde zoveel spelers vrijgesteld als nodig. Zij kwalificeren zich rechtstreeks voor de tweede ronde. Dit wordt per loting bepaald (random dus).\nEER-schema (My)SQL database Klik hier om de mysql code te zien/verbergen om de schema's aan te maken voor de 'tennisvlaanderen' database 🔽\rDROP TABLE IF EXISTS tennisspeler_speelt_wedstrijd; DROP TABLE IF EXISTS tennisspeler_inschrijving_wedstrijdreeks; DROP TABLE IF EXISTS wedstrijd; DROP TABLE IF EXISTS wedstrijdreeks; DROP TABLE IF EXISTS tornooi; DROP TABLE IF EXISTS tennisspeler; DROP TABLE IF EXISTS tennisclub_email; DROP TABLE IF EXISTS tennisclub; CREATE TABLE tennisclub ( clubnummer INT PRIMARY KEY, nummer INT, straatnaam VARCHAR(255), gemeente VARCHAR(255) ); CREATE TABLE tennisclub_email ( id INT AUTO_INCREMENT PRIMARY KEY, clubnummer INT, email_address VARCHAR(255), FOREIGN KEY (clubnummer) REFERENCES tennisclub(clubnummer) ); CREATE TABLE tennisspeler ( tennisvlaanderenid INT AUTO_INCREMENT PRIMARY KEY, geslacht ENUM(\u0026#39;M\u0026#39;, \u0026#39;V\u0026#39;), geboortedatum DATE, ranking INT, rol ENUM(\u0026#39;Wedstrijdleider\u0026#39;, \u0026#39;Scheidsrechter\u0026#39;) DEFAULT NULL, diploma TEXT, naam TEXT, CHECK (ranking BETWEEN 0 AND 10) ); CREATE TABLE tornooi ( id INT AUTO_INCREMENT PRIMARY KEY, startdatum DATE, einddatum DATE, wedstrijdleider INT, tennisclub INT, FOREIGN KEY (wedstrijdleider) REFERENCES tennisspeler(tennisvlaanderenid), FOREIGN KEY (tennisclub) REFERENCES tennisclub(clubnummer) ); CREATE TABLE wedstrijdreeks ( id INT AUTO_INCREMENT PRIMARY KEY, max_punten INT, geslacht ENUM(\u0026#39;M\u0026#39;, \u0026#39;V\u0026#39;), tornooi_id INT, FOREIGN KEY (tornooi_id) REFERENCES tornooi(id), CHECK (max_punten BETWEEN 0 AND 10) ); CREATE TABLE wedstrijd ( partial_id INT, wedstrijdreeks INT, scheidsrechter INT DEFAULT NULL, ronde INT, winnaar INT DEFAULT NULL, score TEXT DEFAULT NULL, PRIMARY KEY (partial_id, wedstrijdreeks), FOREIGN KEY (wedstrijdreeks) REFERENCES wedstrijdreeks(id), FOREIGN KEY (scheidsrechter) REFERENCES tennisspeler(tennisvlaanderenid), FOREIGN KEY (winnaar) REFERENCES tennisspeler(tennisvlaanderenid) ); CREATE TABLE tennisspeler_inschrijving_wedstrijdreeks ( id INT AUTO_INCREMENT PRIMARY KEY, tennisspeler INT, wedstrijdreeks INT, inschrijvingsdatum DATE, FOREIGN KEY (tennisspeler) REFERENCES tennisspeler(tennisvlaanderenid), FOREIGN KEY (wedstrijdreeks) REFERENCES wedstrijdreeks(id) ); CREATE TABLE tennisspeler_speelt_wedstrijd ( id INT AUTO_INCREMENT PRIMARY KEY, speler1 INT, speler2 INT, partial_id INT, wedstrijdreeks INT, FOREIGN KEY (speler1) REFERENCES tennisspeler(tennisvlaanderenid), FOREIGN KEY (speler2) REFERENCES tennisspeler(tennisvlaanderenid), FOREIGN KEY (partial_id) REFERENCES wedstrijd(partial_id), FOREIGN KEY (wedstrijdreeks) REFERENCES wedstrijd(wedstrijdreeks) ); Klik hier om de mysql code te zien/verbergen om de 'tennisvlaanderen' database te in te vullen met wat test/dummy data 🔽\rDELETE FROM tennisspeler_speelt_wedstrijd; DELETE FROM tennisspeler_inschrijving_wedstrijdreeks; DELETE FROM wedstrijd; DELETE FROM wedstrijdreeks; DELETE FROM tornooi; DELETE FROM tennisspeler; DELETE FROM tennisclub_email; DELETE FROM tennisclub; -- Insert tennis clubs INSERT INTO tennisclub (clubnummer, nummer, straatnaam, gemeente) VALUES (1, 12, \u0026#39;Tennis Straat\u0026#39;, \u0026#39;Antwerpen\u0026#39;), (2, 5, \u0026#39;Racketweg\u0026#39;, \u0026#39;Gent\u0026#39;); -- Insert club emails INSERT INTO tennisclub_email (clubnummer, email_address) VALUES (1, \u0026#39;club1@example.com\u0026#39;), (1, \u0026#39;contact@club1.com\u0026#39;), (2, \u0026#39;info@club2.be\u0026#39;); -- Insert tennis players INSERT INTO tennisspeler (tennisvlaanderenid, geslacht, geboortedatum, ranking, rol, diploma, naam) VALUES (1, \u0026#39;M\u0026#39;, \u0026#39;1990-05-15\u0026#39;, 5, \u0026#39;Wedstrijdleider\u0026#39;, \u0026#39;Diploma X\u0026#39;, \u0026#39;Test Wedstrijdleider\u0026#39;), (2, \u0026#39;V\u0026#39;, \u0026#39;1995-08-20\u0026#39;, 8, NULL, NULL, \u0026#39;Testspeler A\u0026#39;), (3, \u0026#39;M\u0026#39;, \u0026#39;1985-03-10\u0026#39;, 3, \u0026#39;Scheidsrechter\u0026#39;, \u0026#39;Diploma Y\u0026#39;, \u0026#39;Test Scheidsrechter\u0026#39;), (4, \u0026#39;V\u0026#39;, \u0026#39;2000-12-05\u0026#39;, 2, NULL, NULL, \u0026#39;Testspeler B\u0026#39;), (5, \u0026#39;M\u0026#39;, \u0026#39;1996-02-18\u0026#39;, 2, NULL, NULL, \u0026#39;Testspeler C\u0026#39;), (6, \u0026#39;M\u0026#39;, \u0026#39;1992-07-14\u0026#39;, 7, NULL, NULL, \u0026#39;Testspeler D\u0026#39;), (7, \u0026#39;V\u0026#39;, \u0026#39;1998-11-23\u0026#39;, 4, NULL, NULL, \u0026#39;Testspeler E\u0026#39;), (8, \u0026#39;M\u0026#39;, \u0026#39;1989-01-30\u0026#39;, 5, NULL, NULL, \u0026#39;Testspeler F\u0026#39;), (9, \u0026#39;V\u0026#39;, \u0026#39;1993-04-18\u0026#39;, 5, NULL, NULL, \u0026#39;Testspeler G\u0026#39;), (10, \u0026#39;M\u0026#39;, \u0026#39;1997-09-05\u0026#39;, 3, NULL, NULL, \u0026#39;Testspeler H\u0026#39;), (11, \u0026#39;V\u0026#39;, \u0026#39;2001-06-12\u0026#39;, 2, NULL, NULL, \u0026#39;Testspeler I\u0026#39;), (12, \u0026#39;M\u0026#39;, \u0026#39;1994-03-22\u0026#39;, 8, NULL, NULL, \u0026#39;Testspeler J\u0026#39;), (13, \u0026#39;V\u0026#39;, \u0026#39;1990-12-01\u0026#39;, 1, NULL, NULL, \u0026#39;Testspeler K\u0026#39;), (14, \u0026#39;M\u0026#39;, \u0026#39;1987-05-09\u0026#39;, 4, NULL, NULL, \u0026#39;Testspeler L\u0026#39;), (15, \u0026#39;V\u0026#39;, \u0026#39;1999-08-15\u0026#39;, 6, NULL, NULL, \u0026#39;Testspeler M\u0026#39;); -- Insert tournaments INSERT INTO tornooi (id, startdatum, einddatum, wedstrijdleider, tennisclub) VALUES (1, \u0026#39;2023-10-01\u0026#39;, \u0026#39;2023-10-07\u0026#39;, 1, 1), (2, \u0026#39;2023-11-01\u0026#39;, \u0026#39;2023-11-15\u0026#39;, 1, 2), (3, \u0026#39;2024-03-05\u0026#39;, \u0026#39;2024-03-12\u0026#39;, NULL, 2); -- Insert competition series INSERT INTO wedstrijdreeks (id, max_punten, geslacht, tornooi_id) VALUES (1, 5, \u0026#39;M\u0026#39;, 1), (2, 5, \u0026#39;V\u0026#39;, 1), (3, 10, \u0026#39;M\u0026#39;, 1), (4, 10, \u0026#39;V\u0026#39;, 1), (5, 5, \u0026#39;M\u0026#39;, 2), (7, 10, \u0026#39;M\u0026#39;, 2), (8, 10, \u0026#39;V\u0026#39;, 2); -- Insert player registrations INSERT INTO tennisspeler_inschrijving_wedstrijdreeks (tennisspeler, wedstrijdreeks, inschrijvingsdatum) VALUES (5, 1, \u0026#39;2023-09-20\u0026#39;), (8, 1, \u0026#39;2023-09-20\u0026#39;), (14, 1, \u0026#39;2023-09-21\u0026#39;), (10, 1, \u0026#39;2023-09-21\u0026#39;), (4, 2, \u0026#39;2023-09-19\u0026#39;), (11, 2, \u0026#39;2023-09-20\u0026#39;), (13, 2, \u0026#39;2023-09-20\u0026#39;), (9, 2, \u0026#39;2023-09-21\u0026#39;), (7, 2, \u0026#39;2023-09-21\u0026#39;), (6, 3, \u0026#39;2023-09-18\u0026#39;), (8, 3, \u0026#39;2023-09-18\u0026#39;), (12, 3, \u0026#39;2023-09-18\u0026#39;), (1, 3, \u0026#39;2023-09-20\u0026#39;), (3, 3, \u0026#39;2023-09-20\u0026#39;), (10, 3, \u0026#39;2023-09-20\u0026#39;), (5, 3, \u0026#39;2023-09-20\u0026#39;), (14, 3, \u0026#39;2023-09-21\u0026#39;), (2, 4, \u0026#39;2023-09-17\u0026#39;), (9, 4, \u0026#39;2023-09-18\u0026#39;), (15, 4, \u0026#39;2023-09-18\u0026#39;), (7, 4, \u0026#39;2023-09-18\u0026#39;), (11, 4, \u0026#39;2023-09-20\u0026#39;), (6, 7, \u0026#39;2023-09-18\u0026#39;), (8, 7, \u0026#39;2023-09-18\u0026#39;), (12, 7, \u0026#39;2023-09-18\u0026#39;); -- Insert matches INSERT INTO wedstrijd (partial_id, wedstrijdreeks, scheidsrechter, ronde, winnaar, score) VALUES (1, 1, NULL, 2, 5, \u0026#39;6-4, 6-2\u0026#39;), (2, 1, NULL, 2, 14, \u0026#39;6-4, 5-7, 6-0\u0026#39;), (3, 1, 3, 1, 14, \u0026#39;6-1, 6-4\u0026#39;), (1, 2, NULL, 4, 4, \u0026#39;6-0, 6-1\u0026#39;), (2, 2, NULL, 2, 9, \u0026#39;7-6(3), 6-4\u0026#39;), (3, 2, NULL, 2, 7, \u0026#39;6-0, 6-0\u0026#39;), (4, 2, 3, 1, 9, \u0026#39;6-2, 7-5\u0026#39;), (1, 3, NULL, 4, 1, \u0026#39;6-2, 6-2\u0026#39;), (2, 3, NULL, 4, 1, \u0026#39;5-7, 6-2, 6-0\u0026#39;), (3, 3, NULL, 4, 1, \u0026#39;6-3, 6-2\u0026#39;), (4, 3, NULL, 4, 1, \u0026#39;7-5, 6-4\u0026#39;), (5, 3, NULL, 2, 1, \u0026#39;6-2, 6-3\u0026#39;), (6, 3, NULL, 2, 1, \u0026#39;6-2, 6-4\u0026#39;), (7, 3, 3, 1, 1, \u0026#39;6-4, 2-6, 7-5\u0026#39;), (1, 4, NULL, 4, 7, \u0026#39;walkover\u0026#39;), (2, 4, NULL, 2, NULL, NULL), (3, 4, NULL, 2, NULL, NULL), (1, 7, NULL, 2, NULL, NULL), (2, 7, NULL, 1, NULL, NULL); -- Insert player-match participation INSERT INTO tennisspeler_speelt_wedstrijd (speler1, speler2, partial_id, wedstrijdreeks) VALUES (5, 10, 1, 1), (8, 14, 2, 1), (5, 14, 3, 1), (4, 11, 1, 2), (4, 9, 2, 2), (13, 7, 3, 2), (7, 9, 4, 2), (1, 3, 1, 3), (6, 5, 2, 3), (14, 8, 3, 3), (10, 12, 4, 3), (1, 6, 5, 3), (8, 12, 6, 3), (6, 12, 7, 3), (7, 11, 1, 4), (7, 2, 2, 4), (15, 9, 3, 4), (6, 8, 1, 7), (12, NULL, 2, 7); Je kan bovenstaande code kopiëren en opslaan onder filenames zoals create_tables.sql en populate_tables_with_testdata.sql. Door deze onder ./resources-directory van Gradle projecten bijvoorbeeld op te slaan zal het heel simpel zijn om tijdens de oefeningen steeds snel en repeatable testdatabases aan te maken die we kunnen gebruiken om onze code te testen.\nDe dummy data Enkele opmerkingen bij de dummy data die weergeeft welke verschillende scenario\u0026rsquo;s allemaal ingevuld zijn die dan in software getest kunnen worden:\nTornooi 1, wedstrijdreeks M5 heeft 4 inschrijvingen (dus perfecte halve finales) en is volledig uitgespeeld. Tornooi 1, wedstrijdreeks V5 heeft 5 inschrijvingen (dus gedeeltelijk kwartfinale) en is volledig uitgespeeld. Tornooi 1, wedstrijdreeks M10 heeft 8 inschrijvingen (dus perfecte kwart finales) en is volledig uitgespeeld. Speler met id 5, doet ook al in tornooi 1 reeks 1 mee. (net als een heel deel andere spelers) Tornooi 1, wedstrijdreeks V10 5 inschrijvingen (dus gedeeltelijk kwartfinale) en is gedeeltelijk al gespeeld maar is nog niet volledig uitgespeeld. bevat een \u0026lsquo;walkover\u0026rsquo; als resultaat. (iemand die opgeeft) Tornooi 2, wedstrijdreeks M5 heeft geen inschrijvingen. Tornooi 2, wedstrijdreeks V5 bestaat (nog) niet. Tornooi 2, wedstrijdreeks M10 heeft inschrijvingen en wedstrijden gepland, maar er zijn nog geen wedstrijden gespeeld. Tornooi 2, wedstrijdreeks V10 heeft inschrijvingen maar er zijn nog geen wedstrijden gepland. Tornooi 3, wat ook een tornooi van clubnummer 1 is bevat nog geen inschrijvingen, en heeft nog geen wedstrijdleider. Nadenken over de structuur van de database en de interactie met je applicatie Je zal wellicht al gemerkt hebben dat de inhoud van de database niet al te leesbaar is. Zo zie je voor matchen enkel tennisvlaanderenid\u0026rsquo;s wat natuurlijk super onhandig is. Als ik mijn wedstrijd opzoek wil ik de naam van mijn tegenstander zien en niet enkel zijn/haar nummer. Daarvoor dienen dus goede SQL-queries gecombineerd met wat programmeermagic om dit zo weer te geven in de UI.\nBovendien missen er ook nog wat logische elementen die je niet rechtstreeks uit de database kan uitlezen maar die je er wel kan van afleiden. Zo weet je dat als er een wedstrijd van een speler voor een bepaalde reeks te zien is in de wedstrijd-tabel maar de winnaar nog NULL is, dat die wedstrijd dan wel ingepland is, maar nog niet gespeeld is.\nWaarom is het nog belangrijk om na te denken over eigen software? Sommige constraints kunnen niet toegevoegd worden in de definitie van de MySQL-database bijvoorbeeld:\nzorgen dat een speler met meer dan 5 punten niet kan inschrijven in een reeks tot en met 5 punten; zorgen dat een man niet kan inschrijven in een vrouwenreeks en vice versa; zorgen dat een scheidsrechter niet zijn eigen match kan beoordelen; \u0026hellip; Hoe bouw je dit nu in? Dit kan over het algemeen op 2 manieren: voorkomen of error messaging:\nJe kan simpelweg voorkomen dat een vrouw in een mannenreeks kan inschrijven door het onmogelijk te maken in de UI dat een vrouw een inschrijvingsknop heeft voor een mannenreeks. Je kan een error geven wanneer je bijvoorbeeld voor een te lage reeks wil inschrijven. Over het algemeen is het dus belangrijk dat je op zoveel mogelijk plaatsen en in zoveel mogelijk lagen restricties controleert zodat er geen fouten kunnen gebeuren. Dat doe je door constraints mee te geven in je database, error handling te doen, je UI zo te voorzien dat fouten maken bijna onmogelijk wordt \u0026hellip; Dit vraagt natuurlijk heel wat denkwerk voor programmeur, maar dit hoort zeker in deze gevallen tot zijn/haar job. Een werkende database en UI voorzien kan 20% van het werk zijn en ervoor zorgen dat je enkel de juiste dingen kan doen in de UI zal wellicht uit 80% van het werk in beslag nemen. (Daarom is het ook belangrijk om goede en voldoende testen te schrijven!)\nTips Test queries die je wil gebruiken in je programma eerst uit in een GUI tool zoals PHPMyAdmin of Adminer om te testen of ze werken en al een idee te hebben van hoe de output eruit ziet zodat je de returns correct kan processen.\n"
},
{
	"uri": "http://localhost:53502/db-course/transacties/failures-rollbacks/",
	"title": "Failures-Rollbacks",
	"tags": [],
	"description": "",
	"content": "Voorbereidende CREATE statements (Dit is SQLite syntax!) Zie SQLite manual:\nDROP TABLE IF EXISTS student; CREATE TABLE student( studnr INT NOT NULL PRIMARY KEY, naam VARCHAR(200) NOT NULL, voornaam VARCHAR(200), goedbezig BOOL ); DROP TABLE IF EXISTS log; CREATE TABLE log( id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, date DATETIME DEFAULT CURRENT_TIMESTAMP, foreign_id INT NOT NULL, msg TEXT ); INSERT INTO student(studnr, naam, voornaam, goedbezig) VALUES (123, \u0026#39;Trekhaak\u0026#39;, \u0026#39;Jaak\u0026#39;, 0); INSERT INTO student(studnr, naam, voornaam, goedbezig) VALUES (456, \u0026#39;Peeters\u0026#39;, \u0026#39;Jos\u0026#39;, 0); INSERT INTO student(studnr, naam, voornaam, goedbezig) VALUES (890, \u0026#39;Dongmans\u0026#39;, \u0026#39;Ding\u0026#39;, 1); System failure simulatie In SQLite met DB Browser Gegeven een aantal SQL statements, waarvan niet alle statements kloppen, maar die wel allemaal bij elkaar horen als één atomaire transactie. Dat betekent dat als er één van die statements misloopt, de rest teruggedraait zou moeten worden. Het spreekt voor zich dat zonder speciale handelingen, zoals het beheren van transacties, dit niet gebeurt. Een eenvoudig voorbeeld demonstreert dit.\nUPDATE student SET voornaam = \u0026#39;Jaqueline\u0026#39; WHERE studnr = 123; INSERT INTO oeitiskapot; INSERT INTO log(foreign_id, msg) VALUES (123, \u0026#39;Voornaam vergissing\u0026#39;); INSERT INTO student(studnr, naam, voornaam, goedbezig) VALUES (445, \u0026#39;Klakmans\u0026#39;, \u0026#39;Jef\u0026#39;, 1); INSERT INTO log(foreign_id, msg) VALUES (445, \u0026#39;Nieuwe student registratie\u0026#39;); Plak dit in de \u0026ldquo;Execute SQL\u0026rdquo; tab van de SQLite DB Browser. Het resultaat is een foutboodschap:\nnear \u0026#34;;\u0026#34;: syntax error: INSERT INTO oeitiskapot; Maar: het eerste UPDATE statement, voor de foute regel, is wel uitgevoerd:\nOefeningen Probeer bovenstaande voorbeeld zelf uit in de SQLite DB Browser. Als je jezelf ervan verzekerd hebt dat inderdaad het eerste UPDATE statement wordt uitgevoerd, terwijl wij dat in één ACID blok willen, ga dan over naar de volgende oefening. In SQLite is het starten van een transactie erg eenvoudig: zie SQLite transaction tutorials van tutorialspoint.com. BEGIN; en COMMIT; zijn voldoende. Probeer dit uit in bovenstaande voorbeeld om er voor te zorgen dat de voornaam van Jaak niet wordt gewijzigd. Om met een \u0026ldquo;clean slate\u0026rdquo; te herbeginnen kan je gewoon de voorbereidende SQL code copy/pasten en opnieuw uitvoeren. Merk op dat dit nog steeds het ongewenst effect heeft dat de student zijn/haar naam wordt gewijzigd. We moeten expliciet zelf ROLLBACK; aanroepen. Probeer een nieuwe student toe te voegen: eentje met studentennummer, en eentje zonder. Dat tweede kan in principe niet door de NOT NULL constraint. Wrap beide statements in een transactie. Let Op: Het zou kunnen dat SQLite de volgende fout geeft: cannot start a transaction within a transaction: BEGIN;. Queries die geplakt worden in het \u0026ldquo;execute SQL\u0026rdquo; scherm worden meestal (onzichtbaar, achter de schermen) gewrapped in transacties. Stop de huidige transactie door COMMIT; uit te voeren met de knop \u0026ldquo;execute single SQL line\u0026rdquo;.\nLet Op: Het zou kunnen dat BEGIN TRANSACTION; de transactie niet goed encapsuleert, maar simpelweg BEGIN; wel. Het TRANSACTION keyword is optioneel volgens de SQLite docs en lijkt, afhankelijk van de geïnstalleerde SQLite versie, ander gedrag te vertonen.\nIn SQLite met Java/JDBC SQLite/JDBC uitleg: zie APIs - JDBC.\nGebruik nu connection.setAutoCommit(false). Deze regel is nodig omdat in JDBC standaard elke SQL statement aanschouwd wordt als een onafhankelijke transactie, die automatisch wordt gecommit:\nWhen a connection is created, it is in auto-commit mode. This means that each individual SQL statement is treated as a transaction and is automatically committed right after it is executed. (To be more precise, the default is for a SQL statement to be committed when it is completed, not when it is executed. A statement is completed when all of its result sets and update counts have been retrieved. In almost all cases, however, a statement is completed, and therefore committed, right after it is executed.)\nJe kan nu manueel committen met connection.commit();.\nZie JDBC Basics in Oracle docs: https://docs.oracle.com/javase/tutorial/jdbc/basics/transactions.html\nOefeningen Maak een nieuw Gradle project aan en connecteer naar je SQLite database. Merk op dat, bij connectionstring \u0026quot;jdbc:sqlite:sample.db\u0026quot;, automatisch een lege .db file wordt aangemaakt indien de database niet bestaat. Probeer met behulp van executeUpdate() en executeQuery() bovenstaande system failure te veroorzaken. Je kan de \u0026ldquo;foute SQL\u0026rdquo; (met \u0026ldquo;oeitiskapot\u0026rdquo;) gewoon in een string in java copy/pasten. executeUpdate() kan verschillende statements tegelijkertijd verwerken. Verifieer dat de naam foutief toch wordt gewijzigd met een SELECT() nadat je de fout hebt opgevangen in een try { } block. Je moet nu dan ook wel de juiste aanpassingen doen om met een SQLite database te connecteren zie hier\nHet probleem is op te lossen met één welgeplaatste regel: connection.rollback(). De vraag is echter: waar plaatsen we die? En ja, rollback() throwt ook de checked SQLException\u0026hellip; Verifieer of je oplossing werkt door de naam na de rollback terug op te halen en te vergelijken met de juiste waarde: \u0026ldquo;Jaak\u0026rdquo;.\nAangezien de API als zeer slim geworden is zal er zelfs een rollback plaatsvinden bij het opkomen van een SQLException zelfs als je zelf die rollback niet specifiek oproept in de catch-clausule. Daarom gaan we deze oefening samen even als demo bekijken.\nDe DROP TABLE IF EXISTS statements kan je in je project in een aparte SQL file bewaren en als een String inlezen, om in één keer te laten uitvoeren na het openen van de connectie:\nprivate void initTables() throws Exception { URI path = Objects.requireNonNull(App.class.getClassLoader().getResource(\u0026#34;create_db.sql\u0026#34;)).toURI(); var create_db_sql = new String(Files.readAllBytes(Paths.get(path))); System.out.println(create_db_sql); var s = connection.createStatement(); s.executeUpdate(create_db_sql); s.close(); } De verwachte fout (met de ongeldige SQL regel) die SQLite doorgeeft aan Java genereert de volgende stacktrace:\norg.sqlite.SQLiteException: [SQLITE_ERROR] SQL error or missing database (near \u0026#34;;\u0026#34;: syntax error)\rat org.sqlite.core.DB.newSQLException(DB.java:1010)\rat org.sqlite.core.DB.newSQLException(DB.java:1022)\rat org.sqlite.core.DB.throwex(DB.java:987)\rat org.sqlite.core.NativeDB._exec_utf8(Native Method)\rat org.sqlite.core.NativeDB._exec(NativeDB.java:94)\rat org.sqlite.jdbc3.JDBC3Statement.executeUpdate(JDBC3Statement.java:109)\rat SQLiteTransactionTest.doStuff(SQLiteTransactionTest.java:54)\rat SQLiteMain.main(SQLiteMain.java:7) Denkvragen De SQLite website beschrijft in detail hoe ze omgaan met \u0026ldquo;atomic commits\u0026rdquo; om aan de ACID regels te voldoen. Lees dit na op https://sqlite.org/atomiccommit.html Op welke manier gebruiken zij een rollback journal? Hoe is dat gelinkt aan de logfile van 14.2.3 op p.435? "
},
{
	"uri": "http://localhost:53502/db-course/nosql/4oef3/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "\rPrint docs\r...\r"
},
{
	"uri": "http://localhost:53502/db-course/bigdata/basics/",
	"title": "1. Big Data Basics",
	"tags": [],
	"description": "",
	"content": "De Big in Big Data mag je letterlijk nemen. IBM berekende onlangs dat wij allemaal 2.5 quintillion bytes aan data genereren. Elke minuut meer dan 350.000 tweets, 75.000 uren van Netflix video streams, meer dan 35.000 Apple store apps gedownload, enzovoort.\nDe term Big Data is al sinds eind de jaren negentig aan een opmars bezig. We kunnen \u0026ldquo;grote datasets\u0026rdquo; categoriseren afhankelijk van wat we noemen de vijf Vs:\nVolume\u0026mdash;Het gaat (uiteraard) over een alsmaar groeiend \u0026ldquo;groot volume\u0026rdquo; aan data; Velocity\u0026mdash;De snelheid waarmee de data in en uit systemem vloeit die altijd maar toeneemt; Variety\u0026mdash;De range aan data types breidt altijd maar uit (JSON, XML, RDBMS, noSQL, files, \u0026hellip;); Veracity\u0026mdash;Hoe waarheidsgetrouw is de data eigenlijk wel? Data vertoont alsmaar vaker inconsistenties/ambiguiteit; Value\u0026mdash;Wat heb je aan al die data zonder er iets waardevol mee te doen (zoals een crutiale business beslissing)? src: tistory.com\rDenk aan de biljoenen mensen die dagelijks Facebook gebruiken en gigantische volumes aan foto\u0026rsquo;s en tekst uploaden. Het aantal gebruikers dat gestaag steeg (velocity) en de variëteit van data zoals APIs tussen Facebook en anderen om elders in te loggen met je account, video en fotomateriaal in plaats van enkel tekst, integratie met WhatsApp/Instagram, \u0026hellip; Maar hoeveel fake data zit er wel niet tussen, en hoeveel accounts worden misbruikt? Hoeveel data lekken en gevoelige data bevat het? (veracity). Vooral uw persoonsgegevens is voor Meta, het bedrijf achter Facebook, letterlijk goud waard, en verkoopt het door aan derden (value), vaak zonder jouw toestemming!\nNog een leuk voorbeeld: de winkel https://ebay.com/ heeft een data warehouse van 45 petabytes\u0026mdash;ofwel 45.000 terabytes!\nUit de vorige hoofdstukken blijkt dat een traditioneel RDBMS systeem niet goed kan scalen (zie nosql introductie). Echter, een NoSQL DB is slechts één component in het gehele Big Data ecosysteem. In de praktijk gaat het over veel pools, clusters, servers, heterogene DB systemen, files, APIs, \u0026hellip; allemaal gecombineerd (zie data warehousing lakes). Het beheren van een Big Data systeem gaat niet over één DB systeem, maar over het beheren van verschillende parameters (snelheid, grootte van input, connecties tussen systemen, \u0026hellip;). De analyse van de inhoud ervan is vaak een taak voor gespecialiseerde data scientists.\n"
},
{
	"uri": "http://localhost:53502/db-course/nosql/basics/",
	"title": "1. NoSQL Basics",
	"tags": [],
	"description": "",
	"content": "Het schaalbaarheid probleem Het probleem met RDMS (relationele database management systems) is vaak schaalbaarheid. Gezien de ACID data validity voorwaarden is altijd de vraag: is dit schaalbaar?\nOptie 1: Vertical scaling De makkelijke oplossing is \u0026ldquo;scaling up\u0026rdquo;: meer storage, CPU, RAM, \u0026hellip; voorzien zodat er meer cycles kunnen benut worden en hopelijk ook meer transacties concurrent kunnen worden verwerkt (zie transacties basics).\nJe botst hier echter snel op hardware limitaties\u0026mdash;niet alles is opgelost met een latje RAM.\nOptie 2: Horizontal scaling In plaats van \u0026ldquo;omhoog\u0026rdquo; te gaan en meer hardware in hetzelfde systeem te steken, kunnen we ook meer hardware op verschillende plaatsen in het netwerk zetten: scaling out in clusters. Dit noemen we horizontaal scalen: meer kleintjes die gedistribueerd hetzelfde doen.\nDeze oplossing introduceert echter een ander probleem: data consistency is niet altijd gegarandeerd. Als ik iets in één server van een cluster bewaar, wordt dit dan onmiddellijk in de andere ook bewaard? Wat als er eentje uitvalt, en dat net mijn access point was? Op welke manier wordt die data verdeeld binnen de cluster? Enzovoort. Distributed computing is een erg complex domein binnen de informatica. We raken in dit vak enkel de top van de ijsberg aan.\nWat is een \u0026ldquo;cluster\u0026rdquo; precies? Denk aan een verzameling van grote data centers: twee of meer fysieke centra waar enorm veel servers geplaatst worden. Eén server kan je eigen laptop zijn. Je kan ook verschillende virtuele servers op je laptop draaien: dat is een node. (We hanteren hier de hierarchie van elementen volgens Cassandara) Cluster \u0026laquo; Data Center \u0026laquo; Rack \u0026laquo; Server \u0026laquo; Node\nEen typische relationele database, met zijn ACID eigenschappen, maakt horizontaal schalen dus moeilijk. Consistentie en availability maakt partitioning tot een uitdaging. Dit is ook zichtbaar in het CAP probleem; of \u0026ldquo;Consistency, Availability, Partitioning Tolerance\u0026rdquo; probleem. Wil je inzetten op partitioning, dan is de kans groot dat je zal moeten inboeten op consistency en availability. De volgende figuur illustreert dit probleem:\nHet CAP probleem. src: freecodecamp.org\rFlexibiliteit van horizontal scaling krijgen we door af te stappen van een typische RDBMS, en te kijken naar wat er kan als de R (relational) wegvalt\u0026mdash;ofwel noSQL databases. De populariteit hiervan groeide exponentieel sinds scalability een groter probleem werd: denk aan gigantische data warehouses van Amazon, Google\u0026rsquo;s zoek engine, Facebook pagina\u0026rsquo;s, enzovoort. NoSQL systemen garanderen ook consistentie\u0026mdash;alleen niet onmiddellijk: dit heet eventual consistency.\nDus, horizontal scaling is eenvoudiger met NoSQL:\nEr is géén relationele data; Er is géén (onmiddellijke) consistentie\u0026mdash;dus ook geen coordinatie overhead!; Dit is zeer goed scalable. NoSQL basics Een vergelijking van eigenschappen tussen een relationele en niet-relationele database systeem:\nEigenschap Relationeel NoSQL Data paradigma relationeel 4 types: key/val, docs, \u0026hellip; (s3.2) Distributie Single-node Distributed Scalability Vertical Horizontal, replication Structuur Schema-based Flexible Querty taal SQL Specialized (JavaScript) Transacties ACID BASE Features views/procs/\u0026hellip; basic API Data vol. \u0026ldquo;normal\u0026rdquo; \u0026ldquo;huge amounts\u0026rdquo; *BASE staat voor Basically Available, Soft state, Eventual concistency\nMerk op dat het niet altijd de beste oplossing is om naar een NoSQL DB te grijpen. Wanneer dan wel of niet? De volgende vragen kunnen hierbij helpen:\nBevat data veel/weinig relaties? Komt er enorm veel data/sec. binnen? Replication vereisten? Scripting mogelijkheden? Bestaande kennis in bedrijf? \u0026hellip; Klassieke relationele databases zijn nog steeds een van de meestgebruikte ter wereld, maar dat wil niet zeggen dat er geen (populaire) alternatieven zijn. Kijk eens naar de db-engines.com ranking trends op db-engines.com:\nDe drie bovenste lijnen zijn Oracle, MySQL en Microsoft SQL Server, de drie giganten die alledrie relationele DBMS systemen zijn. PostgresQL, de oranje stijgende lijn, is volgende\u0026mdash;ook SQL. Maar daarnaast volgen MongoDB, Cassandra, Redis, DynamoDB, \u0026hellip;\u0026mdash;allemaal verschillende soorten noSQL alternatieven.\nNoSQL Types 4 NoSQL types. src: improgrammer.net\rEr zijn, zoals bovenstaande figuur aangeeft, 4 grote groepen van NoSQL systemen:\n1. Document stores. Hier bewaar je een \u0026ldquo;document\u0026rdquo; in, dat meestal in JSON-formaat is, zoals:\n{ \u0026#34;bedrag\u0026#34;: 100.3, \u0026#34;gebruiker\u0026#34;: \u0026#34;Jos Klakmans\u0026#34;, \u0026#34;Stad\u0026#34;: \u0026#34;Diepenbeek\u0026#34;, \u0026#34;certificaten\u0026#34;: [{ \u0026#34;type\u0026#34;: 1, \u0026#34;naam\u0026#34;: \u0026#34;Master in de bliebloe\u0026#34; }, { \u0026#34;type\u0026#34;: 2, \u0026#34;naam\u0026#34;: \u0026#34;Bachelor in de blakkiela\u0026#34; }] } Merk op dat hier geen relaties worden gelegd, alhoewel dat wel kan: bijvoorbeeld document 1 kan een property { id: 1 } hebben, en document 2 { id: 2, relatedDocumentId: 1 }. Dit echter veel gebruiken zal een performance hit geven: document stores dienen voornamelijk om gigantisch veel onafhankelijke data te bewaren, op een ongestructureerde manier. Er zijn geen table definities: een key meer of minder maakt niet uit.\nNoSQL: { name: 'Jos' } -\u0026gt; { name: 'Jos', well-behaved: true }. Geen INSERT INTO student(name) VALUES (\u0026quot;Jos\u0026quot;) dus! Ook hier wordt intern hashing gebruikt (zie onder): Het document { name: 'Jos' } wordt intern opgeslaan als { name: 'Jos', _id: 23235435 }. Data retrieval snelheid blijft belangrijk, dus extra indexen/views kunnen door de gebruiker zelf worden aangemaakt (zie volgende hoofdstukken).\nOm documenten te ordenen worden soms wel collecties aangemaakt, maar dit is bijna altijd optioneel!\nWe zullen ons in deze cursus focussen op document stores. Zie NoSQL - document stores om een idee te hebben hoe dit in de praktijk gebruikt wordt.\n2. Graph-based oplossingen. Wat als we toch veel relationele gegevens hebben, maar het nog steeds over (1) ongestructureerde data gaat en (2) te veel is voor in één klassiek RDBMS systeem te bewaren? Als de relaties de data zelf zijn, dan hebben we een grafen-gebaseerde oplossing nodig. Hier zijn géén dure JOIN statements nodig om de relaties ad-hoc te maken. Een typische toepassing hiervan zou social graphs zijn.\nEen voorbeeld subgraph visualisatie in Neo4j.\rStel dat je alle boeken wilt ophalen geschreven door een bepaalde auteur (= de relatie). In SQL, waar de data typisch in twee tabellen leeft (book en author), heb je een (impliciete) JOIN nodig:\nSELECT book, title FROM book, author, books_authors\rWHERE author.id = books_authors.author_id\rAND book.id = books_authors.book_id\rAND author.name = \u0026#34;De Jos\u0026#34; Maar in Cypher, de querytaal van grafendatabase Neo4J, ziet die query er als volgt uit:\nMATCH (b:Book) \u0026lt;- [ :WRITTEN_BY]-(a:Author)\rWHERE a.name = \u0026#34;De Jos\u0026#34;\rRETURN b.title Data wordt op basis van WRITTEN_BY relatie eigenschap opgehaald. Relationele data\u0026mdash;de letterlijke relaties\u0026mdash;zijn hier altijd expliciet, en niet verborgen in foreign key constraints.\n3. Key-Value stores. Dit is de eenvoudigste soort, waarbij gewoon blobs van data in een hash table opgeslagen worden, zoals jullie gewoon zijn in Java:\nMap\u0026lt;String, Persoon\u0026gt; leeftijden = new HashMap\u0026lt;\u0026gt;(); leeftijden.put(\u0026#34;Wilfried\u0026#34;, new Persoon(\u0026#34;Wilfried\u0026#34;, 20)); leeftijden.put(\u0026#34;Seppe\u0026#34;, new Persoon(\u0026#34;Seppe\u0026#34;, 30)); leeftijden.put(\u0026#34;Bart\u0026#34;, new Persoon(\u0026#34;Bart\u0026#34;, 40)); leeftijden.put(\u0026#34;Jeanne\u0026#34;, new Persoon(\u0026#34;Jeanne\u0026#34;, 18)); Hash functies In dit voorbeeld stopt de HashMap met bestaan zodra die out of scope gaat op je eigen machine, maar er zijn ook distributed hash tables. Hier is de hash functie het belangrijkste onderdeel, die de onderliggende key genereerd en dus bepaald in welke \u0026ldquo;bucket\u0026rdquo; een waarde wordt opgeslagen\u0026mdash;en dus ook, op welke server in een cluster. Een goede hash functie moet (1) deterministisch zijn: atlijd dezelfde hash waarde voor dezelfe input genereren; (2) uniform zijn: er moet een goede verdeling zijn van de output range; en (3) een vaste grootte hebben zodat het makkelijker is voor de data structuur om de hash waarde te bewaren.\nVrijwel alle NoSQL databases gebruiken achterliggend hashing technieken om horizontal scalability makkelijker te maken. Als alle hash values mooi verdeeld worden, kan dit ook mooi over verschillende databases verdeeld worden.\nPartioning/sharding In bovenstaand voorbeeld worden de persoonsgegevens verspreid over 3 verschillende servers door de hashing \u0026ldquo;index\u0026rdquo; (mod3 + 1). Data partitioning noemen we ook wel sharding waarbij een individuele partitie een shard is. Om zo efficient mogelijk te partitioneren schakel je best servers aan elkaar in een soort van \u0026ldquo;ring\u0026rdquo;, zoals in dit schema:\nRing partitioning vereist wel consistent hashing functies, anders klopt de node verdeling (de kleuren in het schema) niet meer. Om zo effient mogelijk data door te geven (replication, zie later NoSQL: replication) hebben nodes weet van elkaar. Het is echter nog steeds niet mogelijk om de ACID regels te volgen: een gedistribueerd systeem zoals deze ring kan nooit én consistent én available én partition tolerant zijn.\nWat is dan een oplossing voor NoSQL systemen? BASE in plaats van ACID:\nBasically Available (BA); elke (gebruikelijk HTTP-based) request ontvangt een respons, hetzij een 200 (OK), hetzij een 4xx/5xx (een externe/interne fout). Ook al zijn niet alle nodes geupdate, toch kan er al een 201 worden teruggegeven\u0026mdash;asynchroon dus. Soft state (S); sate kan wijzigen, ook zonder input! We weten dus nooit exact wat er in de shards zit. Read requests zijn soms out-of-date omdat een shard update in de ring partitie plaats aan het vinden was, maar dat één bepaalde shard nog niet bereikte\u0026hellip; Eventually Consistent (E); NoSQL biedt de \u0026ldquo;ooit is het wel consistent\u0026rdquo; mode aan. In de praktijk verschilt het van NoSQL database tot database systeem hoe dicht deze BASE regels tegen de ACID regels aanleunen. De document-based CouchDB, die we later zullen in detail bekijken, ondersteunt ook vormen van transacties en dergelijke, wat het eerder iets ACID-achtig maakt.\nMemcached Memcached is een distributed in-memory key/value store die op grote schaal gebruikt kan worden als caching mechanisme. Systemen als Memcached zijn enorm performant en worden vaak gebruikt als caching database die geplaatst wordt voor de eigenlijke RDBMS:\ngraph LR;\ruser[User]\rcache{Cache DB}\rdb{Relationele DB}\ruser --\u003e|Haal genres op| cache\rcache --\u003e|cache hit| user cache --\u003e|cache miss| db\rdb --\u003e|refresh| cache\rHet feit dat Netflix Memcached sponsort zegt genoeg. Memcached gebruiken is erg eenvoudig en gewoon een kwestie van de API in Java/Kotlin aan te spreken om data te feeden/op te halen.\nEen simpel Memcached voorbeeld is terug te vinden onder key-value stores: memcached.\n4. Wide-column databases. Wide-column, of column-based databases, zijn eigenlijk relationele databases op zijn kop\u0026mdash;letterlijk.\nWat is het grootste nadeel van het queryen van relationele databases? Deze zijn row-based: als je alle genres uit een BOEK tabel wilt halen, zal je alle rijen moeten afgaan en daar een DISTINCT op doen\u0026mdash;alles behalve performant. Bijvoorbeeld:\nid genre title price\r1 Fantasy book bla 10\r2 Fantasy another title 20\r3 horror wow-book 10 Hoe haal ik hier alle genres op? SELECT DISTINCT(genre) FROM boeken. Wat is de gemiddelde prijs? SELECT AVG(price) FROM boeken\u0026mdash;ook een erg dure operatie indien er miljoenen records aanwezig zijn. Een snelheidswinst valt te boeken door te werken met indexen, maar daar lossen we niet alles mee op.\nWat nu als je de kolommen als rijen beschouwt, op deze manier:\ngenre: fantasy:1,2 horror: 3\rtitle: book bla:1, another title:2 wow-book: 3\rprice: 10:1,3 20:2 Wat is nu de gemiddelde prijs? Haal 1 \u0026ldquo;rij\u0026rdquo; op en deel door het aantal. Welke genres zijn er zoal? De eerste rij is al onmiddellijk het antwoord! We verzamelen hier dus vertical slices van data, wat erg belangrijk kan zijn voor Business Intelligence (BI): super-linked data tussen de \u0026ldquo;echte\u0026rdquo; row-based data.\nDe meest gebruikte column-DB is Cassandra. Op de website staat:\nManage massive amounts of data, fast, without losing sleep.\nCassandra komt met in-memory buffers, tracking \u0026amp; monitoring, \u0026hellip;\nCase Studies Welke database systemen\u0026mdash;of een combinatie ervan\u0026mdash;denk je dat de volgende grote bedrijven hanteren voor hun producten?\nhttps://www.benl.ebay.be/ Hint: https://www.slideshare.net/jaykumarpatel/cassandra-at-ebay-13920376 (2012) https://www.army.mil/ Hint: https://go.neo4j.com/rs/710-RRC-335/images/Neo4j-case-study-US-army-EN-US.pdf (2019) https://spotify.com/ Hint: https://engineering.atspotify.com/2015/01/09/personalization-at-spotify-using-cassandra/ (2015) https://uber.com/ Hint: http://highscalability.com/blog/2016/9/28/how-uber-manages-a-million-writes-per-second-using-mesos-and.html (2016) Denkvragen Is een RDBMS of een NoSQL database geschikter om aan \u0026ldquo;Big Data\u0026rdquo; te doen? Waarom wel/niet? Waarom vereist ring partitioning consistent hashing? Wat heeft een hashing functie te maken met het horizontaal kunnen schalen van data in een DBMS? Waarom gebruiken zo veel grote bedrijven een combinatie van verschillende DBMS systemen? Zie je hier ook nadelen in? Wanneer denk je dat een column-based database als Cassandra nuttig zou zijn? Leg het verschil tussen ACID en BASE uit in functie van de typische eigenschappen van een database. Waarom werkt vertical scaling niet? Waarom wel? "
},
{
	"uri": "http://localhost:53502/db-course/xml/basics/",
	"title": "1. XML Basics",
	"tags": [],
	"description": "",
	"content": "XML Data Storage XML staat voor Extensible Markup Language. Het is een taal die we gebruiken om met tags gegevens te structureren. Een tag opent zich op volgende manier: \u0026lt;boek\u0026gt; en sluit op deze manier: \u0026lt;/boek\u0026gt;. Je herkent misschien het gebruik van deze tags van HTML? Dat komt omdat HTML en XML allebei gegroeid zijn uit dezelfde taal (SGML).\nWaarom XML gebruiken? XML is nog steeds een vaak voorkomende manier om data te structureren en definiëren. Denk bijvoorbeeld aan webhook calls waarbij je kan kiezen tussen een response te krijgen in XML of JSON. Al krijgt JSON de laaste jaren meer en meer voorkeur omwille van zijn makkelijke en leesbare syntax, toch zijn er nog instanties waarbij XML de enige optie is.\nVoorbeeld \u0026lt;boeken\u0026gt; \u0026lt;boek\u0026gt; \u0026lt;titel\u0026gt;De gouden kooi\u0026lt;/titel\u0026gt; \u0026lt;auteur\u0026gt;A.F.Th. van der Heijden\u0026lt;/auteur\u0026gt; \u0026lt;jaar\u0026gt;1981\u0026lt;/jaar\u0026gt; \u0026lt;/boek\u0026gt; \u0026lt;boek\u0026gt; \u0026lt;titel\u0026gt;Het diner\u0026lt;/titel\u0026gt; \u0026lt;auteur\u0026gt;Herman Koch\u0026lt;/auteur\u0026gt; \u0026lt;jaar\u0026gt;2009\u0026lt;/jaar\u0026gt; \u0026lt;/boek\u0026gt; \u0026lt;boek\u0026gt; \u0026lt;titel\u0026gt;De ontdekking van de hemel\u0026lt;/titel\u0026gt; \u0026lt;auteur\u0026gt;Harry Mulisch\u0026lt;/auteur\u0026gt; \u0026lt;jaar\u0026gt;1982\u0026lt;/jaar\u0026gt; \u0026lt;/boek\u0026gt; \u0026lt;/boeken\u0026gt; Wat opvalt is dat we in XML maar 1 root element hebben. De \u0026lt;boeken\u0026gt; tag is het root element van dit voorbeeld en er is geen enkele andere tag op dit niveau. Daarbinnen kunnen we dan wel meerdere keren het \u0026lt;boek\u0026gt; element definiëren.\nOefening Voeg zelf een boek toe aan het bovenstaande voorbeeld Schrijf zelf een XML bestand dat studenten omschrijft. Volgende elementen moeten aanwezig zijn: studnr, naam, voornaam en goedbezig (boolean). "
},
{
	"uri": "http://localhost:53502/db-course/bigdata/datawarehousing/",
	"title": "2. Data Warehousing &amp; BI",
	"tags": [],
	"description": "",
	"content": "Tot nu toe hebben we ons toegelegd op het zo optimaal mogelijk bewaren en ophalen van data\u0026mdash;rekening houdend met integriteit en anderen ACID/BASE principes. Maar wat zijn we hier nu allemaal mee, los van een werkende applicatie? In dit hoofdstuk gaan we data benaderen vanuit business perspectief.\nEen bedrijf kan gebaseerd op de miljoenen eenheden data dat het verzameld, op verschillende plekken en in verschillende formaten, beter beslissingen nemen. Strategische business beslissingen worden meestal op verschillende niveau\u0026rsquo;s genomen:\nNiveau 1 noemen we het operationeel niveau. Hier worden dagelijkse beslissingen genomen op korte termijn, vaak zonder al te veel naar de toekomst te kijken. Denk maar aan verschillende verkopen, implementatie beslissingen vanuit business perspectief, enzovoort. Niveau 2 noemen we het tactisch niveau. Middle management probeert hier op middellange termijn (bijvoorbeeld een maand/kwartaa/jaar) een vooruitblik te doen en gebaseerd daarop een partnerschap aan te gaan of af te wijzen. Niveau 3 noemen we het strategisch niveau. Senior management neemt beslissingen op dit niveau om het bedrijf op lange termijn (5 jaar of misschien zelfs langer) op koers te houden. Stel dat jij een bedrijf van 100 man hebt. Hoe beslis je waarin te investeren, om binnen 5 jaar niet failliet te zijn, maar misschien uit te groeien tot een bedrijf van 150 man? Hier kan data helpen met beslissen. De term Business Intelligence (BI) slaat hier op: de set van activiteiten, technieken, en tools om (1) patronen in data van het verleden te herkennen en (2) voorspellingen te maken naar te toekomst toe.\nEen bijkomend probleem is dat je groot bedrijf enorm veel data heeft:\nHet genereert dagelijks facturen en sales; Werknemers gebruiken de tikklok die weer data voorstelt; Je eindgebruikers interageren met jullie software, wat misschien verspreid zit over verschillende systemen; De helpdesk beheert tickets; HR houdt indexen van lonen bij en iemand beheert de fleet van bedrijfswagens; \u0026hellip; Het is duidelijk dat één simpele SELECT sales FROM income niet voldoende gaat zijn voor het management om beslissingen te helpen maken. We hebben een data warehouse nodig.\nsrc: sqlhammer.com\rProbeer op bovenstaand schema, een voorbeeld van hoe moderne data warehouses werken in een groot bedrijf, alle verschillende componenten te identificeren. Links staat de data die binnenkomt, en rechts het resultaat van de analyse. We bespreken hieronder kort elk blok. Experimentatie met de praktische kant, door middel van libraries als Apache Hadoop, is een optionele oefening voor de student.\nWe beginnen met de grote blauwe blok: een \u0026ldquo;data warehouse\u0026rdquo;.\nEen Data Warehouse (DW) Wat is een data warehouse? Volgens de uitvinder, Bill Inmon:\nA data warehouse is a (1) subject-oriented, (2) integrated, (3) time-variant, and (4) non-volatile collection of data in support of management\u0026rsquo;s decision-making process.\nDat klinkt ingewikkelder dan het is:\nSubject-oriented; de data is gecentreerd rond subjecten ofwel klanten, producten, sales, etc. De data is niet gecentreerd rond transacties of applicaties. Het moet managers helpen een beslissing maken, niet developers helpen ontwikkelen. Integrated; het is één grote structuur met als input verschillende andere DB sources met elk hun eigen formaat. Hier is dus conversie voor nodig: zie verder. Time-variant; een data warehouse bewaart data als een series van snapshots: bij intervallen van bijvoorbeeld elk kwartaal wordt data vernieuwd. Non-volatile; data is voornamelijk read-only (na initieel inladen): de belangrijkste operaties zijn dus loading \u0026amp; retrieval. Bekijk de volgende schematische weergave van een typische data warehouse:\ngraph BT;\rWH[(Data Warehouse)]\rRDBMS1[[RDBMS 1]]\rRDBMS2[[RDBMS 2]]\rXML[/XML\\]\rMAIL[/E-MAIL\\]\rETL1{{ETL}}\rETL2{{ETL}}\rETL3{{ETL}}\rETL4{{ETL}}\rETL1 --\u003e WH\rETL2 --\u003e WH\rETL3 --\u003e WH\rETL4 --\u003e WH\rRDBMS1 --\u003e ETL1\rRDBMS2 --\u003e ETL2\rXML --\u003e ETL3\rMAIL --\u003e ETL4\rAan de onderkant zie je verschillende bronnen van data\u0026mdash;zeer waarschijnlijk op zichzelf relationele of niet-relationele databases, XML, emails, HTML, andere losse CSV bestanden, \u0026hellip; Die moeten vanwege het integrated principe allemaal in één grote blok als snapshot worden bewaard zodat het management deze makkelijk kan queryen. Daarom moet er voor élke data source een ETL of Extraction, Transformation, and Loading proces worden opgestart: bepaalde attributen in de XML veranderen van structuur, de datum in RDBMS1 is opgeslaan als YYYY-MM-DD maar in RDBMS2 als DD-MM-YYYY, afrondingsverschillen worden weggewerkt, etc etc. Merk op dat niet altijd alle gegevens genormaliseerd worden. Een data warehouse kan dus best ook gedenormaliseerde data bevatten, maar dat komt minder frequent voor.\nEen data warehouse is dus geaggregeerde en opgekuiste data dankzij de ETLs. Er is vooral high-level data te vinden die kan gebruikt worden voor tactische, en vooral strategische beslissingen, maar minder voor operationele. Daarvoor kijk je best gewoon naar de bronnen zelf.\nHet opzetten van de ETL is waarschijnlijk 80% van het werk, dit is héél tijdsintensief!\nQ: Over hoeveel data gaat het in een data warehouse? A: Veel. Erg veel. Er zijn warehouses (vandaar ook \u0026ldquo;warenhuis\u0026rdquo; en niet zomaar \u0026ldquo;database\u0026rdquo; of \u0026ldquo;servertje\u0026rdquo;) van 12 petabytes, wat 12000 terabytes is. Bedenk hoeveel data wij elke minuut genereren: hoeveel tweets, hoeveel beurstransacties, hoeveel commits, \u0026hellip;\nIn sommige gevallen wenst men niet onmiddellijk alle data in de productie warehouse te bewaren, maar eest nog een staging area op te zetten. Deze warehouse staat voor de \u0026ldquo;echte\u0026rdquo; en en kan bijvoorbeeld worden gebruikt om intensieve machine learning algoritmes op te laten draaien zonde dat de performantie van de effectieve warehouse in het gedrang komt. Zo\u0026rsquo;n staging warehouse noemen we een operational data store. (zie schema bovenaan: links van het Hadoop logo).\nVoor BI systemen om effectief te zijn, moet de data ook kwalitatief zijn. Gebaseerd op \u0026ldquo;rommel\u0026rdquo; een grote toekomstgerichte business planning maken is een recept voor mislukking\u0026mdash;en mogelijks faillisement. Dus: Garbage In, Garbage Out (GIGO). ETLs moeten correct zijn, en het is ook een kwestie van de juiste data op te nemen in je warehouse. Niet alles hoeft of kan van belang zijn.\nRDBMS vs DW Hoe verhoudt een data warehouse zich ten opzichte van een typisch transactionele database?\nTransactional system Data Warehouse Usage Day to day ops Decision support mngt Latency real-time periodic snapshots Design app-oriented subject-oriented Normalization normalized (sometimes also) denormalized data Manipulation insert/update/delete/select insert (once)/select Transaction mngt important less of a concern Type of queries many simple few complex, some ad-hoc Mini DWs: Data Marts In de praktijk is één gigantische data warehouse, afhankelijk van de grootte van het bedrijf, niet bruikbaar. Data snapshot storage wordt meestal in functionele stukken opgeslagen, misschien opgedeeld per business unit, zoals het bedrijf ook is ingedeeld:\ngraph BT;\rWH[(Data Warehouse)]\rDM1[(Mart 1: Sales)]\rDM2[(Mart 2: Accounting)]\rDM3[(Mart 3: Finances)]\rDM1 --\u003e WH\rDM2 --\u003e WH\rDM3 --\u003e WH\rElke mart wordt op zijn beurt gevoed via een ETL zoals het eerste schema in dit hoofdstuk.\nHet voordeel van zo\u0026rsquo;n opdeling in data marts is (1) focused content en (2) uiteraard performantiewinst. De managers van sales moeten niet onnodig in de accounting mart queries afvuren en omgekeerd, alhoewel het hoger management natuurlijk nog steeds graag een overzicht van alles heeft in bepaalde verslagen.\nData Lakes Soms zijn data warehouses en hun marts niet flexibel genoeg om de gigantische (en eindeloze) stroom aan data te kunnen opslaan. Vergeet niet dat ETLs ook veel processorkracht vereisten, en een snapshot maken maar op een vaste periode gebeurt. In dat geval is een data lake handig: letterlijk een meer waar alle inkomende data (relatief) ongestructureerd wordt ingedumpt (zie lichtblauwe balk op schema bovenaan).\nWanneer voedt men een lake en wanneer een warehouse? Een lake wordt vooral gebruikt voor native data\u0026mdash;in zijn ruw formaat. Hier is nog geen ETL aan bod gekomen. Als het over ruwe signaaldata gaat, clickstreams, social media feeds, server logs, etc, dan is een data lake interessanter.\nNet omdat dit allemaal ruwe data is, is het analyseren van die data werk voor specialisten: dit zijn de \u0026ldquo;advanced analytics\u0026rdquo; op het bovenstaande schema. Hier zijn data scientists mee bezig. De gemiddelde bedrijfsmanager heeft hier echter niets aan! Een data lake is dus niet voldoende om bedrijfsbeslissingen te kunnen helpen maken\u0026mdash;de voornaamste reden waarom we met warehousing bezig zijn. Vaak wordt data van een lake nog doorgesluisd naar een operational data store, die op zijn beurt data laat doordruppelen naar de productie warehouse. Het wordt ingewikkeld\u0026hellip;\nData warehousing wordt ook aangeboden in de cloud. Data lakes worden vaak in de cloud gehost om kosten te drukken aangezien hier nog grotere hoeveelheden data wordt bewaard. Een voorbeeld hiervan is Amazon Redshift, dat wordt gebruikt door Nasdaq. Ze verwerken er 70 miljoen records per dag: https://aws.amazon.com/solutions/case-studies/nasdaq-case-study/.\n"
},
{
	"uri": "http://localhost:53502/db-course/nosql/keyvaluestores/",
	"title": "2. Key-value stores",
	"tags": [],
	"description": "",
	"content": "1.1 Persistente Hashmaps De eenvoudigst mogelijke noSQL database die gebruik maakt van key/values is een simpele HashMap\u0026lt;K,V\u0026gt; die je zelf serialiseert naar een flat file op de HDD. Een netwerk share kan dit bestand delen, maar locking systemen zullen moeten ingebouwd worden om te voorkomen dat dit bestand corrupt wordt.\nDe \u0026ldquo;oude\u0026rdquo; manier om dit te doen op de JVM is gebruik te maken van FileOutputStream:\npublic static void main(String[] args) throws IOException { var db = new HashMap\u0026lt;String, Object\u0026gt;(); db.put(\u0026#34;joske\u0026#34;, new Student(\u0026#34;Joske\u0026#34;, 11)); var file = new File(\u0026#34;database.db\u0026#34;); var f = new FileOutputStream(file); var s = new ObjectOutputStream(f); s.writeObject(db); s.close(); } Inlezen werkt op dezelfde manier, met FileInputStream en ObjectInputStream. Hoe je Student klasse wordt geserialiseerd kan je zelf kiezen, maar een vereiste is dat je de interface Serializable implementeert!\nMet bovenstaande interface kan je de student terug uitlezen:\nvar s = new ObjectInputStream(new FileInputStream(\u0026#34;database.db\u0026#34;)); Map\u0026lt;String, Object\u0026gt; map = (Map\u0026lt;String, Object\u0026gt;) s.readObject(); s.close(); Student joske = (Student) map.get(\u0026#34;joske\u0026#34;); System.out.println(joske.getName()); 1.1.1 Oefeningen Werk bovenstaand voorbeeld uit en persisteer een aantal studenten met de volgende klasse: public class Student { private final String name; private final int age; public Student(String name, int age) { this.name = name; this.age = age; } } 1.2 Distributed Hashmaps: Memcached We kunnen eenvoudig een verbinding maken met een (of meerdere) Memcached server via de Memcached Java client van net.spy.spymemcached (zie mvn repo: https://mvnrepository.com/artifact/net.spy/spymemcached). Dit hoeft maar één regel code te zijn: (zie memcached javadocs)\nvar client = new MemcachedClient(new InetSocketAddress(\u0026#34;127.0.0.1\u0026#34;, 11211)); // bewaar een student onder key \u0026#34;joskey\u0026#34; voor één uur (3600s) client.set(\u0026#34;joskey\u0026#34;, 3600, new Student(\u0026#34;Jos\u0026#34;, 20)); // retrieve object var restoredStudent = (Student) client.get(\u0026#34;Jos\u0026#34;); De client code vereist een werkende memcached server zoals https://www.memcached.org, in bovenstaand voorbeeld draaiend op poort 11211. Je kan dit zelf compileren onder UNIX of Msys in Windows. We gaan voor de oefeningen hier niet verder op in.\nDenkvragen Welke beperkingen zijn er verbonden aan het geserialiseerd database bestand doorgeven aan andere medestudenten? Op welke manier kan je zo verschillende \u0026lsquo;clients\u0026rsquo; verbinden aan één database \u0026lsquo;server\u0026rsquo;? "
},
{
	"uri": "http://localhost:53502/db-course/xml/xsd/",
	"title": "2. XSD",
	"tags": [],
	"description": "",
	"content": "XML Schema Definition Wanneer we met XML communiceren tussen twee verschillende partijen, hebben we natuurlijk ook spelregels nodig. Daarvoor kunnen we een XML schema of XSD gebruiken. Daarin leggen we vast:\nwelke tags wel of niet mogen voorkomen, in welke volgorde die moeten staan, hoe vaak een element mag voorkomen, of een element optioneel of verplicht is, het datatype van het element, welke attributen op een tag toegelaten zijn Ons vorige XML representatie van een collectie boeken kan met volgende XSD beschreven worden:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;xs:schema xmlns:xs=\u0026#34;http://www.w3.org/2001/XMLSchema\u0026#34;\u0026gt; \u0026lt;xs:element name=\u0026#34;boeken\u0026#34; type=\u0026#34;boekenType\u0026#34;/\u0026gt; \u0026lt;xs:complexType name=\u0026#34;boekenType\u0026#34;\u0026gt; \u0026lt;xs:sequence\u0026gt; \u0026lt;xs:element name=\u0026#34;boek\u0026#34; type=\u0026#34;boekType\u0026#34; maxOccurs=\u0026#34;unbounded\u0026#34;/\u0026gt; \u0026lt;/xs:sequence\u0026gt; \u0026lt;/xs:complexType\u0026gt; \u0026lt;xs:complexType name=\u0026#34;boekType\u0026#34;\u0026gt; \u0026lt;xs:sequence\u0026gt; \u0026lt;xs:element name=\u0026#34;titel\u0026#34; type=\u0026#34;xs:string\u0026#34;/\u0026gt; \u0026lt;xs:element name=\u0026#34;auteur\u0026#34; type=\u0026#34;xs:string\u0026#34;/\u0026gt; \u0026lt;xs:element name=\u0026#34;jaar\u0026#34; type=\u0026#34;xs:integer\u0026#34;/\u0026gt; \u0026lt;/xs:sequence\u0026gt; \u0026lt;/xs:complexType\u0026gt; \u0026lt;/xs:schema\u0026gt; Het boeken element, ons root element wordt als eerste beschreven en krijgt een custom type toegekend, namelijk een zelf gedefinieerd type boekenType. Daaronder beschrijven we precies wat een boekenType is. In dit geval is het een complexType. Het bestaat namelijk uit meerdere andere elementen. We geven hier mee dat enkel het element boek mag voorkomen in ons boekType. Wat valt nog op? Dat is de toevoeging van maxOccurs=\u0026quot;unbounded\u0026quot;. Hiermee geven we aan dat dit element ongelimiteerd gebruikt mag worden. De tegenhanger van maxOccurs is minOccurs, door die de waarde 1 mee te geven bijvoorbeeld, maken we een element verplicht. De combinatie kan ook gebruikt worden. Stel dat we een ISBN nummer zouden toevoegen, dan zouden we dat als volgt kunnen doen:\n\u0026lt;xs:element name=\u0026#34;isbn\u0026#34; type=\u0026#34;xs:string\u0026#34; minOccurs=\u0026#34;1\u0026#34; maxOccurs=\u0026#34;1\u0026#34;/\u0026gt; Hierbij geven we dus aan dat het ISBN nummer een verplicht veld is, en ik maar maximaal 1 keer kan voorkomen.\nHet boekType ten slotte heeft ook zijn eigen definitie. Dit type bevat een sequence, dat betekent dat de elementen die gedefinieerd zijn onder het boekType moeten voorkomen in de volgorde dat ze zijn gedefinieerd. De elementen zelf zijn hier primitieve elementen. Daarom krijgen ze reeds bestaande types, zoals string en integer.\nJe kan je XML bestanden laten valideren tegen een XSD schema, door daar zelf logica voor te schrijven. In typische Enterprise applicaties, waarbij XML gebruikt wordt als communicatiemiddel ga je dat steeds willen doen om te verifiëren dat alle data doorgegeven werd op de op voorhand beschreven manier. Of je kan een online validatie tool gebruiken. Hiervoor kan je gedurende deze les deze XSD Validator gebruiken\nOefeningen Maak een XSD schema voor de studenten XML die jullie in de vorige opgave hebben gemaakt. Voeg een nieuw element Gender toe aan XML en XSD. We kunnen ons XSD schema uitbreiden door er ook attributen aan toe te voegen. Laten we een Genre attribuut definiëren op ons boek element.\n\u0026lt;xs:complexType name=\u0026#34;boekType\u0026#34;\u0026gt; \u0026lt;xs:sequence\u0026gt; \u0026lt;xs:element name=\u0026#34;titel\u0026#34; type=\u0026#34;xs:string\u0026#34;/\u0026gt; \u0026lt;xs:element name=\u0026#34;auteur\u0026#34; type=\u0026#34;xs:string\u0026#34;/\u0026gt; \u0026lt;xs:element name=\u0026#34;jaar\u0026#34; type=\u0026#34;xs:integer\u0026#34;/\u0026gt; \u0026lt;/xs:sequence\u0026gt; \u0026lt;xs:attribute name=\u0026#34;genre\u0026#34; type=\u0026#34;xs:string\u0026#34; /\u0026gt; \u0026lt;/xs:complexType\u0026gt; In XML vorm zou dat er dan als volgt uitzien:\n\u0026lt;boek genre=\u0026#34;fantasy\u0026#34;\u0026gt; \u0026lt;titel\u0026gt;The Lost Metal\u0026lt;/titel\u0026gt; \u0026lt;auteur\u0026gt;Brandon Sanderson\u0026lt;/auteur\u0026gt; \u0026lt;jaar\u0026gt;2022\u0026lt;/jaar\u0026gt; \u0026lt;/boek\u0026gt; Validaties We kunnen aan XSD ook nog validatieregels toevoegen die de data-integriteit verzekeren. Hieronder volgen een aantal voorbeelden:\nMinimum en maximumwaarde voor getal \u0026lt;xs:element name = \u0026#34;score\u0026#34;\u0026gt; \u0026lt;xs:simpleType\u0026gt; \u0026lt;xs:restriction base = \u0026#34;xs:integer\u0026#34;\u0026gt; \u0026lt;xs:minInclusive value = \u0026#34;0\u0026#34;/\u0026gt; \u0026lt;xs:maxInclusive value = \u0026#34;100\u0026#34;/\u0026gt; \u0026lt;/xs:restriction\u0026gt; \u0026lt;/xs:simpleType\u0026gt; \u0026lt;/xs:element\u0026gt; Enumeratie van waardes \u0026lt;xs:element name = \u0026#34;Score\u0026#34;\u0026gt; \u0026lt;xs:simpleType\u0026gt; \u0026lt;xs:restriction base = \u0026#34;xs:string\u0026#34;\u0026gt; \u0026lt;xs:enumeration value = \u0026#34;Laag\u0026#34;/\u0026gt; \u0026lt;xs:enumeration value = \u0026#34;Gemiddeld\u0026#34;/\u0026gt; \u0026lt;xs:enumeration value = \u0026#34;Hoog\u0026#34;/\u0026gt; \u0026lt;/xs:restriction\u0026gt; \u0026lt;/xs:simpleType\u0026gt; \u0026lt;/xs:element\u0026gt; Regex \u0026lt;xs:element name = \u0026#34;Naam\u0026#34;\u0026gt; \u0026lt;xs:simpleType\u0026gt; \u0026lt;xs:restriction base = \u0026#34;xs:string\u0026#34;\u0026gt; \u0026lt;xs:pattern value = \u0026#34;[a-z]\u0026#34;/\u0026gt; \u0026lt;/xs:restriction\u0026gt; \u0026lt;/xs:simpleType\u0026gt; \u0026lt;/xs:element\u0026gt; Oefeningen Voeg een attribuut toe aan de studenten XML dat aangeeft of de student een Bachelor of Master volgt. Voeg voor elke student nu ook een lijst van vakken toe. Per vak willen we zien voor hoeveel studiepunten dit meetelt en een score? Voeg dit ook toe in je XML en valideer dit tegen je XSD. "
},
{
	"uri": "http://localhost:53502/db-course/nosql/documentstores/",
	"title": "3. Document stores",
	"tags": [],
	"description": "",
	"content": "0. Data filtering: recap Wat is een \u0026ldquo;mapreduce\u0026rdquo; functie nu weer precies? Weet je nog, in het eerstejaarsvak BES, in Python? Stel, we hebben een array [1, 2, 3, 4] en willen alle elementen verdubbelen. Dat kan erg eenvoudig met een list(map(lambda...)) statement:\nrange = [1, 2, 3, 4] result = list(map(lambda x: x * 2, range)) print(result) Hier gebruikten we een \u0026ldquo;lambda\u0026rdquo; om voor elk element een functie los te laten, die dat element transformeert, ofwel \u0026ldquo;mapt\u0026rdquo;. Python\u0026rsquo;s map() functioneert exact hetzelfde als JavaScript\u0026rsquo;s map()\u0026mdash;evenals reduce() en filter(). Omdat we met een JS-based document store gaan werken is het belangrijk om te weten hoe je bovenstaande principes in JavaScript uitvoert.\nOefening 1 Zoek leerlingen ouder dan 20 en geef hun naam terug. De leerlingen zitten in de volgende JS array: const studenten = [{age: 11, name: 'jos'}, {age: 21, name: 'jef'}].\nOplossing:\nstudenten.filter(function(student) { return student.age \u0026gt; 20 }).map(function(student) { return student.name }) // kan ook met oneliner: studenten.filter(s =\u0026gt; s.age \u0026gt; 20).map(s =\u0026gt; s.name) filtered = filter(lambda student: student.age \u0026gt; 20, studenten) list(map(lambda student: student.name, filtered)) Kopieer bovenstaand voorbeeld in je browser developer console en kijk wat er gebeurt. Het resultaat zou een openklapbare Array [ \u0026quot;jef\u0026quot; ] moeten zijn.\nWe chainen (sequentieel combineren) hier dus filter() en daarna map(). De filter() geeft student Jef terug in een array ([{age: 21, name: 'jef'}]), waarna de map() voor elk element in die array (maar eentje), een transformatie doorvoert: van {age: 21, name: 'jef'} naar 'jef' via student.name.\nOefening 2 Wat is de som van de leeftijden van de studenten? 11 + 21 = 32. Hoe kunnen we dit functioneel schrijven met behulp van een reduce()?\nOplossing:\nstudenten.map(function(student) { return student.age }).reduce(function(age1, age2) { return age1 + age2 }) // kan ook met oneliner: studenten.map(s =\u0026gt; s.age).reduce((a, b) =\u0026gt; a + b) mapped = map(lambda student: student.age, studenten) reduce(lambda age1, age2: age1 + age2, mapped) Kan jij bedenken waarom we hier een map() nodig hebben voor de reduce()?\nMeer informatie: zie Mozilla Developer web docs: map() en reduce/filter. Wanneer je jezelf familiair gemaakt hebt met deze drie functionele (en essentiele!) data manipulatie methodes kan je overgaan tot de hoofdzaak van dit hoofdstuk\u0026mdash;CouchDB en noSQL queries.\n1. Eenvoudige CouchDB Queries Lui in die zetel liggen, en vanaf de bank met gemak query\u0026rsquo;s lanceren? Geen probleem met CouchDB, een open source NoSQL JSON-based document store.\nMango CouchDB heeft een eenvoudige ingebouwde query syntax genaamd Mango. Documentatie op https://github.com/cloudant/mango en http://127.0.0.1:5984/_utils/docs/intro/api.html#documents. Selecteer een database, klik op \u0026ldquo;run a query with Mango\u0026rdquo;:\n{ \u0026#34;selector\u0026#34;: { \u0026#34;year\u0026#34;: 3 } } De selector attribute bepaalt op welke keys er wordt gefilterd. Indexen leggen op zwaar belaste \u0026ldquo;kolommen\u0026rdquo; (keys dus) is in geval van miljarden records zeker geen overbodige luxe.\nMango werkt met een selector syntax (zie documentatie) die impliciet bovenstaande omzet naar {\u0026quot;year\u0026quot;: {\u0026quot;$eq\u0026quot;: 3}}. Er zijn ook andere dollar-based operatoren. Geneste attributes kan je raadplegen met de . separator: {\u0026quot;student.name\u0026quot;: {\u0026quot;eq\u0026quot;: \u0026quot;Joske\u0026quot;}}.\nEen ander voorbeeld: Zoek leerlingen ouder dan 20 en geef hun naam terug:\nfunction(doc) { if(doc.age \u0026gt; 20) { emit(doc._id, doc.name); } } De functie emit(key, value) beslist in welke hoedanigheid een document wordt teruggeven. In dit geval geven we de doc.name terug: de naam van de leerling. We filteren met een simpele if() in de code zelf! Dit kunnen we ook functioneel schrijven in pure JavaScript, los van CouchDB en zijn Mango API, met filter()\u0026mdash;zie de data filtering introductie hierboven.\nNog een ander voorbeeld: van 10 rijen de som teruggeven. In SQL doe je dit met een GROUP BY en COUNT, maar daar bestaat geen alternatief voor in NoSQL, behalve de kracht van JS reduce():\nfunction(keys, values, rereduce) { return values.reduce(function(a, b) { return a + b }) } Opnieuw, hetzelfde kan ook met \u0026ldquo;plain old JavaScript\u0026rdquo;, zoals in de data filtering recap aangegeven ([1, 2, 3, 4].reduce(a, b =\u0026gt; a + b)).\nJe kan in Mango de map() en de reduce() uiteraard ook combineren, net zoals je in JS kan chainen. Hieronder berekenen we bijvoorbeeld de gemiddelde leeftijd van \u0026ldquo;oudere\u0026rdquo; studenten (ouder dan 20 jaar):\nfunction map(doc) { if(doc.age \u0026gt; 20) { emit(doc._id, doc.age); } } function reduce(keys, values, rereduce) { return sum(values) / values.length; } Wat is het verschil tussen function(a, b) {} en (a, b =\u0026gt; ? (Bijna) geen (die jullie moeten kennen). De arrow notatie (=\u0026gt;) is de nieuwe syntax voor anonieme functies aan te maken in JavaScript, en in CouchDB/Mango werken we nog met de oude notatie omdat (1) dit door Couch wordt gegenereerd en (2) de meeste voorbeelden in de documentatie nog zo werken. Dus, function hallokes() { console.log('sup') } is exact hetzelfde als let hallokes = () =\u0026gt; { console.log('sup') }. Zie MDN docs: Arrow function expressions voor meer informatie.\nLET OP:\nreduce() schiet (misschien) in actie als map() nog bezig is. We gaan hier later nog verder op in in NoSQL - Advanced queries.\nDe CouchDB API interface: alles via HTTP(S) curl is een snelle cmd-line tool waarbij je via -X kan meegeven of het over een HTTPs GET, POST, PUT, \u0026hellip; gaat. De DB locatie en poort met het juiste endpoint zijn hier de belangrijkste factoren. Een bepaald document raadplegen doe je met:\ncurl -X GET http://127.0.0.1:5984/[database]/[id] Het resultaat is altijd een geldig JSON object (ook al geef je een ongeldige ID mee): curl -X GET \u0026quot;http://127.0.0.1:5984/courses/aalto-university;bachelor-data-science;professional-development;1\u0026quot;\n{\u0026#34;_id\u0026#34;:\u0026#34;aalto-university;bachelor-data-science;professional-development;1\u0026#34;,\u0026#34;_rev\u0026#34;:\u0026#34;1-f7872c4254bfc2e0e5507502e2fafd6f\u0026#34;,\u0026#34;title\u0026#34;:\u0026#34;Professional Development\u0026#34;,\u0026#34;url\u0026#34;:\u0026#34;https://oodi.aalto.fi/a/opintjakstied.jsp?OpinKohd=1125443391\u0026amp;haettuOpas=-1\u0026#34;,\u0026#34;university\u0026#34;:\u0026#34;Aalto University\u0026#34;,\u0026#34;country\u0026#34;:\u0026#34;Finland\u0026#34;,\u0026#34;category\u0026#34;:\u0026#34;professional\u0026#34;,\u0026#34;ECTS\u0026#34;:5,\u0026#34;year\u0026#34;:1,\u0026#34;optional\u0026#34;:true,\u0026#34;skills\u0026#34;:[\u0026#34;motivate self\u0026#34;,\u0026#34;oral communication\u0026#34;,\u0026#34;self-directed learning\u0026#34;,\u0026#34;self-reflection\u0026#34;,\u0026#34;give/receive feedback\u0026#34;,\u0026#34;set/keep timelines\u0026#34;,\u0026#34;show initiative\u0026#34;],\u0026#34;course\u0026#34;:\u0026#34;Bachelor Data Science\u0026#34;,\u0026#34;lo\u0026#34;:\u0026#34;\u0026lt;br/\u0026gt;Learning Outcomes \u0026lt;br/\u0026gt;Being able to effectively communicate one\u0026#39;s strenghts and professional capacities\u0026lt;br/\u0026gt;Finding one’s own academic and professional interests and taking initiative in one’s own learning\u0026lt;br/\u0026gt;Planning and prototyping one\u0026#39;s own professional development\u0026lt;br/\u0026gt; \u0026lt;br/\u0026gt;Content \u0026lt;br/\u0026gt;The course is integrated to the Aaltonaut program to promote reflection, skill articulation and initiative. The course comprises workshops on different themes related to developing professional skills, independently building a learning portfolio, and taking part in feedback, reflection and goal setting activities.\u0026lt;br/\u0026gt;\u0026lt;br/\u0026gt; \u0026#34;} Indien ongeldig: {\u0026quot;error\u0026quot;:\u0026quot;not_found\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;missing\u0026quot;}.\nIndien geen toegang: {\u0026quot;error\u0026quot;:\u0026quot;unauthorized\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;You are not authorized to access this db.\u0026quot;}. Zie \u0026ldquo;LET OP\u0026rdquo; hieronder\u0026mdash;gebruik het -u argument.\n2. Oefeningen: Voorbereidingswerk Download CouchDB via https://couchdb.apache.org. Download de testdatabase JSON file Maak een nieuwe databases aan via de Fauxton Web-based admin tool. Open CouchDB, ga naar \u0026ldquo;Open Admin Console\u0026rdquo; of surf zelf naar http://127.0.0.1:5984/_utils/. Maak een database aan genaamd \u0026lsquo;courses\u0026rsquo;. Importeer de test JSON met curl in cmdnline: curl -d @dump.db -H \u0026#34;Content-Type: application/json\u0026#34; -X POST http://127.0.0.1:5984/courses/_bulk_docs LET OP:\nBij het aanmaken van een database kan je kiezen tussen partitioned en non-partitioned. Kies hiervoor non-partitioned. Het kan zijn dat CURL een security fout geeft. Bij het installeren van CouchDB moet je een admin username/password meegeven. Voeg aan het einde van je curl commando dit toe: -u username:wachtwoord. Nadien kan je in Fauxton op F5 drukken en zou je dit moeten zien:\nIk heb voor jullie de dump genomen door het omgekeerde (exporteren) te doen:\ncurl -X GET http://127.0.0.1:5984/courses/_all_docs\\?include_docs\\=true \u0026gt; dump.db (Voor mensen op Windows-curl: verander \\ naar /. Ook; bij meegeven van JSON data: enkele quotes \u0026rsquo;\u0026rsquo; vervangen door dubbele \u0026quot;\u0026quot; en dubbele in de enkele escapen met backlash \u0026quot;).\nDaarna volgt wat post-processing (rows wordt docs, elke doc moet in de root array zitten en _rev moet weg) om tot bovenstaande dump.db filte te komen. Dit hebben wij handmatig voor jullie gedaan, zodat de downloadbare file klaar is om te importeren.\n3. Oefeningen met Fauxton/Curl Schrijf een Mango query die cursussen ophaalt waarbij het aantal ECTS punten groter is dan 5. Hoe voer je de query uit oefening 1 uit, zonder de Admin console, maar met curl? Selecteer alle documenten die als skill de waarde self-reflection én show initiative bevatten. Probeer zelf een dump te nemen van je eigen database zoals hierboven beschreven, met het _all_docs endpoint. Wat gebeurt er als je die dump opnieuw wilt importeren via het _bulk_docs endpoint? Maak een nieuwe database genaamd studenten. POST via curl enkele nieuwe documenten, met als template { name: $naam, age: $age, favouriteCourses: [$course1, $course2]} naar deze DB. Controleer in Fauxton of de records correct zijn ingegeven. Verzin zelf wat Mango queries om studenten te filteren. Maak een index aan op age voor je studenten database. Merk op dat indexes, zichtbaar in http://127.0.0.1:5984/_utils/#database/studenten/_index ook worden beschouwd als documenten op zich! Tip: CouchDB heeft een eenvoudige ingebouwde query syntax genaamd Mango. Documentatie op https://github.com/cloudant/mango en https://docs.couchdb.org/en/stable/api/database/find.html. Lees eerst na hoe dit in elkaar zit!\n4. Java Client API Als je geen toegang hebt tot de admin console, of je wenst vanuit een Java programma records weg te schrijven naar een Couch database (of query\u0026rsquo;s uit te voeren), dan heb je de Java API nodig.\nIn principe kan je met eender welke HTTP client REST calls uitvoeren en de responses zelf verwerken. Om het jezelf gemakkelijker te maken, gebruiken we hier ter illustratie LightCouch.\nLees de LightCouch Getting Started guide. Maak een nieuw gradle 6 project met de volgende dependencies:\ndependencies {\rimplementation group: \u0026#39;org.lightcouch\u0026#39;, name: \u0026#39;lightcouch\u0026#39;, version: \u0026#39;0.2.0\u0026#39;\r} In je java/main/resources map dien je een couchdb.properties file aan te maken die verwijst naar de DB URL/poort/naam (zie getting started):\ncouchdb.name=testdb\rcouchdb.createdb.if-not-exist=true\rcouchdb.protocol=http\rcouchdb.host=127.0.0.1\rcouchdb.port=5984\rcouchdb.username=\rcouchdb.password= Vanaf dan is het heel eenvoudig: Maak een CouchDbClient instantie aan. Nu kan je .save(), .shutdown() en .find() uitvoeren. Wat kan je bewaren? POJO (Plain Old Java Objects) klassen\u0026mdash;of in geval van Kotlin, data objects\u0026mdash;waarbij alle members automatisch worden geserialiseerd.\nLightCouch oefeningen Maak zoals hierboven beschreven een nieuw gradle project aan (IntelliJ?) en voeg LightCouch toe als dependency. Probeer naar een nieuwe database enkele objecten weg te schrijven. Gebruik hiervoor een Student klasse met als velden name en age (respectievelijk String en int als type). Controleer of dit is aangekomen in de admin console. Dat ziet er dan hopelijk zo uit: { \u0026#34;_id\u0026#34;: \u0026#34;387a34be062140e4be1390e846242114\u0026#34;, \u0026#34;_rev\u0026#34;: \u0026#34;1-742f438439fd68bc6c67ca0d615f1469\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Joske\u0026#34;, \u0026#34;age\u0026#34;: 10 } Probeer de views en query\u0026rsquo;s even uit. Zoek bijvoorbeeld alle studenten in List\u0026lt;Student\u0026gt; en druk de namen af door middel van println(). Denkvragen Wat is het verschil tussen een key/value store en een document store? Kan je een verklaring geven waarom NoSQL databases zonder DB SCHEME werken, als je weet dat bijvoorbeeld CouchDB plain JSON objecten kan bewaren? Wat is het verschil tussen het bewaren van een JSON object via Curl en het bewaren van een POJO via LightCouc (De Client API verschillen zelf niet in rekening gebracht)? "
},
{
	"uri": "http://localhost:53502/db-course/xml/xpath/",
	"title": "3. XPath",
	"tags": [],
	"description": "",
	"content": "XPath XPath is een taal die we gebruiken om specifieke elementen of attributen te vinden in een XML bestand. Zoals je in de voorbije oefeningen al hebt gemerkt zijn XML bestanden nogal groot en niet zo makkelijk in een oogopslag om alle informatie uit te halen.\nLaten we ons voorbeeldbestand nemen:\n\u0026lt;boeken\u0026gt; \u0026lt;boek genre=\u0026#34;Non-Fiction\u0026#34;\u0026gt; \u0026lt;titel\u0026gt;Mythos\u0026lt;/titel\u0026gt; \u0026lt;auteur\u0026gt;Stephen Fry\u0026lt;/auteur\u0026gt; \u0026lt;jaar\u0026gt;2017\u0026lt;/jaar\u0026gt; \u0026lt;/boek\u0026gt; \u0026lt;boek genre=\u0026#34;biography\u0026#34;\u0026gt; \u0026lt;titel\u0026gt;Scar Tissue\u0026lt;/titel\u0026gt; \u0026lt;auteur\u0026gt;Anthony Kiedis\u0026lt;/auteur\u0026gt; \u0026lt;jaar\u0026gt;2004\u0026lt;/jaar\u0026gt; \u0026lt;/boek\u0026gt; \u0026lt;boek genre=\u0026#34;fantasy\u0026#34;\u0026gt; \u0026lt;titel\u0026gt;The Lost Metal\u0026lt;/titel\u0026gt; \u0026lt;auteur\u0026gt;Brandon Sanderson\u0026lt;/auteur\u0026gt; \u0026lt;jaar\u0026gt;2022\u0026lt;/jaar\u0026gt; \u0026lt;/boek\u0026gt; \u0026lt;/boeken\u0026gt; XPath voorbeelden /\nDit selecteert het meest top level object. In de praktijk geeft dit dus het hele document terug.\n/boeken\nDit zou het boeken element teruggeven. Wat dus ook het hele bestand is.\n/boeken/boek/titel\nGeef alle titels die vallen in de hiërarchie boeken -\u0026gt; boek.\n//titel\nGeef alle titels, eender waar in het document.\n//boek/@genre\nGeef alle genre attributen die gekoppeld zijn aan een boek element.\n//boek[@genre='fantasy']\nGeef alle boek elementen terug die in het genre fantasy vallen.\n//boek/*\nGeef alle subelementen van het boek element.\nOefeningen Hieronder vind je een xml bestand waarop we de XPath oefeningen gaan uitvoeren. Je kan je XPath valideren op deze online XPath evaluator.\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;catalog\u0026gt; \u0026lt;book id=\u0026#34;bk101\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Gambardella, Matthew\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;XML Developer\u0026#39;s Guide\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Computer\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;XML\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;44.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-10-01\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;An in-depth look at creating applications with XML.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk102\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Ralls, Kim\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Midnight Rain\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Fantasy\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;Low Fantasy\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;5.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-12-16\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;A former architect battles corporate zombies, an evil sorceress, and her own childhood to become queen of the world.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk103\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Corets, Eva\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Maeve Ascendant\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Fantasy\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;Dystopian Fantasy\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;5.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-11-17\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;After the collapse of a nanotechnology society in England, the young survivors lay the foundation for a new society.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk104\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Corets, Eva\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Oberon\u0026#39;s Legacy\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Fantasy\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;Dystopian Fantasy\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;5.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2001-03-10\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;In post-apocalypse England, the mysterious agent known only as Oberon helps to create a new life for the inhabitants of London. Sequel to Maeve Ascendant.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk105\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Corets, Eva\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;The Sundered Grail\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Fantasy\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;Dystopian Fantasy\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;5.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2001-09-10\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;The two daughters of Maeve, half-sisters, battle one another for control of England. Sequel to Oberon\u0026#39;s Legacy.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk106\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Randall, Cynthia\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Lover Birds\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Romance\u0026lt;/maingenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;4.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-09-02\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;When Carla meets Paul at an ornithology conference, tempers fly as feathers get ruffled.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk107\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Thurman, Paula\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Splish Splash\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Romance\u0026lt;/maingenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;4.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-11-02\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;A deep sea diver finds true love twenty thousand leagues beneath the sea.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk108\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Knorr, Stefan\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Creepy Crawlies\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Horror\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;Short Stories\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;4.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-12-06\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;An anthology of horror stories about roaches, centipedes, scorpions and other insects.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk109\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Kress, Peter\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Paradox Lost\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Science Fiction\u0026lt;/maingenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;6.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-11-02\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;After an inadvertant trip through a Heisenberg Uncertainty Device, James Salway discovers the problems of being quantum.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk110\u0026#34;\u0026gt; \u0026lt;author\u0026gt;O\u0026#39;Brien, Tim\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Microsoft .NET: The Programming Bible\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Computer\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;.NET\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;36.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-12-09\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;Microsoft\u0026#39;s .NET initiative is explored in detail in this deep programmer\u0026#39;s reference.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk111\u0026#34;\u0026gt; \u0026lt;author\u0026gt;O\u0026#39;Brien, Tim\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;MSXML3: A Comprehensive Guide\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Computer\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;XML\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;36.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-12-01\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;The Microsoft MSXML3 parser is covered in detail, with attention to XML DOM interfaces, XSLT processing, SAX and more.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk112\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Galos, Mike\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Visual Studio 7: A Comprehensive Guide\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Computer\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;Visual Studio\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;49.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2001-04-16\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;Microsoft Visual Studio 7 is explored in depth, looking at how Visual Basic, Visual C++, C#, and ASP+ are integrated into a comprehensive development environment.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;/catalog\u0026gt; Geef alle prijzen weer. Schrijf hiervoor 2 verschillende XPath queries die hetzelfde resultaat geven. Geef de titel van het boek met id bk110. Geef de description van alle boeken. Geef alle non-fictie boeken Lijst alle subgenres van de fictie boeken op. "
},
{
	"uri": "http://localhost:53502/db-course/nosql/mapreduce/",
	"title": "4. Advanced map-red. queries",
	"tags": [],
	"description": "",
	"content": "Deze oefeningen gaan verder op de database die je hebt opgezet in het stuk over document stores. Herinstalleer indien nodig en download de benodigde gegevens via de instructies (2.2 Oefeningen: voorbereidingswerk) in die link. Start voor onderstaande oefeningen de lokale CouchDB Server en de Admin Console (Project Fauxton) opnieuw op.\nZoals ook op de PouchDB docs vermeld staat; zijn mapreduce queries niet altijd nodig:\nDocumenten op _id raadplegen gaat door middel van de Curl REST API Documenten sorteren of simpele queries uitvoeren gaat door middel van de Mango API, zoals reeds gezien. Dit zijn simpele queries, maar die volstaan meestal. Indien de DB store \u0026lt; 100.000 records bevat, zoals de onze, kan je ook simpelweg alles in-memory inladen (bijvoorbeeld in de browser), en met javascript zelf verder filteren: const db = pouchdb.get(); // zoiets // ... const skillsOfBigCourses = db.filter(doc =\u0026gt; { return doc.ECTS \u0026gt; 6 }).map(doc =\u0026gt; { return skills }) // gebruik dit in een template HTML factory Emit Een mapreduce query is in PouchDB uitvoerbaar met db.query() en in CouchDB deel van de _view API. Klik dus op het plusje + bij All Documents en dan op \u0026ldquo;new view\u0026rdquo;:\nDaar kan je een nieuwe \u0026ldquo;map\u0026rdquo; functie aanmaken:\nfunction (doc) { emit(doc._id, 1); } Merk op dat hier de JavaScript syntax geldt. emit() betekent \u0026ldquo;geef als key deze waarde terug voor elk gevonden document\u0026rdquo;. Als je dit verandert naar doc.title wordt er een view aangemaakt die documenten op titel bewaart, om daar zeer snel in te kunnen zoeken. Bovenstaande functie wordt uitgevoerd voor elk document, vandaar de \u0026ldquo;map\u0026rdquo; in de naam. Het zou kunnen dat je filtert, vandaar de \u0026ldquo;reduce\u0026rdquo; in de naam.\nIk kan dus gewoon if() gebruiken, en zo documenten filteren. Alle cursussen gegeven in het tweede jaar of later:\nfunction (doc) { if(doc.year \u0026gt; 1) { emit(doc.title, 1); } } Aggregeren Stel dat ik de totale ECTS punten wil verzamelen van alle Belgische vakken in de database. Dus: eerst filteren op country property, en daarna de som nemen van alle ECTS properties. Hoe doe je zoiets in SQL? Met SUM() en GROUP BY:\nSELECT SUM(ECTS) FROM courses WHERE country = \u0026#34;Belgium\u0026#34; GROUP BY country Hoe doe je zoiets in NoSQL/Mongo/CouchDB? Met Reduce Functions. Je kan in Fauxton bij het bewerken van je view een CUSTOM waarde in de Reduce combobox selecteren:\nWat is die derde rereduce parameter? Volgens de docs:\nReduce functions take two required arguments of keys and values lists - the result of the related map function - and an optional third value which indicates if rereduce mode is active or not. Rereduce is used for additional reduce values list, so when it is true there is no information about related keys (first argument is null).\nRereducen wordt typisch uitgevoerd bij een cluster met verschillende CouchDB Nodes die de data verdeelt. CouchDB ontvangt groepen van inputs in plaats van alles in één vanwege performantie optimalisatie. Dit systeem is visueel uitgelegd in deze primer, maar is voor ons niet van toepassing.\nDus, map functie om te filteren op België:\nfunction (doc) { if(doc.country == \u0026#34;Belgium\u0026#34;) { emit(doc._id, doc.ECTS); } } Door ECTS in emit() mee te geven (als VALUE!) kunnen we in de reduce functie de array values manipuleren. En de reduce functie om de ECTS punten op te tellen:\nfunction (keys, values, rereduce) { return sum(values); } sum() is een ingebouwde CouchDB functie. Dit kan ook manueel op de functionele JS reduce() manier:\nfunction (keys, values, rereduce) { return values.reduce((a, b) =\u0026gt; a + b); } Klik op \u0026ldquo;Run Query\u0026rdquo;. De resultaten zijn de resultaten van de MAP - de Reduce value moet je expliciet enablen door vanboven rechts op \u0026ldquo;Options\u0026rdquo; te klikken, en dan \u0026ldquo;Reduce\u0026rdquo; aan te vinken:\nMerk op dat je met \u0026ldquo;Group Level\u0026rdquo; moet spelen (Op None zetten) om de groepering te doen werken, anders gaat de reduce functie de som nemen op elk indiviudeel document, wat uiteraard geen correct som is.\nMerk op dat reduce functies verschillende keren kunnen worden opgeroepen - en dat reduce reeds kan beginnen voordat map klaar is met zijn werk. Deze maatregelen zijn genomen om vlot om te kunnen gaan met miljarden records, verticaal verspreid over verschillende clusters.\nOefeningen Maak een nieuwe view die documenten teruggeeft die in de titel het woord \u0026ldquo;project\u0026rdquo; bevatten. Werk case-insensistive. Vergeet niet dat het zou kunnen dat sommige documenten géén title property hebben, of deze null is. Wat dan? Schrijf een reduce query die voor alle bovenstaande titels het aantal cursussen weergeeft (enkel het aantal is voldoende) dat explicit op true heeft staan. Schrijf een view die de som neemt van alle ECTS punten van alle cursussen. Doe dit op drie manieren: Met de ingebouwde _sum functie. Met een custom reduce en sum() zoals hierboven in het voorbeeld Met een custom reduce die values.reduce() gebruikt: zie docs Array.prototype.reduce(). Wat is volgens jou het fundamentele verschil tussen deze 3 opties? Op welk gebied? Kopieer je LightCouch oefening van Document stores als een nieuw Java project. Programmeer nu in Java om de view die je hebt gemaakt in oefening 2 op te roepen met dbClient.view(). Zie LightCouch docs. Schrijf een view die het aantal optionele cursussen weergeeft waarvan \u0026ldquo;motivate others\u0026rdquo; een skill is. Denkvragen Waarom is het niet mogelijk in NoSQL databases om een simpele query uit te voeren die bijvoorbeeld auteurs opvraagt ouder dan een bepaalde leeftijd, en dan alle titels per auteur teruggeeft? (Hint: p. 321) Wat is het verschil tussen emit(doc._id, 1) en emit(doc._id, doc.year)? Wat is het verschil tussen map(), reduce() en filter() in Javascript? Hint: Zie Mozilla MDN Web Docs. "
},
{
	"uri": "http://localhost:53502/db-course/nosql/replication/",
	"title": "5. Replication",
	"tags": [],
	"description": "",
	"content": "\rMet replication is het eenvoudig om clusters van clones te maken om de 99.9% uptime te kunnen garanderen, gegeven de juiste loadbalancing instellingen. Als voorbeeld gaan we een open-source JavaScript DB gebruiken genaamd PouchDB. PouchDB draait goed client-side in de browser, en interfacet heel gemakkelijk met zijn inspirator, CouchDB. Met Pouch is het een kwestie van een paar regeltjes code om replication aan te zetten tussen Pouch en de \u0026ldquo;master\u0026rdquo; Couch database, zoals ook zichtbaar op de Pouch website:\nvar db = new PouchDB(\u0026#39;dbname\u0026#39;); db.put({ _id: \u0026#39;dave@gmail.com\u0026#39;, name: \u0026#39;David\u0026#39;, age: 69 }); db.changes().on(\u0026#39;change\u0026#39;, function() { console.log(\u0026#39;Ch-Ch-Changes\u0026#39;); }); db.replicate.to(\u0026#39;http://example.com/mydb\u0026#39;); Replication opzetten Wat is het doel? Replication op te zetten tussen de cursussen database van 2. document stores en de PouchDB JS web-based client. Dat kan op verschillende manieren:\nUnidirectional replication\u0026mdash;1-way traffic master/slave. Eén database is de \u0026ldquo;master\u0026rdquo; waar men op werkt, en de andere is een mirror/backup. Bidirectional replication\u0026mdash;2-way traffic. Data die in beide databases verandert, wordt gesynchroniseerd naar beiden databases. Uiteraard zul je hier aan conflict management moeten doen. Live/Continuous replication\u0026mdash;2-way \u0026ldquo;live\u0026rdquo; traffic dat onmiddellijk zichtbaar is via JS callbacks. Offline replication schematisch voorgesteld. src: pouchdb.com\rZie ook de PouchDB Docs: replication explained. Merk op dat de drie bovenstaande replication principes ook van toepassing zijn voor CouchDB. Om replication te demonstreren hebben we uiteraard een 2de database nodig, vandaar de introductie van PouchDB.\nInterne werking Hoe werkt replication intern? Elk document heeft een _rev property:\nElke change aan elk document wordt bijgehouden. In bovenstaande screenshot zie je als eerste document een _rev value van 3-82ac8d.... Dit is revisie 3. Je kan deze lijst van revisies van één bepaald document ook raadplegen via een REST: zie de documentatie, GET list of revisions.\nEen document ophalen in CouchDB kan via http://127.0.0.1:5984/[db]/[key]. Voeg aan deze url ?revs=true of ?revs_info=true toe en kijk wat er gebeurt.\nDemo JS code Je kan bovenstaande demo code onmiddellijk proberen op https://pouchdb.com: Druk op F12 of CTRL+SHIFT+J (Mac: OPT+CMD+J) of ga naar menu Developer -\u0026gt; Developer Tools van je favoriete browser. In de tab \u0026ldquo;Console\u0026rdquo; wordt je begroet door de PouchDB welkomsttekst. Daar kan je je test commando\u0026rsquo;s in uitvoeren: var db = .... Om te controleren of het record het tot in de database heeft gehaald, zie hieronder, bij tips.\nGebruik in de oefeningen de CDN versie om het jezelf gemakkelijk te maken\u0026mdash;indien cdn.jsdelivr.net niet bereikbaar is download je zelf de laatste versie van de JS file via de PouchDB download pagina. Maak een leeg .html bestand aan en kopieer de Quick Start code over:\n\u0026lt;script src=\u0026#34;//cdn.jsdelivr.net/npm/pouchdb@8.0.1/dist/pouchdb.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; var db = new PouchDB(\u0026#39;my_database\u0026#39;); \u0026lt;/script\u0026gt; Vergeet niet dat je lokale CouchDB waarschijnlijk draait op poort 5984.\nPouchDB, CouchDB, help, wat is het verschil? Pouch is een JavaScript client library voor Node en het Web. Beiden gebruiken Mango, MapReduce Replication, \u0026hellip; technieken. Beiden kan je clusteren, hebben conflict management, compacting, \u0026hellip; Bekijk het zo: Pouch is de (easy-to-setup) Couch van het web. Zie ook: Who\u0026rsquo;s using PouchDB?\nEen uitgewerkt voorbeeld in begeleidende video:\nOefeningen Start CouchDB opnieuw met de bestaande courses db. Stel PouchDB in op unidirectionele replication. Alle LOKALE wijzigingen worden nu bewaard in de remote DB. Schrijf in Javascript ter test een nieuw fictief document weg met db.put(). Vul alle JSON properties in: kijk naar een bestaand document in je Couch database. Maak een nieuw .html bestand aan, en stel een remote URL in om vanuit JS onmiddellijk op de remote DB te kunnen queryen. Gebruik de Mango query API van Pouch om in CouchDB de oefeningen van 2. document stores te implementeren. Opgelet: hier moet je een extra JS file voor includen, pouchdb.find.js, zoals aangegeven in de link, downloadbaar hier en zorg ervoor dat zowel PouchDB als de find versies van dezelfde release komen! Gebruik de Mapreduce query API van Pouch om in CouchDB de oefeningen van 3. advanced map/red. queries te implementeren. Merk op dat voor map en reduce beiden uit te voeren, je een JSON object moet meegeven met beide functies: { map: function(doc) { emit(...); }, reduce: '_count}. Zie docs in link. Maak een nieuw .html bestand aan, en stel continuous replication in. Voeg dan een nieuw document toe in de CouchDB Admin console. Maak in HTML een knop die gewoon records afdrukt via console.log(). Wordt het nieuwe document getoond? Gebruik deze boilerplate: \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/pouchdb@8.0.1/dist/pouchdb.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;button id=\u0026#34;btn\u0026#34;\u0026gt;Print docs\u0026lt;/button\u0026gt; \u0026lt;pre id=\u0026#34;pre\u0026#34;\u0026gt; ... \u0026lt;/pre\u0026gt; \u0026lt;script\u0026gt; function print(doc) { document.querySelector(\u0026#39;#pre\u0026#39;).innerHTML = JSON.stringify(doc); } var db = new PouchDB(\u0026#39;my_database\u0026#39;); // do your setup here function queryDocs() { // do your thing here print(\u0026#39;goed bezig\u0026#39;); } document.querySelector(\u0026#34;#btn\u0026#34;).addEventListener(\u0026#34;click\u0026#34;, queryDocs); \u0026lt;/script\u0026gt; Tips: Wanneer je een item hebt toegevoegd aan je lokale JavaScript database met .put(), maar replication nog niet aan staat, kan het handig zijn om met Chrome/Opera/\u0026hellip; Dev Tools te kijken naar de local storage databases. Deze zijn terug te vinden in de tab \u0026ldquo;Application\u0026rdquo;, bij \u0026ldquo;IndexedDB\u0026rdquo;:\nDe volgende elementen zijn te herkennen in bovenstaande screenshot:\nIk heb een \u0026ldquo;mydb\u0026rdquo; object aangemaakt (DB naam _pouch_mydb) Onder element \u0026ldquo;by-sequence\u0026rdquo; kan je de huidige elementen in de DB raadplegen, zoals bovenstaande demo code waarbij object met naam \u0026ldquo;David\u0026rdquo; werd toegevoegd. Troubleshooting Cross site origin fouten? - Het kan zijn dat je browser, zoals een strict ingestelde Firefox, klaagt over Cross-Origin domains wanneer replication aan staat, omdat die naar 127.0.0.1 gaat, en je browser de .html file aanlevert vanuit file:/// wat technisch gezien niet dezelfde hostname is. Ga naar je CouchDB admin config (klik op tandwieltje), op CORS, en klik \u0026ldquo;enable\u0026rdquo; (all domains). Oplossing 1: gebruik een andere browser. Oplossing 2: disable CORS in de browser (zie artiel). Optie 3: gebruik een python3 webserver om je bestand te serven. Open een terminal en typ python -m http.server in de directory van je html bestand. Ga dan naar http://127.0.0.1:8000/oefening.html (Poort 8000). Indien niet opgelost, ga naar volgende troubleshooting puntje:\nConnecton errors? - Als Pouch bij replication connection errors geeft in de JS Console kan het zijn dat je Couch server te streng staat ingesteld, en hij de requests blokkeert. In dat geval ga je naar Fauxton, klik je op het \u0026ldquo;tandwieltje\u0026rdquo; linkqs, en enable je CORS (Cross Origin Requests):\nAccess denied? - Als je een admin username/password hebt ingesteld dien je dit ook mee te geven met de parameters: new PouchDb(\u0026quot;http://localhost:5984\u0026quot;, { auth: { username: \u0026quot;jef\u0026quot;, password: \u0026quot;lowie\u0026quot;} }). Zie options for remote databases in de PouchDb API manual.\nMijn find() doet niks? - Merk op dat eender welke actie een Promise object teruggeeft. Dat wil zeggen dat de query \u0026ldquo;onderweg\u0026rdquo; is, en als je iets wilt uitvoeren wanneer dit klaar is (een asynchroon proces), moet dit via de Promise API, zoals .then(). Lees hierover in de Mozilla MDN docs.\nIk krijg rare javascript errors? - Is je pouch.min.js en pouch.find.min.js versie dezelfde? D.w.z. zijn de major/minor/revision nummers hetzelfde? Dit staat aangeduid in de eerste regel van de source file. Indien niet, download de correcte versie via de PouchDB Github Releases pagina.\nIk krijg 404 object not found bij put? - Heb je je remote DB opgezet naar een onbestaande database, zoals /hallokes? Die moet je eerst zelf aanmaken in de CouchDB admin pagina! Anders kan je geen PUT commando\u0026rsquo;s op die URL opsturen.\nUncaught in Promise request PUT not supported? - In serviceWorker.js? Ben je op de pouchdb.com website in de console dingen aan het testen? Sommige scripts, zoals deze, vangen PUT commando\u0026rsquo;s op en crashen dan. Je object zal wel correct zijn bewaard, dit mag je negeren.\nDenkvragen Heb je een verschil gemerkt tussen bidirectionele en live replication in PouchDB? Probeer beide instellingen uit en kijk in de Chrome/Opera/Mozilla Dev Tools van je browser naar de uitgaande HTTP requests. Op welk moment gebeurt dit? Welke POST/GET metadata wordt verstuurd? Wat is het verschil tussen in Pouch alle documenten op te vragen en daarna als array MapReduces toe te passen, of dit in de Mango query rechtstreeks te doen? "
},
{
	"uri": "http://localhost:53502/db-course/apis/basics/",
	"title": "API Basics",
	"tags": [],
	"description": "",
	"content": "Layered Application Tiers In software engineering worden applicaties logisch opgesplitst in verschillende \u0026ldquo;tiers\u0026rdquo;. Een typische 3-Tier webapplicatie bestaat uit 3 lagen: de laag die de gebruiker te zien krijgt\u0026mdash;de UI, bestaande uit HTML en CSS, de backend\u0026mdash;een server waar de requests naartoe worden gestuurd en die de aanvragen verwerkt, en een data laag die onze database voorstelt. Onderstaand schema vat dit samen (via Trevor N. Mudge):\nIn de praktijk varieert deze tier benadering van project tot project.\nTot nu toe in dit vak hebben we ons toegelegd op Tier 3: de data laag. Zonder frontend applicatie laag kan een gebruiker echter niet interageren met deze database; er is dus minstens één extra tier nodig.\nOm ons in het vak databases te kunnen focussen op de data en de integratie van de data met de software gaan wij ons toeleggen op Tier 2 + 3. Het web gedeelte valt weg en proberen zoveel mogelijk gebruik te maken van een commandline interface om te concepten uit te werken. In het vak Full Stack Web development duiken gaan we meer in op een mooie interface GUI programmeren. Een simpele 2-tier applicatie is ook wel een client-server applicatie genoemd. In ons geval is de server de database, die in principe op een andere machine kan gedeployed worden. Voor de oefeningen vereenvoudigen we dit systeem door gebruik te maken van een embedded database die in het lokaal geheugen kan draaien.\nWe teren dus op de volgende kennis:\nHet opstellen van Gradle projecten in Java (SES); Databases ontwerpen en koppelen (Databases); GUI interfaces ontwikkelen (FSWEB). Problemen met je JDK versie en Gradle versies? Raadpleeg de Gradle Compatibiility Matrix. Gradle 6.7 of hoger ondersteunt JDK15. Gradle 8.5 of hoger ondersteunt JDK21. Let op met syntax wijzigingen bij Gradle 7+! Je Gradle versie verhogen kan door de URL in gradle/gradlew.properties te wijzigen.\nGradle dependency of Git source control problemen? Grijp terug naar de cursus van SES.\nAPI solutions testen "
},
{
	"uri": "http://localhost:53502/db-course/",
	"title": "Index",
	"tags": [],
	"description": "",
	"content": " Databases Syllabus Lesgevers: Coördinerend Verantwoordelijke: prof. dr. Kris Aerts (kris.aerts@kuleuven.be) assistent lesgever: ing. Arne Duyver (arne.duyver@kuleuven.be) Kantoor: Technologiecentrum Diepenbeek, Groep ACRO. Cursusbeschrijving Dit opleidingsonderdeel focust enerzijds op drie soorten databases:\nrelationele databases de NoSQL-alternatieven XML databases En anderzijds op twee toepassingen:\nprogrammeren van database-gestuurde applicaties via API\u0026rsquo;s een inleiding in Big Data Vereiste voorkennis Basiskennis van een Object-Geörienteerde programmeertaal als Java of C# Basiskennis van het UNIX systeem, werken met commandline Doelstellingen Zie ook Studiegids UHasselt\nDe context en het overzicht worden aangereikt in de eerste lessen van dit vak.\nAls practicum wordt een grotere probleemstelling als project uitgewerkt. Alle aan te leren aspecten van databases komen in dit project aan bod. Studenten kunnen facultatief buiten het practicum extra thematische oefeningen oplossen.\nKalender Zie Mytimetable UHasselt.\n"
},
{
	"uri": "http://localhost:53502/db-course/apis/jdbc/",
	"title": "JDBC - Java Database Connectivity",
	"tags": [],
	"description": "",
	"content": "Java Database Connectivity (JDBC) Hoe verbind ik Java met de DB? JDBC is een interface in de JDK die ons in staat stelt om een connectie te openen naar een database. JDBC is een API: een abstracitelaag of een protocol. Dit betekent dat we met JDBC kunnen verbinden naar eender welke server van eender welke flavor: een Oracle SQL, MSSQL, of SQLite database. De database vendor wordt verborgen achter de JDBC laag. Voor deze oefeningen beperken we ons tot MySQL.\nVoor elke database moet er dus een vendor-specifieke driver als dependency worden toegevoegd. In het geval van MySQL is dit de mysql-jdbc driver, de mysql-jdbc package. JDBC zelf leeft in java.sql en is een integraal onderdeel van de JDK: dit moeten we dus niet apart oplijsten als dependency of downloaden.\ngraph LR;\rJava[Java]\rJDBC[JDBC]\rMYSQL[MySQL-JDBC]\rDB[(MySQL Database)]\rsubgraph Java space\rsubgraph JDK\rJava -.-\u003e JDBC\rend\rJDBC --\u003e MYSQL\rend\rsubgraph DB space\rMYSQL --\u003e DB\rend\rDe mysql-jdbc package zorgt voor de brug tussen onze Java applicatie en de database, maar we spreken die aan via JDBC.\nEnkele belangrijke statements:\nEen connectie naar een database vastleggen: var connection = DriverManager.getConnection(\u0026quot;jdbc:mysql://localhost:3306/\u0026lt;database_name\u0026gt;\u0026quot;, \u0026quot;root\u0026quot;, \u0026quot;\u0026quot;); Wil je meerdere queries tegelijk uitvoeren dan moet je dit ook nog specifiek vermelden in de driver door ?allowMultiQueries=true toe te voegen aan de database url bv: \u0026quot;jdbc:mysql://localhost:3306/\u0026lt;database_name\u0026gt;?allowMultiQueries=true\u0026quot;\nEen SELECT query uitvoeren: var s = connection.createStatement(); var result = s.executeQuery(\u0026quot;...\u0026quot;); var cell = result.getString(\u0026quot;\u0026lt;column_name\u0026gt;\u0026quot;); Een INSERT/UPDATE/\u0026hellip; query uitvoeren (die de structuur of inhoud van de database wijzigt): var s = connection.createStatement(); s.executeUpdate(\u0026quot;...\u0026quot;); Het volgende voorbeeld opent een verbinding naar een DB, maakt een tabel aan, voegt een record toe, en telt het aantal records:\npublic static void createDb() throws SQLException { var connection = DriverManager.getConnection(\u0026#34;jdbc:mysql://localhost:3306/school\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;\u0026#34;); var s = connection.createStatement(); s.executeUpdate(\u0026#34;DROP TABLE IF EXISTS `student`;\u0026#34;); s.executeUpdate(\u0026#34;CREATE TABLE student(nr INT);\u0026#34;); s.executeUpdate(\u0026#34;INSERT INTO student(nr) VALUES(1);\u0026#34;); s.close(); connection.close(); } public static void verifyDbContents() throws SQLException { var connection = DriverManager.getConnection(\u0026#34;jdbc:mysql://localhost:3306/school\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;\u0026#34;); var s = connection.createStatement(); var result = s.executeQuery(\u0026#34;SELECT COUNT(*) as cnt FROM student;\u0026#34;); while (result.next()) { System.out.println(\u0026#34;Assert that number of rows is 1: \u0026#34; + (result.getInt(\u0026#34;cnt\u0026#34;) == 1)); assert result.getInt(\u0026#34;cnt\u0026#34;) == 1; } s.close(); connection.close(); } Gradle dependency: ``\n// https://mvnrepository.com/artifact/mysql/mysql-connector-java implementation \u0026#39;mysql:mysql-connector-java:5.1.6\u0026#39; Merk op dat SQLException een checked exception is die je constant moet meespelen in de method signature of expliciet moet opvangen. Het probleem van een try { } catch { } finally { } block is dat in de finally je ook geen close() kan uitvoeren zonder opnieuw een try block te openen\u0026hellip; Inception!\nHet connection.close() statement moet er voor zorgen dat voor elke request de connection netjes wordt afgesloten. Een database heeft meestal een connection pool van x aantal beschikbare connections, bijvoorbeeld 5. Als een connection per request niet wordt gesloten, heeft de volgende bezoeker van onze website geen enkele kans om zijn search query te lanceren, omdat de database dan zegt dat alle connecties zijn opgebruikt!\nMerk op dat de String jdbc:mysql://localhost:3306/school een connectie met je MariaDB aanmaakt en de meegegeven database, zodat je met PHPmyAdmin data kan inspecteren. Indien je een tabel aanmaakt de eerste keer, gaat dit de tweede keer crashen met table already exists. Houd hier dus rekening mee (e.v.t. met IF NOT EXISTS). Je kan ook een in-memory database aanmaken, die volledig in RAM leeft en bij elke opstart opnieuw wordt aangemaakt, met de String jdbc:sqlite:memory. (Hiervoor gebruiken we dan de sqlite JDBC-connector, hier gaan we in deze cursus echter niet verder op in.)\nWerk je met een andere database maar heb je geen idee hoe die speciale connection string te vormen? Geen probleem, daarvoor dient https://www.connectionstrings.com/. Bijvoorbeeld, een connectie naar de Microsoft Azure cloud kan met de volgende syntax:\nServer=tcp:myserver.database.windows.net,1433;Database=myDataBase;User ID=mylogin@myserver;Password=myPassword;Trusted_Connection=False;Encrypt=True; Het is de connection string die bepaalt welke dependency binding gebruikt wordt! Dit noemen we late binding: er is geen expliciete referentie naar iets van MySQL in de Java code; we werken enkel met JDBC zelf. Als je de vendor driver vergeet toe te voegen als Gradle dependency gebeurt er dit:\nException in thread \u0026#34;main\u0026#34; java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/school\rat java.sql/java.mysql.DriverManager.getConnection(DriverManager.java:702)\rat java.sql/java.mysql.DriverManager.getConnection(DriverManager.java:251)\rat Demo.main(Demo.java:8) In-memory databases (ConStr. jdbc:sqlite:memory), die met een lege database vertrekken, en constant CREATE TABLE() statements issuen, vervuilen je broncode. Als je veel SQL moet uitvoeren is het beter om dit in een .sql bestand te bewaren in src/main/resources en eenmalig in te lezen als SQL met new String(Files.readAllBytes(Paths.g));, om te kunnen uitvoeren via statement.executeUpdate().\nBijvoorbeeld voor onze casus:\nprivate void initTables() throws Exception { Connection connection = DriverManager.getConnection(\u0026#34;jdbc:mysql://localhost:3306/tennisvlaanderen?allowMultiQueries=true\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;\u0026#34;); URI create_tables_path = Objects.requireNonNull(App.class.getClassLoader().getResource(\u0026#34;create_tables.sql\u0026#34;)).toURI(); var create_tables_sql = new String(Files.readAllBytes(Paths.get(create_tables_path))); URI populate_tables_path = Objects.requireNonNull(App.class.getClassLoader().getResource(\u0026#34;populate_tables_with_testdata.sql\u0026#34;)).toURI(); var populate_tables_sql = new String(Files.readAllBytes(Paths.get(populate_tables_path))); System.out.println(create_tables_sql); System.out.println(populate_tables_sql); var s = connection.createStatement(); s.executeUpdate(create_tables_sql); s.executeUpdate(populate_tables_sql); s.close(); connection.close(); } Queries/Objecten in JDBC Stel dat we het eerste voorbeeld van een school database willen uitbreiden en studenten die in de database opgeslagen zijn willen inladen in een Student klasse instantie: van de TABLE STUDENT naar de class Student. In geval van JDBC is dat veel handwerk:\nMaak een verbinding met de database. Voer de SELECT statements uit. Loop door de ResultSet en maak een nieuwe Student instantie aan. Vang alle mogelijke fouten zelf op: wat met lege kolommen, null? Wat met INTEGER kolommen die je wilt mappen op een String property? Om van de huidige resultatenrij naar de volgende te springen in ResultSet gebruikt men de methode next() in een typisch while() formaat:\nvar result = statement.executeQuery(\u0026#34;SELECT * FROM \u0026lt;table_name\u0026gt;\u0026#34;); while(result.next()) { var eenString = result.getString(\u0026#34;\u0026lt;column_name\u0026gt;\u0026#34;); // doe iets! } Zie ook ResultSet Oracle Javadoc.\nAangezien we reeds hebben kennis gemaakt met de (beperkte) API, schakelen we onmiddellijk over naar de oefeningen:\nDemos We gebruiken de student tabel statements uit RDBMS Transacties - Failures \u0026amp; Rollbacks maar nu met MySQL syntax:\n-- Drop tables if they exist DROP TABLE IF EXISTS student; -- Create student table CREATE TABLE student ( studnr INT NOT NULL PRIMARY KEY, naam VARCHAR(200) NOT NULL, voornaam VARCHAR(200), goedbezig BOOL ); -- Insert sample data into student INSERT INTO student (studnr, naam, voornaam, goedbezig) VALUES (123, \u0026#39;Trekhaak\u0026#39;, \u0026#39;Jaak\u0026#39;, 0), (456, \u0026#39;Peeters\u0026#39;, \u0026#39;Jos\u0026#39;, 0), (890, \u0026#39;Dongmans\u0026#39;, \u0026#39;Ding\u0026#39;, 1); We maken hier weer gebruik van Gradle, maar aangezien onze database op onze Windows host draait gaan we geen verbinding kunnen maken via onze WSL. Daarom moeten we eerst nog even Gradle voor windows installeren. De stappen daarvoor vind je hier. (Je kan ook je bestanden aanmaken in je WSL en dan de projectmap kopiëren naar je windows file explorer. Dan kan je de Gradle wrapper voor Windows gebruiken ./gradle.bat)\nAlles in de main Om dingen te doen met de database moeten we dus een aantal stappen doorlopen, die hier beschreven en gecodeerd zijn in een main-method:\npublic static void main(String[] args){ try{ // CONNECT TO MYSQL var connection = DriverManager.getConnection(\u0026#34;jdbc:mysql://localhost:3306/school\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;\u0026#34;); // CREATE THE TABLES var statement = connection.createStatement(); statement.executeUpdate(\u0026#34;DROP TABLE IF EXISTS `student`;\u0026#34;); statement.executeUpdate(\u0026#34;\u0026#34;\u0026#34; CREATE TABLE student( studnr INT NOT NULL PRIMARY KEY, naam TEXT NOT NULL, voornaam TEXT, goedbezig BOOLEAN ); \u0026#34;\u0026#34;\u0026#34;); statement.executeUpdate(\u0026#34;DROP TABLE IF EXISTS log;\u0026#34;); statement.executeUpdate(\u0026#34;\u0026#34;\u0026#34; CREATE TABLE log( id INTEGER NOT NULL PRIMARY KEY AUTO_INCREMENT, date DATETIME DEFAULT CURRENT_TIMESTAMP, foreign_id INT NOT NULL, msg TEXT ); \u0026#34;\u0026#34;\u0026#34;); statement.executeUpdate( \u0026#34;INSERT INTO student(studnr, naam, voornaam, goedbezig) VALUES (123, \u0026#39;Trekhaak\u0026#39;, \u0026#39;Jaak\u0026#39;, 0);\u0026#34;); statement.executeUpdate( \u0026#34;INSERT INTO student(studnr, naam, voornaam, goedbezig) VALUES (456, \u0026#39;Peeters\u0026#39;, \u0026#39;Jos\u0026#39;, 0);\u0026#34;); statement.executeUpdate( \u0026#34;INSERT INTO student(studnr, naam, voornaam, goedbezig) VALUES (890, \u0026#39;Dongmans\u0026#39;, \u0026#39;Ding\u0026#39;, 1);\u0026#34;); statement.close(); //VERIFY DATABASE CONTENT statement = connection.createStatement(); var result = statement.executeQuery(\u0026#34;SELECT COUNT(*) as cnt FROM student;\u0026#34;); while (result.next()){ System.out.println(\u0026#34;Assert that number of rows is 3: \u0026#34;+ (result.getInt(\u0026#34;cnt\u0026#34;) == 3)); assert result.getInt(\u0026#34;cnt\u0026#34;) == 3; } //READ FROM DB statement = connection.createStatement(); result = statement.executeQuery(\u0026#34;SELECT * FROM student;\u0026#34;); while (result.next()){ System.out.println(\u0026#34;Studnr: \u0026#34;+result.getInt(\u0026#34;studnr\u0026#34;)); } //UPDATE DB statement = connection.createStatement(); statement.executeUpdate(\u0026#34;UPDATE student SET voornaam = \u0026#39;Jaqueline\u0026#39; WHERE studnr = 123;\u0026#34;); // OPTIONAL VERIFY UPDATE WITH A READ // Closing all connections correctly result.close(); statement.close(); connection.close(); }catch (Exception e){ e.printStackTrace(); } } Opsplitsen in verschillende methoden Je merkt onmiddellijk dat deze code onoverzichtelijk is, je kan dus beter verschillende methoden aanmaken en dan oproepen in de main-method. We splitsen op in:\npublic static void connectToDbMysql(String connectionString, String user, String pwd) public static void createDbMysql() public static void verifyDbContents() public static ResultSet readFromDb(String query) public static void updateDb(String updateStr) public static void closeAllConnections() Dit laten we als een oefening voor de student.\nOpsplitsen van verantwoordelijkheden in verschillende klasses Wanneer we nu met meerdere databases en meerdere tabellen werken gaat het niet meer overzichtelijk zijn om alles in dezelfde klasse te doen, daarom gaan we verantwoordelijkheden opsplitsen in verschillende klassen:\nConnectionManager klasse die instaat voor de verbinding met de database. \u0026lt;naam\u0026gt;Repository klasse die instaat voor de logica die te maken heeft met queries uitvoeren die over een bepaalde model klasse gaan bv. We hebben een klasse Student en een tabel student dan komt in de StudentRepository alle code om onder andere data uit de studententabel op te halen en om te vormen tot echte student objecten in Java. In de main komt dan alles samen, data ophalen uit database en omvormen tot Java objecten en dan die objecten gebruiken. We maken en testen een klasse StudentRepository die de volgende methode implementeert. Zoals je ziet is het de bedoeling dat de JDBC Connection instance elders wordt aangemaakt, bijvoorbeeld in een aparte ConnectionManager klasse.\npublic class StudentRepository { public StudentRepository(Connection connection); public List\u0026lt;Student\u0026gt; getStudentsByName(String name); } Klik hier voor de volledige implementatie van de StudentRepository klasse 🔽\rpackage be.kuleuven.student; import java.sql.*; import java.util.ArrayList; import java.util.List; public class StudentRepository { private final Connection connection; public StudentRepository(Connection connection) { this.connection = connection; } public List\u0026lt;Student\u0026gt; getStudentsByName(String name){ ArrayList\u0026lt;Student\u0026gt; resultList = new ArrayList\u0026lt;Student\u0026gt;(); try { Statement s = connection.createStatement(); String stmt = \u0026#34;SELECT * FROM student WHERE naam = \u0026#39;\u0026#34; + name + \u0026#34;\u0026#39;\u0026#34;; ResultSet result = s.executeQuery(stmt); while(result.next()) { int studnr = result.getInt(\u0026#34;studnr\u0026#34;); String naam = result.getString(\u0026#34;naam\u0026#34;); String voornaam = result.getString(\u0026#34;voornaam\u0026#34;); boolean goedbezig = result.getBoolean(\u0026#34;goedbezig\u0026#34;); resultList.add(new Student(studnr, naam, voornaam, goedbezig)); } s.close(); } catch(Exception e) { throw new RuntimeException(e); } return resultList; }; } Klik hier voor de volledige implementatie van de Student klasse 🔽\rpackage be.kuleuven.student; import java.util.Objects; public class Student { private int studnr; private String naam,voornaam; private boolean goedBezig; public Student(){ } public Student(int studnr, String naam, String voornaam, boolean goedBezig) { this.studnr = studnr; this.naam = naam; this.voornaam = voornaam; this.goedBezig = goedBezig; } public int getStudnr() { return studnr; } public void setStudnr(int studnr) { this.studnr = studnr; } public String getNaam() { return naam; } public void setNaam(String naam) { this.naam = naam; } public String getVoornaam() { return voornaam; } public void setVoornaam(String voornaam) { this.voornaam = voornaam; } public boolean isGoedBezig() { return goedBezig; } public void setGoedBezig(boolean goedBezig) { this.goedBezig = goedBezig; } @Override public String toString() { return \u0026#34;Student{\u0026#34; + \u0026#34;studnr=\u0026#34; + studnr + \u0026#34;, naam=\u0026#39;\u0026#34; + naam + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, voornaam=\u0026#39;\u0026#34; + voornaam + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, goedBezig=\u0026#34; + goedBezig + \u0026#39;}\u0026#39;; } @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Student student = (Student) o; return studnr == student.studnr \u0026amp;\u0026amp; Objects.equals(naam, student.naam) \u0026amp;\u0026amp; Objects.equals(voornaam, student.voornaam) \u0026amp;\u0026amp; Objects.equals(goedBezig, student.goedBezig); } @Override public int hashCode() { return Objects.hash(studnr, naam, voornaam, goedBezig); } } Klik hier voor de volledige implementatie van de ConnectionManager klasse 🔽\rpackage be.kuleuven; import java.nio.file.Files; import java.nio.file.Paths; import java.sql.*; public class ConnectionManager { private Connection connection; private String connectionString; public ConnectionManager(String connectionString) { this.connectionString = connectionString; try { connection = DriverManager.getConnection(connectionString); connection.setAutoCommit(false); initTables(); verifyTableContents(); } catch (Exception e) { System.out.println(\u0026#34;Db connection handle failure\u0026#34;); e.printStackTrace(); throw new RuntimeException(e); } } public Connection getConnection() { return connection; } public String getConnectionString() { return connectionString; } public void flushConnection() { try { connection.commit(); connection.close(); } catch (SQLException e) { throw new RuntimeException(e); } } public void initTables() throws Exception { String sql = new String(Files.readAllBytes(Paths.get(\u0026#34;src/main/resources/dbcreate.sql\u0026#34;))); System.out.println(sql); Statement s = connection.createStatement(); s.executeUpdate(sql); s.close(); } public void verifyTableContents() throws SQLException { Statement s = connection.createStatement(); ResultSet result = s.executeQuery(\u0026#34;SELECT COUNT(*) as cnt FROM student\u0026#34;); assert result.getInt(\u0026#34;cnt\u0026#34;) == 3; } } Klik hier voor een voorbeeld van de Main klasse waar we bovenstaande klassen gebruiken 🔽\rpackage be.kuleuven; import be.kuleuven.student.Student; import be.kuleuven.student.StudentRepository; import java.sql.*; import java.util.List; public class Main { private static Statement statement = null; private static ResultSet result = null; public static void main(String[] args) throws SQLException { ConnectionManager cm = new ConnectionManager(\u0026#34;jdbc:mysql://localhost:3306/school\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;\u0026#34;); cm.flushConnection(); Connection connection = cm.getConnection(); StudentRepository studentRepository = new StudentRepository(cm.getConnectionString()); List\u0026lt;Student\u0026gt; result = studentRepository.getStudentsByName(\u0026#34;Jaak\u0026#34;); for (Student s: result) { System.out.println(s); } } } Enkele vragen/oefeningen:\nBreid de StudentRepository-klasse uit met de volgende methoden (CREATE, READ, UPDATE, DELETE = CRUD): public class StudentRepository { public StudentRepository(Connection connection); public List\u0026lt;Student\u0026gt; getStudentsByName(String name); public List\u0026lt;Student\u0026gt; getStudentsByStudnr(int nr) public void saveNewStudent(Student student); public void updateStudent(Student student); public void deleteStudentByStudnr(int nr); } Hoe zou je bovenstaande StudentRepository unit (integratie) testen, zonder de \u0026ldquo;productie database\u0026rdquo; op te vullen met testdata? (Hint: kijk naar het constructor argument). Hoe kan je getStudentsByName() testen zonder de volgende oefening afgewerkt te hebben, die nieuwe studenten bewaren pas mogelijk maakt? Breid dit uit met saveNewStudent(Student). Breid dit uit met updateStudent(Student). Wat moet je doen als deze student nog niet in de database zit? Welke gegevens update je wel en welke niet? Merk op dat elke keer als je je project opstart je geen CREATE TABLE student kan uitvoeren als je een file-based SQLite bestand hanteert: eens de tabel is aangemaakt geeft een nieuwe create foutmeldingen. DROP TABLE IF EXISTS student; lost dit op, maar daardoor ben je ook altijd je data kwijt. Hoe los je dit probleem op? Stel dat een Student is ingeschreven in een Vak met properties naam (vb. \u0026ldquo;databases\u0026rdquo;) en ects (vb. 4). Maak een VakRepository om nieuwe vakken te bewaren. Hoe link je de Student klasse met de Vak klasse? wat verandert er in de query van getStudentsByName()? BELANGRIJK:\nexecuteUpdate() van een Statement is erg omslachtig als je een string moet samenstellen die een INSERT query voorstelt (haakjes, enkele quotes, \u0026hellip;). Wat meer is, als de input van een UI komt, kan dit gehacked worden, door zelf de quote te sluiten in de string. Dit noemt men SQL Injection, en om dat te vermijden gebruik je in JDBC de prepareStatement() methode. Zie JDBC Basics: Prepared Statements. De String die je meegeeft bevat in de plaats van parameters een vraagteken: INSERT INTO STUDENT(bla, bla) VALUES(?, ?). Die parameters vul je daarna aan met preparedStatement.setString() of setInt(). Op die manier is de code zowel netjes als injectie-vrij! Als je data wenst op te halen dat is verspreid over verschillende tabellen, is de kans groot dat een JOIN SQL statement nodig is. Probeer eerst de query te schrijven in de PhpMyAdmin tool. De Java objecten opvullen is de laatste taak. Bijvoorbeeld:\n... try { String stmt = \u0026#34;INSERT INTO student(naam, voornaam, studnr, goedbezig) VALUES (?, ?, ?, ?)\u0026#34;; System.out.println(stmt); PreparedStatement prepared = connection.prepareStatement(stmt); prepared.setString(1, \u0026#34;Verboven\u0026#34;); prepared.setString(2, \u0026#34;Mark\u0026#34;); prepared.setInt(3, 666); prepared.setBoolean(4, false); prepared.execute(); prepared.close(); } catch(SQLException ex) { throw new RuntimeException(ex); } ... Jdbc met SQLite Een SQLite database kan handig zijn omdat een lokale .db-file al als database kan dienen wat de overhead van moeilijke connecties kan verminderen. Hiervoor moeten we dan een aantal dingen aanpassen:\nDe driver dependency wordt nu: implementation 'org.xerial:sqlite-jdbc:3.42.0.0' De Connection met een lokale database file kan je dan maken met: var connection = (Connection) DriverManager.getConnection(\u0026quot;jdbc:sqlite:mydatabase.db\u0026quot;); Indien de databasefile nog niet bestaat wordt deze aangemaakt. Let op! De import van connection mag nu niet de import zijn van de Mysql dependency maar wordt: import java.sql.Connection; Let op dat je nu ook correcte SQLite syntax gebruikt in je queries, maar voor de rest zal alles gelijkaardig werken. EER-schema/database mapping naar Java Objects Om dit te verduidelijken en in te oefenen gaan we de demo database wat uitbreiden zodat er ook one-to-many en many-to-many relationships in voorkomen. We voegen opleidingen toe en elke student volgt één opleiding en een opleiding heeft dus meerdere studenten. We voegen ook vakken toe wat een many-to-many relatie oplevert aangezien een student meerdere vakken kan volgen en een vak meerdere studenten kan hebben.\nKlik hier voor de sql code van deze uitgebreidere database🔽\rDROP TABLE IF EXISTS student_volgt_vak; DROP TABLE IF EXISTS student; DROP TABLE IF EXISTS vak; DROP TABLE IF EXISTS opleiding; CREATE TABLE opleiding( id INT NOT NULL PRIMARY KEY, opleidingsnaam VARCHAR(200) NOT NULL ); CREATE TABLE student( studnr INT NOT NULL PRIMARY KEY, naam VARCHAR(200) NOT NULL, voornaam VARCHAR(200), goedbezig BOOLEAN, opleiding INT DEFAULT NULL, FOREIGN KEY (opleiding) REFERENCES opleiding(id) ); CREATE TABLE vak( vaknr INT NOT NULL PRIMARY KEY, vaknaam VARCHAR(200) NOT NULL, opleiding INT DEFAULT NULL, FOREIGN KEY (opleiding) REFERENCES opleiding(id) ); CREATE TABLE student_volgt_vak( id INT AUTO_INCREMENT PRIMARY KEY, student INT, vak INT, FOREIGN KEY (student) REFERENCES student(studnr), FOREIGN KEY (vak) REFERENCES vak(vaknr) ); INSERT INTO opleiding(id, opleidingsnaam) VALUES (1, \u0026#39;IIW\u0026#39;); INSERT INTO student(studnr, naam, voornaam, goedbezig, opleiding) VALUES (123, \u0026#39;Trekhaak\u0026#39;, \u0026#39;Jaak\u0026#39;, 0, 1); INSERT INTO student(studnr, naam, voornaam, goedbezig, opleiding) VALUES (456, \u0026#39;Peeters\u0026#39;, \u0026#39;Jos\u0026#39;, 0, 1); INSERT INTO student(studnr, naam, voornaam, goedbezig, opleiding) VALUES (890, \u0026#39;Dongmans\u0026#39;, \u0026#39;Ding\u0026#39;, 1, NULL); INSERT INTO vak(vaknr, vaknaam, opleiding) VALUES (1, \u0026#39;DAB\u0026#39;, 1); INSERT INTO vak(vaknr, vaknaam, opleiding) VALUES (2, \u0026#39;SES\u0026#39;, 1); INSERT INTO vak(vaknr, vaknaam, opleiding) VALUES (3, \u0026#39;FSWEB\u0026#39;, 1); INSERT INTO student_volgt_vak(student, vak) VALUES (123, 1); INSERT INTO student_volgt_vak(student, vak) VALUES (123, 2); INSERT INTO student_volgt_vak(student, vak) VALUES (123, 3); INSERT INTO student_volgt_vak(student, vak) VALUES (456, 1); INSERT INTO student_volgt_vak(student, vak) VALUES (456, 2); INSERT INTO student_volgt_vak(student, vak) VALUES (890, 1); Hoe kan je die relaties nu zichtbaar maken in Java. Dit is vrij eenvoudig, een Student kan meerdere vakken volgen dus krijgt de student klasse een Lijst met vakken. Een student behoort ook tot een Opleiding, dus die opleiding wordt ook een datamember voor Student. Analoog zullen de klassen Vak en Opleiding een lijst van studenten hebben en zal een vak ook een opleiding als datamember hebben.\nNu zal je zeker zeggen maar zijn we dan niet veel data aan het dupliceren en is dat niet waarom we een SQL database gebruiken. Dan ben je helemaal correct. Het verschil met de Java klassem/objecten is dat we enkel die objecten aanmaken die we op dat moment nodig hebben en die halen we uit \u0026hellip; je raad het al: de database. Dus het is volledig ok om zoveel data in een object op te slaan omdat we nooit alle data van de database in Java Objeten omvormen, we weten op voorhand bijvoorbeeld welke student we willen bekijken en kunnen dus specifiek voor die student een object aanmaken en de rest blijft gewoon in de database staan tot we het nodig hebben!\nGrotere oefening Breid de demos van hierboven uit met alle data van de nieuwe databas:\nBreid de Student klasse uit met een lijst van vakken en een opleiding. // Template van de klasse Student public class Student { private int studnr; private String voornaam, achternaam; private boolean goedBezig; private Opleiding opleiding; private ArrayList\u0026lt;Vak\u0026gt; vakken; // Constructors // Getters en Setters // To String // Equals // Hash } Maak een klasse voor Vak en Opleiding. // Template van de klasse Vak public class Student { private int vaknr; private String naam; private Opleiding opleiding; private ArrayList\u0026lt;Student\u0026gt; studenten; // Constructors // Getters en Setters // To String // Equals // Hash } // Template van de klasse Opleiding public class Student { private String naam; private ArrayList\u0026lt;Student\u0026gt; inschrijvingen; // Constructors // Getters en Setters // To String // Equals // Hash } Voorzie nu voor de verschillende klassen corresponderende Repository-klassen waar alle logica in te staan komt om de data over de verschillende klassen uit de database te halen en om te vormen tot Java objecten. (Je moet dus je StudentRepository-klasse aanpassen, een VakRepository-klasse en een OpleidingRepository-klasse aanmaken) Om de lijsten op te stellen kan je best van handige SQL-queries gebruik maken. Hier vind je enkele voorbeelden: -- Krijg alle studenten die behoren tot een opleiding (vervang ? door een opleiding id) SELECT s.* FROM student s WHERE s.opleiding = ?; -- Krijg alle vakken waarvoor een specifieke student is ingeschreven (vervang ? door een studnr) SELECT v.* FROM student_volgt_vak svv JOIN vak v ON svv.vak = v.vaknr WHERE svv.student = ?; -- Krijg alle studenten die behoren tot een vak (vervang ? door een vaknr) SELECT s.* FROM student_volgt_vak svv JOIN student s ON svv.student = s.studnr WHERE svv.vak = ?; Maak van je App.java een soort command line administratie systeem waarmee je een aantal dingen kan doen (Zorg er natuurlijk voor dat alle wijzigingen ook doorgevoerd worden in de database): voor een gegeven student opvragen voor welke vakken hij/zij is ingeschreven. voor een gegeven student opvragen voor welke opleiding hij/zij is ingeschreven. voor een gegeven vak opvragen welke studenten ingeschreven zijn. voor een gegeven opleiding opvragen welke studenten ingeschreven zijn. studenten uitschrijven voor een vak. studenten inschrijven voor een vak. studenten uitschrijven voor een opleiding. studenten inschrijven voor een opleiding. studenten, vakken en opleidingen aanmaken. "
},
{
	"uri": "http://localhost:53502/db-course/apis/jdbi/",
	"title": "JDBI - Java DataBase Interface v3",
	"tags": [],
	"description": "",
	"content": "Queries/Objecten in Jdbi 3 Jdbi (Java DataBase Interface v3) is een lightweight library geschreven bovenop JDBC. Het gebruikt dus de interne Java API om te communiceren tussen de database en de Java applicatie. Echter, het maakt het leven voor ons als ontwikkelaar op heel wat vlakken véél aangenamer: waar JDBC eerder database-driven en dialect-afhankelijk is, is Jdbi eerder user-driven en met behulp van plugins dialect-onafhankelijk.\nJDBI3 is opgedeeld in modules, waarvan wij de volgende drie gaan gebruiken:\njdbi3-core (altijd nodig) - voor JDBC zit dit in de JDK. jdb3-sqlobject - voor de eenvoudige mapping naar Plain Old Java Objects (POJOs) Nog steeds je mysql driver: implementation 'mysql:mysql-connector-java:8.0.33' Voor SQLite heb je ook nog volgende implementation nodig jdbi3-sqlite.\nimplementation \u0026#39;mysql:mysql-connector-java:8.0.33\u0026#39; // JDBI implementation \u0026#39;org.jdbi:jdbi3-core:3.45.0\u0026#39; implementation \u0026#39;org.jdbi:jdbi3-sqlobject:3.45.0\u0026#39; Met JDBI3 wordt op de volgende manier Java met de DB verbonden:\ngraph LR;\rJava[Java]\rJdbi[Jdbi3-core]\rJDBC[JDBC]\rJMYSQL[Jdbi3-MySQL]\rMYSQL[MySQL-JDBC]\rDB[(MyuSQL Database)]\rsubgraph Java space\rJava --\u003e Jdbi\rJdbi --\u003e JDBC\rJdbi --\u003e JMYSQL\rJMYSQL -.-\u003e MYSQL\rJDBC -.-\u003e MYSQL\rend\rsubgraph DB space\rMYSQL --\u003e DB\rend\rEr komt dus één blokje bij tussen Java en JDBC: we gebruiken niet langer de ingebouwde JDK interfaces maar rechtstreeks de jdbi-core dependency die via JDBC de MySQL connectie maakt.\nOm voorgaand JDBC demo (met enkel een simpele student) te implementeren in Jdbi3 hebben we eerst een extractie van een interface nodig voor de repository acties, zodat we snel kunnen switchen tussen onze verschillende implementaties:\npublic interface StudentRepository { List\u0026lt;Student\u0026gt; getStudentsByName(String student); void saveNewStudent(Student student); void updateStudent(Student student); } Nu kan StudentRepositoryJdbcImpl (hernoem bovenstaande) en onze nieuwe StudentRepositoryJdbi3Impl de interface implements-en. Afhankelijk van een instelling bijvoorbeeld kunnen we switchen van SQL leverancier, zolang de code overal de interface gebruikt.\ngraph LR;\rMain[Controlller]\rInterface{StudentRepository}\rJdbc[StudentRepositoryJdbcImpl]\rJdbi[StudentRepositoryJdbi3Impl]\rMain --\u003e Interface\rInterface --\u003e Jdbc\rInterface --\u003e Jdbi\rJDBC vs Jdbi3 Geen idee waar te beginnen? Hier: http://jdbi.org/\n1. Connection openen In plaats van JDBC\u0026rsquo;s DriverManager.getConnection() om de Connection instance te bootstrappen, gebruiken wij gewoon Jdbi.create() met ook drie parameters, namelijk dezelfde ConnectionString, user en password.\nJdbi jdbi = Jdbi.create(connectionString, username, password); 2. Query uitvoeren In plaats van de vervelende checked SQLExceptions en de createStatement() code, heb je nu de keuze om ofwel de Fluent API te gebruiken:\nreturn jdbi.withHandle(handle -\u0026gt; { return handle.createQuery(\u0026#34;SELECT * FROM student WHERE naam = :naam\u0026#34;) .bind(\u0026#34;naam\u0026#34;, student) .mapToBean(Student.class) .list(); }); Merk op dat Jdbi3 er voor kan zorgen dat de resultaten van je query automatisch worden vertaald naar een Student instantie door middel van bean mapping: de mapToBean() methode. Die gaat via reflectie alle kolomnamen 1-op-1 mappen op properties van je object dat je wenst te mappen (Je kolomnamen moeten dan wel overeenkomen met de attribuut namen van je Java Klasse). Er zijn ook nog andere mogelijkheden, zoals mappen op een HashMap, ea:\n"
},
{
	"uri": "http://localhost:53502/db-course/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]