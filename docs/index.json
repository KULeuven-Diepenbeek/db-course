[
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/sql/rdbms-basics/",
	"title": "1. Database Basics",
	"tags": [],
	"description": "",
	"content": "Een database is niet meer dan een verzameling van gegevens. Een DBMS (DataBase Management System) is de software waarmee databases beheerd of aangemaakt kunnen worden.\n1. Waarom een database gebruiken? Een database wordt ook maar gewoon opgeslagen op een file system. Dus waarom kan ik dan niet zelf files gebruiken om mijn data op te slaan?\nDatabases bieden een aantal key features:\nPerformant (index management) Betere integratie met andere applicaties Uniform DBMS voor bewerken of ophalen van data Concurrency ondersteuning Security \u0026amp; Privacy van data \u0026hellip; In het tweedejaarsvak Besturingssystemen en C leerde je dat IO manipulatie heel dure operaties zijn. Een erg groot bestand openen of een seek() operatie uitvoeren daarop, duizenden bestanden tegelijkertijd openen voor data access, \u0026hellip;\u0026mdash;allemaal voorbeelden van nadelen waar een database de oplossing kan bieden. Achterliggend werkt het DBMS systeem nog steeds met files, maar dat is supergeoptimaliseerd door bijvoorbeeld gebruik te maken van verschillende niveaus van caching, file chunking, gedistribueerde modellen, \u0026hellip; De theorie en implementatie van een DBMS gaan we niet behandelen in deze cursus: de focus ligt op het gebruik van bestaande systemen.\n2. Database Model De data die zich in een database bevindt wordt op een specifieke manier opgeslagen. De structuur waarop deze data bijgehouden wordt, noemen we het database model.\nEen database model bestaat uit meerdere data modellen. Een data model beschrijft één specifiek object.\nWe zien hetzeflde eigenlijk terug als we denken aan Java of Kotlin. We definiëren hoe een klasse eruit ziet. Bijvoorbeeld volgende klasse:\ndata class Book(val isbn: string, val title: string, val author: string, val price: double) public class Book { String isbn; String title; String author; double price; public Book(isbn, title, author, price) { this.isbn = isbn; this.title = title; this.author = author; this.price = price; } } Dit kunnen we ook in een database bepalen. Daar zou het data model van de tabel Book er bijvoorbeeld als volgt kunnen uitzien:\nclassDiagram\rclass Book{\risbn: NVARCHAR(50)\rtitle: NVARCHAR (500)\rauthor: NVARCHAR (500)\rprice: DECIMAL(10,4)\r}\rNet als we in code state kunnen hebben wanneer we onze klasses instantiëren:\nvar book = Book(\u0026#34;0765326353\u0026#34;, \u0026#34;The Way of Kings\u0026#34;, \u0026#34;Brandon Sanderson\u0026#34;, 24.99) var book = new Book(\u0026#34;0765326353\u0026#34;, \u0026#34;The Way of Kings\u0026#34;, \u0026#34;Brandon Sanderson\u0026#34;, 24.99); Zo kunnen we ook state hebben in onze database:\nisbn title author price 0765326353 The Way of Kings Brandon Sanderson 24.99 Elk data model kan een aantal properties bevatten, zoals bovenstaande isbn en title, waarbij een type moet gedefiniëerd worden, zoals bovenstaande NVARCHAR(x). Dit zijn datatype namen die specifiek zijn voor elk DBMS.\nIn de oefeningen gaan wij SQLite gebruiken: zie ook datatypes in SQLite. SQLite\u0026rsquo;s types zijn loosely typed, wat wil zeggen dat er geen verschil is tussen VARCHAR (MSSQL\u0026rsquo;s ASCII) en NVARCHAR (MSSQL\u0026rsquo;s Unicode, UTF-16). Intern worden beide types gemapped naar TEXT. Raadpleeg dus telkens de manual om te controleren welke DBMS welke types ondersteund, en wat deze precies betekenen! Een Java/Kotlin String mapt dus niet altijd 100% op een RDBMS teksttype.\nEen voorbeeld van een simpel database model voor de inventaris van een bibliotheek zou er ongeveer als volgt kunnen uitzien:\nclassDiagram\rBook \"0..*\" --\u003e \"1..*\" Genre\rBook \"1..*\" --\u003e \"1\" Author\rclass Author{\rid: INT\rname: NVARCHAR\rfirstName: NVARCHAR\r}\rclass Genre{\rid: INT\rdescription: NVARCHAR\r}\rclass Book{\risbn: NVARCHAR\rtitle: NVARCHAR\rauthor: INT\rprice: DECIMAL\rgenre: INT\r}\rMerk op dat we hier relaties gebruiken: de DBMS systemen die we eerst behandelen, SQL-varianten, zijn RDBMS systemen: relationele database management systemen. De author in Book is een nummer dat verwijst naar de id van Author in een ander model of tabel. Op deze manier is het mogelijk om, voor elke rij in Author, meerdere Book rijen aan te maken:\ndata class Author(val id: int, val name: string, val books: List\u0026lt;Book\u0026gt;) public class Author { private final int id; private final String name; private final List\u0026lt;Book\u0026gt; books; public Author(int id, int name) { this.id = id; this.name = name; this.books = new ArrayList\u0026lt;\u0026gt;(); } } "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/sql-ddl-dml/ddl/",
	"title": "1. DDL",
	"tags": [],
	"description": "",
	"content": "Data Defintion Language is de taal die we gebruiken om de structuur van onze database te veranderen. We kunnen hiermee tabellen aanmaken, wijzigen of verwijderen. Maar ook indexen, views, triggers of stored procedures worden hiermee aangemaakt.\nZowat elke RDBMS heeft tooling om DDL te doen via een handige interface, in plaats van dit zelf uit te schrijven. In de praktijk ga je waarschijnlijk met beiden in contact komen. We gaan DB Browser for SQLite gebruiken tijdens onze lessen.\nKijk naar de Chinook database en maak een schematische voorstelling van hoe deze database eruit ziet. Je kan hiervoor Mermaid gebruiken, of een eigen tool of pen en papier.\nTabellen aanmaken en wijzigen Met DDL definiëer je structuur in SQL. Met DML wijzig of manipuleer je de inhoud ervan. De Chinook database bevat natuurlijk reeds tabellen, maar alles begint met een CREATE TABLE statement. Je kan in SQLite Browser rechtsklikken op tabellen en Copy Create Statement kiezen om te reverse-engineeren hoe de tabellen aangemaakt werden.\nBijvoorbeeld, voor albums:\nCREATE TABLE \u0026#34;albums\u0026#34; ( [AlbumId] INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL, [Title] NVARCHAR(160) NOT NULL, [ArtistId] INTEGER NOT NULL, FOREIGN KEY ([ArtistId]) REFERENCES \u0026#34;artists\u0026#34; ([ArtistId]) ON DELETE NO ACTION ON UPDATE NO ACTION ) Rekening houdend met de vereenvoudigde datatypes van SQLite, zou je het zelf waarschijnlijk ongeveer zo schrijven:\nCREATE TABLE album ( AlbumId INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL, Title TEXT NOT NULL, ArtistId INTEGER NOT NULL, FOREIGN KEY ArtistId REFERENCES artists (ArtistId) ) De NO ACTION statements zijn nutteloos. Namen hoeven, afhankelijk van het dialect, al dan niet escaped als [naam] of \u0026quot;naam\u0026quot;. Merk ook op dat bovenstaande SQL zal falen als de tabel artists niet eerst gemaakt wordt, anders kan de DB geen foreign key constraint controle uitvoeren. Meerdere statements worden gebruikelijk gescheiden door puntkomma ;.\nMerk op dat in SQL DDL we keywords met HOOFDLETTER schrijven en tabel of kolomnamen met kleine letter.\nProbleem met je structuur? Geen probleem: DROP TABLE album. Als hier data in zit ben je die ook onherroepelijk kwijt! Kolom vergeten? Geen probleem: ALTER TABLE album ADD COLUMN blah TEXT. Kolom te veel? Geen probleem: ALTER TABLE album DROP COLUMN blah. Not null constraint vergeten? Geen probleem: ALTER TABLE album ALTER COLUMN blah NOT NULL. Oei, syntaxfoutje? SQLite ondersteunt geen alter in alter, andere vendors wel. Check constraint vergeten? Geen probleem: ALTER TABLE album ADD CONSTRAINT my_constraint CHECK(len(blah) \u0026gt; 9) Oei, syntaxfoutje? Zelfde probleem\u0026mdash;enkel op te lossen door DROP en re-create. De CREATE en DROP statements kunnen ook gebruikt worden\u0026mdash;afhankelijk van de compatibiliteit van je RDBMS\u0026mdash;om indexen, aliases, tablespaces, synoniemen, sequenties, \u0026hellip; aan te maken en te verwijderen.\nMaak twee nieuwe tabellen aan: een licenses tabel, die per album (en dus ook artiest) licenties en hun kostprijs opslaat, en een memorabelia tabel die merchandise voor artiesten bevat om te verkopen. Denk goed na over het gebruik van constraints. Voeg daarna met ALTER TABLE kolommen toe om het (variërend) BTW percentage voor beide tabellen te bewaren.\nViews aanmaken Een view is eigenlijk een specifieke query die we een vaste naam geven.\nAls ik een view wil maken van alle tracks van het Rock genre, dan doe ik dat als volgt:\nCREATE VIEW rock_tracks AS SELECT * FROM tracks WHERE GenreId = 1 Vanaf dit punt kan ik in een nieuwe query het volgende uitvoeren:\nSELECT * FROM rock_tracks Merk op dat we vaak geen idee hebben welke ID het genre Rock heeft:\nSELECT * FROM genres WHERE Name = \u0026#39;Rock\u0026#39; In plaats van de resultaten te limiteren op GenreId, kunnen we beide tabellen joinen:\nCREATE VIEW rock_tracks AS SELECT tracks.* FROM tracks INNER JOIN genres ON genres.GenreId = tracks.GenreId WHERE genres.Name = \u0026#39;Rock\u0026#39; Dit kan ook met behulp van een subquery. Zie ook: DDML - JOIN operator en verder, subqueries.\nSchrijf een view die de naam van elke track geeft, alsook de naam van het album en de artiest, gesorteerd op artiest, album en dan track.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/sql/",
	"title": "1. RDBMS",
	"tags": [],
	"description": "",
	"content": "RDBMS Zie menu links.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/transacties/basics/",
	"title": "1. Transaction Mgmt. Basics",
	"tags": [],
	"description": "",
	"content": "SQL DBMS systemen zijn eerst en vooral multi-user systemen. Om zowel verschillende gebruikers te kunnen behandelen als nog steeds de ACID regels ondersteunen, is er een systeem nodig dat soms gebruikers \u0026ldquo;in wacht\u0026rdquo; zet. Stel je voor dat Jens en Jolien tegelijkertijd data lezen én updaten\u0026mdash;in dezelfde tabel, hetzelfde record. Jens leest uit \u0026ldquo;de rekening staat op 100 EUR\u0026rdquo; en Jolien haalt er 10 EUR vanaf. Wie mag eerst? Kan dit tegelijkertijd? Jens krijgt te horen dat er 100 EUR op de rekening staat, terwijl in werkelijkheid dit 10 EUR minder is.\n0. Waarom transacties? Heel simpel. Dit is het verkeer zonder transacties:\nDit met:\nOm Atomicity, Consistency, Isolation, Durability te garanderen is er dus een transactie manager nodig die alles in goede banen leidt op het moment dat verschillende gebruikers data gaan raadplegen en/of manipuleren. Dit principe is ruwweg hetzelfde als task management van het vak Besturingssystemen en C\u0026mdash;maar dan op database-applicatie niveau.\n1. Wat is een transactie? Een transactie is een set van database operaties (bij relationele databases dus een aantal SQL operaties), dat door één gebruiker of applicatie als één unit of work aanzien wordt. Bijvoorbeeld, Jens wilt geld overschrijven van zijn rekening naar die van Jolien. Dit gaat meestal in verschillende stappen:\nHaal €10 van balans van Jens; Stort €10 op balans van Jolien. graph LR;\rJN[Rekening van Jens]\rJL[Rekening van Jolien]\rJN --\u003e|10 EUR| JL\rDit is één transactie\u0026mdash;het zou nooit mogen gebeuren dat er €10 verdwijnt van Jens\u0026rsquo; account zonder dat Jolien dat geld ontvangt. Met andere woorden, er kan niets tussen stap 1 en stap 2 komen: geen systeem crash, geen andere gebruiker (bijvoorbeeld Marianne die Jens €20 voor zijn verjaardag stort op de rekening). Dit is één \u0026ldquo;unit of work\u0026rdquo;: als er iets misloopt zou alles teruggedraaid moeten worden. Dus, een transactie heeft als resultaat ofwel success, ofwel failure, maar niets tussenin. Indien dit succesvol wordt afgerond zou het DBMS systeem moeten garanderen dat het geld effectief op Jolien\u0026rsquo;s rekening staat. Indien het faalde zou het DBMS systeem moeten garanderen dat Jens zijn geld niet kwijt is.\nIn de praktijk worden veel verschillende transacties tegelijkertijd uitgevoerd\u0026mdash;eventueel door verschillende gebruikers. Er moet dus iemand zijn die dit beheert, en dat is de transactie manager. Wie beslist of Jens eerst zijn geld mag afhalen, of dat Marianne eerst zijn verjaardagscadeau mag overmaken op de rekening? Wie beslist dat tussen stap 1 en 2 bij de transfer van het geld van Jens naar Jolien niemand mag tussenkomen? Juist: de transactie manager. Hier zijn verschillende strategieën voor, zoals we later zullen zien in Concurrency Control.\n2. Het beheren van transacties Formeel gezien wordt er een transactie afgelijnd door aan te kondigen wanneer een transactie begint en wanneer hij stopt, zodat de manager de juiste acties kan doorvoeren. De gebruiker kan met SQL ook zelf een transactie terugdraaien als er een programmafout voorkomt, bijvoorbeeld met een try { ... } catch(Exception ex) { rollback }. Meer hierover in sectie failures/rollbacks.\nDe transactie manager, die afgelijnde transacties ontvangt, kan dit dan in een schedule zetten, om te beslissen welke (delen van) transacties wanneer moeten worden uitgevoerd, net zoals Round Robin CPU scheduling algoritmes. Uiteindelijk wordt er een status toegekend aan een transactie:\nCommitted\u0026mdash;het is gelukt en de data is permanent gepersisteerd. Aborted\u0026mdash;Een error tijdens het uitvoeren van de transactie. Indien er halverwege de abort data is gewijzigd moet dit worden teruggezet, of worden rollbacked. Vorige versies van data moet dus ook worden bijgehouden. Jens\u0026rsquo; rekening kan bijvoorbeeld €90 zijn initieel, hij haalt er €10 af om over te maken wat dit tot €80 maakt, maar er loopt iets mis: de rollback triggert het terugdraaien van het getal 80 naar de originele 90.\nDit is een pseudocode voorbeeld van bovenstaande afgelijnde transactie:\nBEGIN TRANSACTION;\rUPDATE account SET waarde = waarde - :over_te_maken_bedrag\rWHERE eigenaar = \u0026#39;Jens\u0026#39;\rUPDATE account SET waarde = waarde + :over_te_maken_bedrag\rWHERE eigenaar = \u0026#39;Jolien\u0026#39;\rCOMMIT; Transacties kosten CPU en RAM en zijn configureerbaar maar dus gelimiteerd in aantal. De manager kan worden ingesteld tot bijvoorbeeld ondersteunen van maximum 10 transacties tegelijkertijd.\nDBMS Componenten bij een transactie Een voorbeeld van een transactie workflow (de nummers komen overeen met het schema):\nDBMS componenten aan het werk tijdens een transactie. src: pdbmbook.com\rDe manager waarschuwt de scheduler dat er een nieuwe transactie moet worden ingepland. Deze optimaliseert dit naar throughput (zie BESC); De recovery en stored data manager worden op de hoogte gebracht. Deze optimaliseert disk access: het zou kunnen dat DB reads/writes via een buffer verlopen omdat fysieke file operaties duur zijn; De scheduler is nu klaar om input te ontvangen en uit te voeren in de juiste volgorde; Dit triggert mogelijks interactie met de stored data manager (het effectief wegschrijven van wijzigingen); De uitkomst wordt doorgegevan via een output area: ofwel is het gelukt (5b), ofwel is het mislukt (5a), waardoor de recovery manager zijn werk moet doen om dingen terug te draaien. 3. Wat als er iet misgaat? Hoe werkt dat blokje \u0026ldquo;recovery manager\u0026rdquo; precies? Een DBMS systeem gebruikt achterliggend een logfile als belangrijk element om eventuele recoveries te kunnen doorvoeren. Een logfile bevat in principe redundante data: in het beste geval wordt dit nooit gebruikt. Maar in het geval dat er ook maar iets misloopt is het van groot belang dat de log entries kunnen worden gebruikt om de data terug te zetten.\nVoor elke transactie en operatie wordt relevante informatie geregistreerd in de logfile als een log record. Deze bevat de volgende informatie:\nEen unieke Log ID; Een unieke Transactie identifier om de records te kunnen koppelen aan de transacties; Een markering voor de start van de transactie + tijd + type (read/write/read-write combo) aan te duiden; Database record identifiers en operaties (select/insert/\u0026hellip;.) die bij de transactie horen; before images: een snapshot van de data voordat de transactie werd doorgevoerd. Deze worden gebruikt om een undo uit te voeren; after images: een snapshot van de data nadat de transactie werd doorgevoerd. Deze worden gebruikt om een redo uit te voeren, moest bijvoorbeeld een fysieke file write mislukken en hier een retry op worden toegepast. Er wordt altijd eerst in de logfile geschreven: dit noemen we een write-ahead log strategy. Op die manier is de DBMS manager voorbereid op een mogelijke rollback. Alle updates worden dus eerst naar de logfile geschreven voordat er iets fysiek veranderd op de harde schijf. Merk op dat de \u0026ldquo;logFILE\u0026rdquo; ook (gedeeltelijk) in-memory kan zijn.\nWat kan er zoal misgaan? Failures worden in drie groepen opgedeeld:\nTransaction failures: fouten in de logica van de transactie, zoals verkeerde input, incorrecte variabelen, statements die niet kloppen, etc. Sommige applicaties vangen dit al op voordat het naar de DBMS gaat. System failures: DB of OS crashes op de server, bijvoorbeeld door stroomonderbrekingen of bugs in de database zelf. Het zou kunnen dat de DBMS buffer inhoud hierdoor leeg raakt en delen van data niet teruggezet kunnen worden. Media failures: Storage access fouten door bijvoorbeeld disk crashes, een storing in het netwerk, etc. Het zou kunnen dat de logfile niet toegankelijk is. Het is de moeite waard om even te kijken naar de laatste 2 groepen en hoe daar recovery processen precies werken.\nSystem Recovery Veronderstel dat er 5 transacties door de DBMS worden verwerkt. Tc duidt een checkpoint aan van de data in de buffer. Er treedt een systeemfout op rechts bij Tf:\nUNDO/REDO operaties voor 5 \u0026#39;kapotte\u0026#39; transacties. src: pdbmbook.com\rWe bekijken de 5 transacties afzonderlijk:\nT1\u0026mdash;Aangezien deze succesvol werd gecommit voor de systeemfout én voor de snapshot Tc, hoeft hier niets voor te gebeuren na een crash. T2\u0026mdash;Deze transactie is ook compleet voor Tf, maar er zit nog data in de buffer van de snapshot Tc die niet naar disk geschreven werd. Hier is dus een REDO nodig. T3\u0026mdash;Deze transactie was nog bezig bij de crash van Tf. We hebben niet alle data in de buffer: er is dus transactie data verloren gegaan: een UNDO dus. T4\u0026mdash;Deze transactie is gelukt maar alle data is nog steeds pending to disk (bij T2 was dit een deel): REDO. T5\u0026mdash;De DBMS scheduler had deze net ingepland toen het systeem crashte. Het is niet nodig om hier is van terug te draaien omdat er niks pending was (na de Tc checkpoint). Media Recovery Wat doe jij als er een harde schijf gerashed is van je computer? Bidden voor een werkende backup? Indien fysieke files niet meer toegankelijk zijn is een \u0026ldquo;media recovery\u0026rdquo; afhenkelijk van data redundancy principes. Hopelijk heb je een backup strategie voorzien. Voor database systemen wordt dit streng toegepast en moeten we een recovery doorvoeren via een mirror op een andere HDD in RAID, op een cloud backup, een offline backup, \u0026hellip;\nOm de failover time te minimaliseren wordt dit vaak automatisch opgezet. Een harde schijf kan in een server in RAID-1 modus geplaatst worden: die functioneert als 100% clone van de andere. Indien er één van beide HDDs faalt, neemt onmiddellijk de andere het werk over, zodat gebruikers zo goed als geen last hebben van de media failure. Systemen als backup copies door iets te \u0026ldquo;archiveren\u0026rdquo; (een .tar.gz of .zip op bepaalde tijdstippen aan de kant zetten) vereist meestal meer werk om terug te zetten. Backups nemen betekent ook beslissen of het een full of incremental backup zal zijn, waarbij je (1) alle files apart zet, of (2) enkel de wijzigingen ten opzichte van vorige snapshots.\nEen goede backup strategie\u0026mdash;dit geldt zowel voor databases als voor je eigen data!!\u0026mdash;volgt het 1-2-3 backup principe:\nZorg voor minstens drie backups van je data, waarvan twee lokaal maar op verschillende media (bvb, verschillende servers, op HDD en op USB, \u0026hellip;), en één off-site kopie, zoals cloud-based backup systemen als Dropbox, Google Drive, Backblaze\u0026rsquo;s Cloud Storage. Dan hebben we het nog niet over security gehad\u0026hellip;\nDenkvragen Waarom kan je niet gewoon media recovery strategieën toepassen bij systeemcrashes? Waarom wel, maar is dat misschien geen goed idee? Als er verschillende transacties tegelijkertijd aan één record iets wijzigen, welke problemen zie jij dan zoal? Hoe zou je dat door de transaction manager laten oplossen? Kan je zo twee verschillende oplossingen bedenken? Wat is alweer het verschil tussen UNDO en REDO recovery technieken? Als ier iets misgaat op applicatieniveau, bijvoorbeeld een crash in je Java applicatie, moet de DBMS dan iets doen, of moet de programmeur dan iets doen, om ACID te blijven garanderen? Wat zou er volgens jou moeten gebeuren als twee personen tegelijkertijd op bol.com een item bestellen waarvan maar één hoeveelheid in stock is? Wie trekt hier aan het korte eind? Hoe vangen grote webwinkels dit probleem op? "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/transacties/concurrency-control/",
	"title": "2. Concurrency Control",
	"tags": [],
	"description": "",
	"content": "De transactie management scheduler (zie transacties - basics) is verantwoordelijk om verschillende transacties correct in te plannen zonder dat er data problemen of clashes optreden.\n1. Problemen? Welke problemen? Denk terug aan het bank transfer probleem van de vorige sectie. Veronderstel dat deze keer zowel Jens als Marianne €10 willen overmaken naar Jolien. Als we dat als volgt doen:\nVerminder bedrag van source rekening Verhoog bedrag van destination rekening Dan zou het kunnen dat bij het uitlezen van #2, Jolien\u0026rsquo;s rekening op €100 staat. Maar als de transactie van Marianne dit ook leest als €100, en niet wacht tot de €110 die het zou moeten zijn na de commit van de transactie van Jens, dan gaat in totaal Marianne slechts €10 rijker zijn in plaats van twee keer dat bedrag. Oeps!\ngraph LR;\rJN[Rekening van Jens]\rJL[Rekening van Jolien]\rML[Rekening van Marianne]\rJN --\u003e|10 EUR| JL\rML --\u003e|10 EUR| JL\rHieronder volgen een aantal veel voorkomende concurrency problemen die de transaction scheduler uitdagen.\nA. Lost Updates Dit is exact bovenstaande situatie. Het UPDATE statement van Jens\u0026rsquo; transactie (verhoog Jolien\u0026rsquo;s rekening met 10) is \u0026ldquo;verloren\u0026rdquo;, omdat Marianne hier tussen komt, en haar UPDATE die terug ongedaan maakt:\ntime T1 (Marianne) T2 (Jens) bedrag 1 begin trans 100 2 begin trans read(bedrag): 100 100 3 read(bedrag): 100 bedrag = bedrag + 10 100 4 bedrag = bedrag + 10 write(bedrag) 110 5 write(bedrag) commit 110 (oeps) 6 commit 110 Dit voorbeeld illustreert dat, alhoewel beide transacties 100% correct zijn, er toch nog problemen kunnen optreden als transacties elkaar gaan storen. Het spreekt voor zich dat als T1 data zou lezen en schrijven uit een andere rij of tabel, dit geen probleem zou zijn\u0026mdash;in dit specifieke voorbeeld.\nB. Dirty Reads Een \u0026ldquo;dirty read\u0026rdquo; probleem is het lezen van uncommited \u0026ldquo;dirty\u0026rdquo; data\u0026mdash;data die eigenlijk voor de andere transactie nog niet zichtbaar mat zijn omdat het hier over uncommitted data gaat. Als Marianne\u0026rsquo;s read(bedrag) toch het juiste bedrag zou inlezen (110), voordat Jens\u0026rsquo; transactie compleet is, maar op een of andere manier is die transactie teruggedraaid, dan spreken we over een dirty read, en krijgt Jolien onterecht toch €20, terwijl Jens zijn €10 mag houden. It prints money!\ntime T1 (Marianne) T2 (Jens) bedrag 1 begin trans 100 2 read(bedrag): 100 100 3 bedrag = bedrag + 10 100 4 begin trans write(bedrag) 110 5 read(bedrag): 110 110 6 bedrag = bedrag + 10 ROLLBACK! 120 (oeps) 7 write(bedrag) 120 8 commit 120 C. Inconsistent Analysis Bij inconsistente analyse tussen twee transacties gaat het over een sequentie van verschillende dirty reads die de situatie alleen maar verergeren, zelfs zonder de eventuele rollback. Stel dat het over te schrijven bedrag in stukjes van €2 wordt overgeschreven, waarbij telkens tussenin een read(bedrag) plaats vindt\u0026mdash;die natuurlijk de data van de andere transactie inleest. Het resultaat is, opnieuw, een veel te grote som, en een mogelijks erg blije Jolien.\nWe laten een schematische voorstelling van dit probleem als oefening voor de student.\n\u0026hellip; En meer Er zijn nog verschillende andere mogelijkheden waarbij de scheduler de bal kan misslaan. Bijvoorbeeld door non-repeateable reads: transactie T1 leest dezelfde rij verschillende keren in maar verkrijgt telkens andere waardes (wat niet zou mogen) vanwege andere transacties die ook met die rij bezig zijn.\nOf wat dacht je van phantom reads: transactie T2 is bezig met rijen effectief te verwijderen, terwijl T1 deze toch nog inleest. Het zou kunnen dat hierdoor verschillende rijen ontstaan (T2 rollback, T1 die een nieuwe rij maakt), of dat voorgaande bestaande rijen verdwijnen door T2, waardoor de transactie van T1 mogelijks faalt.\nTeruggrijpende naar ons Jolien voorbeeld, stel dat Jens Jolien €5 wilt betalen per klusje dat ze gedaan heeft. Klusjes worden opgeslagen in een aparte tabel, maar ondertussen kan Jolien een nieuw klusje afvinken, waardoor Jens\u0026rsquo; transactie een phantom read krijgt:\ntime T1 (Jens) T2 (Jolien) klusjes 1 read 1: SELECT * FROM klusjes WHERE naam = 'Jolien' (2) 2 2 2 3 random ander werk INSERT INTO klusjes ... 3 4 3 5 read 2: SELECT * FROM klusjes WHERE naam = 'Jolien' (3, oeps) 3 6 sort 3x5 op rekening (teveel) 3 7 commit Bijgevolg verkgijt T1 inconsistente data: de ene keer 2, de andere keer 3\u0026mdash;vergeet niet dat het goed zou kunnen dat T2 nog teruggedraaid wordt.\nWat is het verschil tussen een non-repeatable read, een phantom read, en een dirty read? Dirty reads lezen foutieve uncommitted data van een andere transactie\u0026mdash;het lezen van \u0026lsquo;in progress\u0026rsquo; data. Non-repeateable reads en phantom reads lezen foutieve committed data van een andere transactie. Bij non-repeatable reads gaat het over UPDATEs, en bij phantom reads over INSERTs en/of DELETEs: rijen die plots verschijnen of zijn verdwenen sinds de transactie begon.\n2. Scheduler oplossingen Wat is de simpelste manier om bovenstaande problemen allemaal integraal te vermijden? Juist ja\u0026mdash;sequentieel transacties verwerken.\nA. Serial scheduling Met serial scheduling is T2 verplicht te wachten op T1 totdat die zijn zaakje op orde heeft. De lost update transactie flow van hierboven ziet er dan als volgt uit:\ntime T1 (Marianne) T2 (Jens) bedrag 1 begin trans 100 2 read(bedrag): 100 100 3 bedrag = bedrag + 10 100 4 write(bedrag) 110 5 commit 110 6 begin trans 110 7 read(bedrag): 110 110 8 bedrag = bedrag + 10 120 9 write(bedrag) 120 10 commit 120 Wat valt je op als je naar de time kolom kijkt? Serial scheduling duurt nu 10 ticks t.o.v. 6 bij de potentiële lost update\u0026mdash;da\u0026rsquo;s een redelijk grote performance hit van 40%! Serial scheduling lost misschien wel alles op, maar daardoor verliezen we alle kracht van het woord parallel: dit is in essentie non-concurrency.\nWat zijn dan betere scheduling alternatieven?\nB. Optimistic scheduling Bij \u0026ldquo;optimistic\u0026rdquo; scheduling gaan we ervan uit dat conflicten tussen simultane transacties nauwelijks voorkomen. Met andere woorden, we benaderen het probleem (misschien te) optimistisch. Transacties mogen gerust tegelijkertijd lopen als ze bijvoorbeeld verschillende tabellen of stukken data in dezelfde tabel bewerken\u0026mdash;zolang er geen conflict is, geniet paralellisatie de voorkeur.\nBij optimistische schedulers worden alle transactie operaties doorgevoerd. Wanneer deze klaar zijn voor een eventuele COMMIT, wordt er gecontroleerd op potentiële conflicten. Indien geen, success. Indien wel, abort en ROLLBACK.\nMerk op dat rollback operaties erg dure operaties zijn: de manager moet graven in de logfile, moet beslissen of er UNDO/REDO operaties moeten worden uitgevoerd, er is mogelijke trage disc access (I/O), \u0026hellip; Als je vaak rollbacks hebt/verwacht is optimistic scheduling nog steeds geen performant alternatief.\nC. Pessimistic scheduling Bij \u0026ldquo;pessimistic\u0026rdquo; scheduling gaan we van het omgekeerde uit: transacties gaan heel zeker conflicteren. De scheduler probeert transactie executies te verlaten om dit zo veel mogelijk te vermijden. Een serial scheduler is een extreem geval van een pessimistic scheduler.\nLocking In de praktijk wordt locking gebruikt op een pre-emptive manier (zie besturingssystemen: scheduling algorithms) om toch transacties waar mogelijk concurrent te laten doorlopen. Bij transacties die schrijven in plaats van die enkel lezen zullen locks eerder nodig zijn. Er bestaan uiteraard erg veel verschillende locking technieken/algoritmes.\nWe maken onderscheid tussen twee groepen:\nexclusive locks: als T1 een exclusieve lock neemt, kan er geen enkele andere transactie op die database worden uitgevoerd. Dit is een erg strict systeem, denk aan serial scheduling. shared locks: zolang T1 een lock neemt op een object (zie onder), krijgt het de garantie dat geen enkele andere transactie dat object kan manipuleren totdat de lock terug wordt vrijgegeven (eventueel ook door middel van een rollback). Locks worden \u0026ldquo;gedeeld\u0026rdquo;: T1 krijgt write access, en T2 moet wachten met schrijven, maar mag wel lezen. De database \u0026ldquo;objecten\u0026rdquo; waar een lock op genomen kan worden zijn onder andere (van kleine locks naar groot):\nrow locks; column locks; page locks (delen van een tabel zoals stored in files); table locks; databas locks (bvb een file lock in SQLite); Een lock op één rij in beslag genomen door T1 betekent dat voor diezelfde tabel T2 nog steeds bedragen kan wijzigen van een andere rekening. Column locks kunnen tot meer wachttijd leiden. Page locks zijn \u0026ldquo;stukken\u0026rdquo; van een tabel (rijen voor x en erna). Een page is een chunk van een tabel die op die manier wordt opgeslaan. Dit verschilt van DB implementatie tot implementatie. Tenslotte kan een hele tabel gelockt worden\u0026mdash;of de hele tablespace\u0026mdash;wat meer pessimistisch dan optimistisch is.\nLocks zijn onderhevig aan dezelfde nadelen als rollbacks: ze zijn duur. Als er erg veel row locks zijn op een bepaalde tabel kan dit veel CPU/RAM in beslag nemen. In dat geval kan de lock manager beslissen om aan lock escalation te doen: de 100 row locks worden één page of table lock. Dit vermindert resource gebruik drastisch\u0026mdash;maar zou transacties ook langer kunnen laten wachten. You win some, you lose some\u0026hellip;\nProblemen bij oplossen van problemen: deadlocks Stel dat Jens cash geld wilt deponeren, en Marianne hem ook geld wenst over te schrijven. Voordat Marianne dat doet koopt ze eerst nog een cinema ticket. Jens wil ook een ticket in dezelfde transactie. Het gevolg is dat T1 en T2 oneindig op elkaar blijven wachten. Dat ziet er zo uit:\ngraph LR;\rC{Cinema tabel}\rR{Rekening tabel}\rJ[Jens]\rM[Marianne]\rJ --\u003e|deposit 10| R\rM --\u003e|transfer 10| R\rM --\u003e|koop ticket| C\rJ --\u003e|koop ticket| C\rDe kruisende pijlen duiden al op een conflict:\ntime T1 (Jens) T2 (Marianne) 1 begin tarns 2 begin tarns 3 update rekening (acquire lock R) 4 update cinema (acquire lock C) 5 poging tot update cinema (WACHT) 6 poging tot update rekening (WACHT) Deze (simpele) deadlock kan gelukkig gedetecteerd worden door het DBMS systeem. Die zal één van beide transacties als \u0026ldquo;slachtoffer\u0026rdquo; kiezen en die transactie terugdraaien\u0026mdash;meestal gebaseerd op welke het makkelijkste is om terug te draaien. Het probleem is dat de meeste applicaties niet onmiddellijk voorzien zijn op zo\u0026rsquo;n onverwachte rollback. Dit resulteert meestal in een negatieve gebruikerservaring.\nDeadlocks en algoritmes om dit te detecteren en op te lossen zijn erg complexe materie. Het volstaat om bovenstaand eenvoudig voorbeeld te kennen, en te weten hoe dat aangepakt zou kunnen worden\u0026mdash;bijvoorbeeld met starvation, timeouts, en priority shift principes zoals ook gezien in het vak Besturingssystemen en C.\nZie ook A beginners guide to DB deadlocks.\nIsolation levels Pessimistic locking kan veel problemen opvangen, maar ten koste van performantie\u0026mdash;wat meestal belangrijker is. Voor veel transacties is het oké om met een minimum aan conflicten de throughput van transacties zo hoog mogelijk te houden. De meeste DBMS systemen zijn hier flexibel in: je kan wat we noemen isolation levels instellen, dat meestal bestaat uit de volgende vier opties (van low naar high isolation):\nRead uncommited\u0026mdash;Dit laat toe om \u0026ldquo;uncommited\u0026rdquo; data te lezen (dat problemen geeft, zie boven), en wordt meestal gebruikt in combinatie met read-only transacties. Read committed\u0026mdash;Gebruikt short-term read locks en long-term write locks, en lost zo het inconsistent analysis/lost update probleem op, maar is niet krachtig genoeg om phantom reads tegen te houden. Repeatable read\u0026mdash;Gebruikt long-term read \u0026amp; write locks. Een transactie kan zo dezelfde rij verschillende keren opnieuw lezen zonder conflicten van insert/updates van andere transacties. Het phantom read probleem is echter nog steeds niet opgelost. Serializable\u0026mdash;het krachtigste isolation level dat in theorie aansluit met serial scheduling. Een short-term lock wordt enkel vastgehouden gedurende het interval dat nodig is om een operatie af te ronden, terwijl long-term locks een protocol volgen en meestal tot de transactie commited/rollbacked is vastgelegd zijn.\nMerk op dat voor elke database implementatie de selectie van een isolation level andere gevolgen kan hebben! Zie de tabellen in https://github.com/changemyminds/Transaction-Isolation-Level-Issue. Het is dus van belang de documentatie van je DB te raadplegen, zoals deze van Oracle, waarin de volgende beschrijving staat voor TRANSACTION_SERIALIZABLE: \u0026ldquo;Dirty reads, non-repeatable reads and phantom reads are prevented.\u0026rdquo;.\nWe komen hier nog later op terug in concurrency in practice wanneer we bijvoorbeeld bij JPA of Hibernate aangeven welk isolation level gewenst is.\nDenkvragen Waarom is het phantom read probleem niet opgelost bij isolation level 3 (repeatable read)? Kan je nog andere situaties verzinnen waarin een deadlock kan voorkomen? Welk isolation level of scheduling algoritme lost dit op? Wat is de verantwoordelijkheid van de DBMS\u0026rsquo;s transactie management systeem in verhouding tot de ACID eigenschappen? Welke impact heeft lock granulariteit op transactie throughput? "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/sql/rdbms-components/",
	"title": "2. Database Componenten",
	"tags": [],
	"description": "",
	"content": "1. Three Layer Architecture Logical Layer De Logical Layer is waar we bepalen hoe onze data gestructureerd wordt. Hier bepalen we wat voor data we bijhouden, hoe die data eruitziet en hoe die zich gedraagt ten op zichte van onze andere datamodellen.\nEnkele voorbeelden hiervan zijn:\nEen BOEK mag door maximum 0 of 1 PERSONEN ontleend worden. Een PERSOON mag meerdere BOEKEN ontlenen. Een PERSOON is een subtype van een GEBRUIKER. Oefening Hoe zou een database model van een bibliotheek eruit zien? Teken zelf eens uit hoe dit gemodelleerd zou kunnen worden. Hoe houdt ik bij dat een boek uitgeleend werd? Wat als ik ook andere dingen wil uitlenen uit de bibliotheek, zoals DVD\u0026rsquo;s of eBooks? Internal Layer De Internal Layer houdt zich bezig met alle details over hoe de data bewaard wordt. Sommige van de concepten die hier aan bod komen zijn de volgenden:\nIndex management Constraint definities (uniek, referentieel, \u0026hellip;) Gepartitioneerde tabellen \u0026hellip; Deze technologieën hebben allemaal te maken met performantie of data integriteit. We willen onze data op een zo\u0026rsquo;n performante manier opslaan én nog belangrijker op een zo performante manier terug ophalen.\nIndexatie Data wordt ongestructureerd bijgehouden in een tabel. Een tabel is eigenlijk niet meer dan een ongesorteerde lijst van gegevens. Bij elke nieuw element wordt dat aan het eind van de lijst toegevoegd.\nWat als we nu uit een lijst van miljoenen boeken de verzamelde werken van Tolkien willen ophalen? In plaats van door de hele lijst één voor één te gaan zoeken, kunnen we gelukkig gebruik maken van indexen.\nEen index is een inhoudstafel die we bijhouden van een bepaald aantal velden van onze tabel. Stel we hebben een Book tabel met miljoenen rijen, waaronder de volgende:\nid isbn title author price 1345 0765326353 The Way of Kings Brandon Sanderson 24.99 6789 0395177111 The Hobbit J.R.R. Tolkien 24.99 3240 0812511816 The Eye of the World Robert Jordan 24.99 8939 0358439191 The Lord of the Rings J.R.R. Tolkien 24.99 1230 0143111582 Dune Frank Herbert 24.99 Als we een index zouden leggen op de author kolom dan zou die volgende informatie kunnen bevatten:\nauthor id Brandon Sanderson 1345 Frank Herbert 1230 J.R.R. Tolkien 6789 J.R.R. Tolkien 8939 Robert Jordan 3240 Een index houdt een mini-tabel bij van de velden die aan de index worden toegevoegd in combinatie met het identity1 veld. Deze tabel is wel gesorteerd op de velden uit de index, wat zoekopdrachten versnelt.\nConstraints We kunnen onze tabellen behoeden van corrupte data te bevatten door constraints te gebruiken. Het ISBN veld is bijvoorbeeld een uniek veld en mag nooit een waarde bevatten die al gekend is in onze database. Hiervoor kunnen we een unique constraint toevoegen. Bij data insertion gaat de database zelf nakijken of deze value al bestaat en zo ja wordt het toevoegen van de record geblokkeerd. Zo behouden we onze data integriteit.\nAndere voorbeelden van constraints kunnen zijn:\nDe prijs van een boek moet groter dan 0 zijn Een boek kan niet verwijderd worden als het ooit werd uitgeleend Het ISBN-13 nummer moet 13 karakters hebben Het ISBN nummer moet - een aantal keren bevatten Een naam veld mag niet NULL (niet ingevuld) zijn Een email veld moet @ bevatten \u0026hellip; Hoe constraints in de praktijk worden toegevoegd aan data modellen wordt behandeld in het hoofdstuk SQL DDL \u0026amp; DML. Zie ook SQLite table-constraint syntax.\nGepartitioneerde tabellen Sommige tabellen in productie omgevingen bevatten immense hoeveelheden aan data. We spreken over een grootorde van meerdere miljarden rijen. Hoe groter een tabel wordt, hoe trager het wordt om data op te halen. Het maakt niet uit hoeveel indexen we hebben gelegd, of welke SSD schijven we onderliggend op de fysieke storage hebben zitten. Meer data gaat altijd gelijk staan aan tragere data retrieval.\nOm tegen te gaan dat we tabellen krijgen die té groot worden en we daar niet meer zinvol data van kunnen ophalen bestaan hier een paar oplossingen voor. Het partitioneren van tabellen is er eentje van. Archivatie is een andere oplossing.\nNeem als voorbeeld een bank, die elke overschrijving van een rekening moet bewaren. De overschrijving tabel zou kunnen gepartitioneerd worden op jaar. Zodat er nog steeds 1 tabel overschrijving is, maar waarbij we die op de fysieke schijf opsplitsen per jaar, en elke op bijvoorbeeld de recentste 3 jaren index management voor bijhouden. De andere jaren kunnen nog steeds opgevraagd worden maar niet met dezelfde performantie als de meest recente data.\nExternal Layer De External Layer is wat we van onze database laten zien aan de buitenwereld. Dit zijn views van data. Een view is een virtuele representatie van data. We schrijven een query op onze tabellen en bewaren deze query als een view. Op deze manier kunnen we garanderen aan integrerende applicaties dat onze data er steeds hetzelfde gaat uitzien en tevens beschermen van informatie die voor het integrerende systeem niet relevant is.\nIn onze bibliotheek kunnen we een aantal views osptellen op basis van de noden van de verschillende applicaties. In het online platform waar je boeken kan uitlenen is het niet nodig de informatie over een auteur als een aparte entiteit weer te geven. We kunnen de tabel van Authors dus verbergen en enkel een view aanbieden op niveau van Books die er als volgt zou uitzien:\nclassDiagram\rclass LendingAppBooks{\risbn: NVARCHAR\rtitle: NVARCHAR\rauthor: NVARCHAR\rprice: DECIMAL\rgenre: NVARCHAR\r}\rVoor de inventaris applicatie moeten we wel in staat zijn om nieuwe boeken en auteurs toe te voegen. Daar kunnen de views er dan als volgt uitzien:\nclassDiagram\rInventoryBooks \"1..*\" --\u003e \"1\" InventoryAuthors\rclass InventoryAuthors{\rid: INT\rname: NVARCHAR\rfirstName: NVARCHAR\r}\rclass InventoryBooks{\risbn: NVARCHAR\rtitle: NVARCHAR\rauthor: INT\rprice: DECIMAL\r}\r2. Catalog Dit is het hart van de de database. Dit bevat alle metadata die zich in de database bevindt. Onder andere, de tabellen; views; stored procedures; \u0026hellip;\nDe SQL standaard om deze informatie in te bewaren is in INFORMATION_SCHEMA. Niet alle SQL Database providers voldoen hier echter aan. SQLite doet dit niet en daar vind je die informatie in de tabel sqlite_master.\n3. Database Languages SQL is onderverdeeld in twee verschillende talen. Enerzijds heb je DDL (Data Definition Language). Dit gebruik je om de database structuur te wijzigen. Nieuwe tabellen toevoegen, indexen aanmaken, views verwijderen, \u0026hellip;\nAnderzijds heb je DML (Data Manipulation Language). Dit gebruik je voor alle CRUD (Create, Read, Update, Delete) acties op data. Hier gaan we in een volgend hoofdstuk verder op in gaan.\nEigenlijk niet het Identity veld, maar het veld dat in de Clustered Index zit van de tabel. Als er dan in de query meer informatie nodig is om op te halen kan die via die manier de rest van de data ophalen.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/sql-ddl-dml/dml/",
	"title": "2. DML",
	"tags": [],
	"description": "",
	"content": "Data Modification Language is de taal die we gebruiken om de data van onze database te bekijken of aan te passen. Met DML kunnen we CRUD operaties uitvoeren. Create, Read, Update en Delete.\nSELECT SELECT is het commando dat we gebruiken om data op te vragen uit de database.\nSELECT { DISTINCT } expression\rFROM table\r{ WHERE condition } LIKE operator LIKE wordt gebruikt om wildcard searches uit te voeren. Deze kan enkel gebruikt worden op alfanumerieke velden.\n% is een match anything character voor een onbeperkt aantal karakters (0 tot n). Zo matcht Gen% met volgende waardes: Gen, Genk, Gent, Genève, Genua, \u0026hellip;\n_ is een match anything character voor één karakter. Zo matcht Gen_ met volgende waardes: Genk, Gent, \u0026hellip; Maar niet met volgende waardes: Gen, Genève, Genua, \u0026hellip;\nNULL NULL is het ontbreken van een waarde. Het is een onbekende. We kunnen in DML niet zomaar vergelijken met NULL. We kunnen namelijk niet zeggen dat een onbekende gelijk is aan een andere onbekende.\nHieronder een overzicht van een binary AND table met True, False en NULL waardes.\nAND True False NULL True True False NULL False False False False NULL NULL False NULL Denkvraag: Waarom is False == NULL gelijk aan False?\nHieronder vinden we de binary OR table met True, False en NULL waardes.\nOR True False NULL True True True True False True False NULL NULL True NULL NULL Als we willen vergelijken met NULL in queries, dan gebruiken we volgende code:\n\u0026lt;value\u0026gt; IS NULL\nen\n\u0026lt;value\u0026gt; IS NOT NULL\nSchrijf een query die alle Customers (volledige naam, customer ID en land) laat zien die niet wonen in de USA. Schrijf een query die enkel de Customers laat zien die in Brazilië wonen. Schrijf een query die alle Employees laat zien die werken in de Sales afdeling. Schrijf een query die een unieke lijst van landen laat zien uit de Invoices tabel. Schrijf een query die alle Tracks laat zien waarvoor er geen componist bekend is. Schrijf een query van alle unieke Componisten. Als de componist niet bekend is, dan moet er \u0026lsquo;Onbekend\u0026rsquo; weergegeven worden gesorteerd op naam. Schrijf een query die het maximumbedrag van alle Invoices laat zien. JOIN Wanneer we informatie willen ophalen uit meerdere tabellen dan gebruiken we daar een JOIN statement voor. Die syntax ziet er als volgt uit:\nSELECT { DISTINCT } expression\rFROM table\rINNER JOIN other_table ON join_condition\r{ WHERE condition } Hiermee matchen we alle data van de ene tabel met de andere tabel op de meegegeven conditie. Er bestaan drie verschillende types JOINs:\nINNER JOIN - Geeft alle resultaten die bestaan zowel in de ene als de andere tabel LEFT JOIN - Geeft alle resultaten die bestaan in de base tabel, ook al bestaan die niet in de tabel waarop we joinen RIGHT JOIN - Wordt in de praktijk zelden tot nooit gebruikt. Geeft alle resultaten die bestaan in de gejoinde tabel ook al bestaan ze niet in de base tabel. Schrijf een query die alle Invoices laat zien van alle Customers uit Brazilië. Het resultaat moet de volledige naam van de Customer, Invoice ID, Invoice Datum en Billing Country weergeven. Schrijf een query die alle Invoices laat zien voor elke Sales Agent. Het resultaat moet de volledige naam van de Sales Agent weergeven. Schrijf een query die het Invoice Totaal, de Customer naam en land en de naam van de Sales Agent weergeeft voor alle Invoices en Customers. Schrijf een query die het aantal invoice lijnen weergeeft voor Invoice ID 37. Schrijf een query die de track naam weergeeft langs elke invoice lijn. Schrijf een query die de track naam en de artiest naam weergeeft langs elke invoice lijn. Schrijf een query die alle tracks laat zien, maar geen ID\u0026rsquo;s. Het resultaat moet de album titel, het media type en het genre bevatten. Schrijf een query die alle genres weergeeft waarvoor er geen tracks bestaan. GROUP BY Soms willen we data aggregeren. In Basic Engineering Skills in Python werd aggregratie gebruikt om bijvoorbeeld de som van een lijst te nemen, of met funtools.reduce() een custom functie los te laten op een lijst. (Dit gaan we ook nog zien in het hoofdstuk rond NoSQL \u0026ndash; Advanced map-reduce queries).\nIn RDBMS bestaan hiervoor een aantal verschillende functies. De meest courante zijn hieronder te vinden:\nMAX() MIN() COUNT() AVG() SUM() Elke waarde die je extra selecteert in een query bovenop een aggregate function, moet in een GROUP BY clause komen. Hoe ziet dit er dan bijvoorbeeld uit?\nSELECT BillingCity, SUM(Total) FROM Invoices GROUP BY BillingCity Zonder GROUP BY statement krijg je ofwel een fout ofwel maar één record terug, zoals in SQLite.\nHAVING Als we willen filteren op een grouping function, dan gaat dat niet via een WHERE clause, dan krijg je namelijk een foutmelding:\nSELECT BillingCity, count(*) FROM invoices WHERE count(*) \u0026gt; 2 GROUP BY BillingCity Om te filteren op een grouping function schrijven we dit in een HAVING clause die de query gebruikerlijks afsluit:\nSELECT BillingCity, count(*) FROM invoices GROUP BY BillingCity HAVING count(*) \u0026gt; 2 Schrijf een query die het aantal Invoices laat zien voor 2009 en 2011. Schrijf een query die het aantal invoices per land laat zien. Schrijf een query die per Invoice ID het aantal invoice lijnen laat zien. Schrijf een query die de naam van elke playlist laat zien, alsook het aantal tracks in elke playlist. Schrijf een query die alle data uit de Invoices tabel laat zien, aangevuld met het aantal invoice lijnen. Schrijf een query die de totale verkoopcijfers per Sales Agent laat zien. Schrijf een query die laat zien welke Sales Agent de grootste verkoopcijfers heeft voor 2009. Schrijf een query die laat zien welke Sales Agent de grootste verkoopcijfers heeft voor 2010. Schrijf een query die laat zien welke Sales Agent de grootste verkoopcijfers heeft over alle jaren heen. Schrijf een query die het aantal Customers laat zien per Sales Agent. Schrijf een query die de totale verkoopcijfers per land laat zien. In welk land werd er het meest uitgegeven? Schrijf een query die laat zien welke track er in 2013 het meest werd verkocht. Schrijf een query die laat zien wat de top 5 tracks zijn die ooit werden verkocht. Schrijf een query die laat zien wie de top 3 artiesten zijn die het meest verkocht werden. Schrijf een query die laat zien welk media type het meest verkocht werd. Schrijf een query die de tracks laat zien die meer dan 4 keer verkocht zijn. Subqueries Een query die we uitvoeren geeft een set van resultaten terug. Die set kunnen we opnieuw gebruiken als input voor een nieuwe query. We kunnen die set op verschillende plaatsen gebruiken als input voor een nieuwe query. Hieronder een aantal voorbeelden.\nIn een WHERE clause SELECT * FROM invoice_items WHERE invoice_items.TrackId IN ( SELECT tracks.TrackId FROM tracks WHERE name LIKE \u0026#39;%hell%\u0026#39; ) In een FROM clause SELECT * FROM ( SELECT tracks.TrackId, tracks.Name FROM tracks WHERE name LIKE \u0026#39;%hell%\u0026#39; ) In een JOIN clause SELECT * FROM tracks INNER JOIN ( SELECT tracks.TrackId, tracks.Name FROM tracks WHERE name LIKE \u0026#39;%hell%\u0026#39; ) hell_tracks ON hell_tracks.TrackId = tracks.TrackId Subqueries in een WHERE IN statement worden geëvauleerd voor elke voor elke rij uit de outer query, dus zijn eigenlijk niet zo heel performant. We kunnen dat iets verbeteren door dat te herschrijven naar een WHERE EXISTS statement. Zie hieronder.\nSELECT * FROM invoice_items WHERE EXISTS ( SELECT 1 FROM tracks WHERE name LIKE \u0026#39;%hell%\u0026#39; AND tracks.TrackId = invoice_items.TrackId ) De IN clause gaat een subquery volledig ophalen om alle rijen te hebben om dan in die lijst van rijen te kunnen zoeken. Een EXISTS clause gaat een subquery maar zo lang uitvoeren tot er een resultaat gevonden is. Als de tabel uit de subquery 1000 rijen bevat en er wordt een match gevonden op rij 200, dan gaan de andere 800 niet meer geëvauleerd worden.\nDe meeste van deze queries kunnen ook geschreven worden met een JOIN statement. Dit is echter niet waar we hier op willen oefenen. Los dus volgende oefeningen op met minstens één subquery. Als je hier moeite mee hebt kan her handig zijn om eerst een werkende query te bekomen met JOIN en die dan om te vormen naar een subquery.\nSchrijf een query die alle invoices laat zien die een track bevatten van Iron Maiden. Schrijf een query die alle invoices laat zien die verkocht werden door Margaret Park. Schrijf een query die alle genres laat zien waarvoor er geen track bestaat. Schrijf een query die alle invoices laat zien waarvan de prijs groter is dan het gemiddelde van alle invoices. Schrijf een query die alle invoices laat zien waarin een Metallica track verkocht is, waarvan de prijs groter is dan het gemiddelde van alle invoices waarin een Metallica track verkocht is. Data manipulatie INSERT Met een INSERT Statement gaan we data toevoegen in de database. We gebruiken een column listing om aan te geven welke kolommen, in welke volgorde, we van een waarde kan voorzien. Kolommen die NULL values ondersteunen mogen uit de column listing gelaten worden.\nINSERT INTO Genres(Name) VALUES(\u0026#39;Rock\u0026#39;) Voeg je favoriete album (inclusief artiest en tracks) toe aan de database.\nUPDATE Met een UPDATE statement kunnen we één of meerdere waardes in een set van data aanpassen.\nUPDATE Tracks SET MediaTypeId = 1 WHERE AlbumId = 2 Wijzig de UnitPrice en de Composer voor de 3e track van je toegevoegde album. Wijzig de titel van je favoriete album (zie oefening hierboven).\nDELETE Hiermee kunnen we een set van data verwijderen.\nLET OP! Een DELETE statement zonder WHERE clause verwijdert alles uit de tabel!\nDELETE FROM Genre WHERE Name = \u0026#39;Rock\u0026#39; Verwijder het album (inclusief artiest en tracks) dat je hierboven hebt toegevoegd.\nWat is volgens jou het verschil tussen DELETE FROM zonder WHERE en DROP TABLE?\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/sql-ddl-dml/",
	"title": "2. SQL DDL &amp; DML",
	"tags": [],
	"description": "",
	"content": "SQL DDL \u0026amp; DML Zie menu links.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/transacties/failures-rollbacks/",
	"title": "3. Failures-Rollbacks",
	"tags": [],
	"description": "",
	"content": "Voorbereidende CREATE statements (Dit is SQLite syntax!) Zie SQLite manual:\nDROP TABLE IF EXISTS student; CREATE TABLE student( studnr INT NOT NULL PRIMARY KEY, naam VARCHAR(200) NOT NULL, voornaam VARCHAR(200), goedbezig BOOL ); DROP TABLE IF EXISTS log; CREATE TABLE log( id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, date DATETIME DEFAULT CURRENT_TIMESTAMP, foreign_id INT NOT NULL, msg TEXT ); INSERT INTO student(studnr, naam, voornaam, goedbezig) VALUES (123, \u0026#39;Trekhaak\u0026#39;, \u0026#39;Jaak\u0026#39;, 0); INSERT INTO student(studnr, naam, voornaam, goedbezig) VALUES (456, \u0026#39;Peeters\u0026#39;, \u0026#39;Jos\u0026#39;, 0); INSERT INTO student(studnr, naam, voornaam, goedbezig) VALUES (890, \u0026#39;Dongmans\u0026#39;, \u0026#39;Ding\u0026#39;, 1); 1. System failure simulatie 1.1 In SQLite met DB Browser Gegeven een aantal SQL statements, waarvan niet alle statements kloppen, maar die wel allemaal bij elkaar horen als één atomaire transactie. Dat betekent dat als er één van die statements misloopt, de rest teruggedraait zou moeten worden. Het spreekt voor zich dat zonder speciale handelingen, zoals het beheren van transacties, dit niet gebeurt. Een eenvoudig voorbeeld demonstreert dit.\nUPDATE student SET voornaam = \u0026#39;Jaqueline\u0026#39; WHERE studnr = 123; INSERT INTO oeitiskapot; INSERT INTO log(foreign_id, msg) VALUES (123, \u0026#39;Voornaam vergissing\u0026#39;); INSERT INTO student(studnr, naam, voornaam, goedbezig) VALUES (445, \u0026#39;Klakmans\u0026#39;, \u0026#39;Jef\u0026#39;, 1); INSERT INTO log(foreign_id, msg) VALUES (445, \u0026#39;Nieuwe student registratie\u0026#39;); Plak dit in de \u0026ldquo;Execute SQL\u0026rdquo; tab van de SQLite DB Browser. Het resultaat is een foutboodschap:\nnear \u0026#34;;\u0026#34;: syntax error: INSERT INTO oeitiskapot; Maar: het eerste UPDATE statement, voor de foute regel, is wel uitgevoerd:\nOefeningen Probeer bovenstaande voorbeeld zelf uit in de SQLite DB Browser. Als je jezelf ervan verzekerd hebt dat inderdaad het eerste UPDATE statement wordt uitgevoerd, terwijl wij dat in één ACID blok willen, ga dan over naar de volgende oefening. In SQLite is het starten van een transactie erg eenvoudig: zie SQLite transaction tutorials van tutorialspoint.com. BEGIN; en COMMIT; zijn voldoende. Probeer dit uit in bovenstaande voorbeeld om er voor te zorgen dat de voornaam van Jaak niet wordt gewijzigd. Om met een \u0026ldquo;clean slate\u0026rdquo; te herbeginnen kan je gewoon de voorbereidende SQL code copy/pasten en opnieuw uitvoeren. Merk op dat dit nog steeds het ongewenst effect heeft dat de student zijn/haar naam wordt gewijzigd. We moeten expliciet zelf ROLLBACK; aanroepen. Probeer een nieuwe student toe te voegen: eentje met studentennummer, en eentje zonder. Dat tweede kan in principe niet door de NOT NULL constraint. Wrap beide statements in een transactie. Let Op: Het zou kunnen dat SQLite de volgende fout geeft: cannot start a transaction within a transaction: BEGIN;. Queries die geplakt worden in het \u0026ldquo;execute SQL\u0026rdquo; scherm worden meestal (onzichtbaar, achter de schermen) gewrapped in transacties. Stop de huidige transactie door COMMIT; uit te voeren met de knop \u0026ldquo;execute single SQL line\u0026rdquo;.\nLet Op: Het zou kunnen dat BEGIN TRANSACTION; de transactie niet goed encapsuleert, maar simpelweg BEGIN; wel. Het TRANSACTION keyword is optioneel volgens de SQLite docs en lijkt, afhankelijk van de geïnstalleerde SQLite versie, ander gedrag te vertonen.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/apis/basics/",
	"title": "1. API Basics",
	"tags": [],
	"description": "",
	"content": "Layered Application Tiers In software engineering worden applicaties logisch opgesplitst in verschillende \u0026ldquo;tiers\u0026rdquo;. Een typische 3-Tier webapplicatie bestaat uit 3 lagen: de laag die de gebruiker te zien krijgt\u0026mdash;de UI, bestaande uit HTML en CSS, de backend\u0026mdash;een server waar de requests naartoe worden gestuurd en die de aanvragen verwerkt, en een data laag die onze database voorstelt. Onderstaand schema vat dit samen (via Trevor N. Mudge):\nIn de praktijk variëert deze tier benadering van project tot project.\nTot nu toe in dit vak hebben we ons toegelegd op Tier 3: de data laag. Zonder frontend applicatie laag kan een gebruiker echter niet interageren met deze database; er it dus minstens één extra tier nodig.\nOm ons in het vak databases te kunnen focusen op de data en de integratie van de data met de software gaan wij ons toeleggen op Tier 2 + 3. Het webgedeelte valt weg en om een UI te maken herbruiken we de opgebouwde JavaFX kennis van het eerstejaarsvak Software Ontwerp in Java (INF1). We gaan dus terug Java applicaties maken en die verbinden met onze database schema\u0026rsquo;s. Een simpele 2-tier applicatie is ook wel een client-server applicatie genoemd. In ons geval is de server de database, die in principe op een andere machine kan gedeployed worden. Voor de oefeningen vereenvoudigen we dit systeem door gebruik te maken van een embedded database die in het lokaal geheugen kan draaien.\nWe teren dus op de volgende kennis:\nHet opstellen van Gradle projecten in Java (SES); JavaFX UIs bouwen (INF1); Databases ontwerpen en koppelen (Databases). Problemen met je JDK versie en Gradle versies? Raadpleeg de Gradle Compatibiility Matrix. Gradle 6.7 of hoger ondersteunt JDK15. Gradle 8.5 of hoger ondersteunt JDK21. Let op met syntax wijzigingen bij Gradle 7+! Je Gradle versie verhogen kan door de URL in gradle/gradlew.properties te wijzigen.\nGradle dependency of Git source control problemen? Grijp terug naar de cursus van SES.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/nosql/basics/",
	"title": "1. NoSQL Basics",
	"tags": [],
	"description": "",
	"content": "Het schaalbaarheid probleem Het probleem met RDMS (relationele database management systems) is vaak schaalbaarheid. Gezien de ACID data validity voorwaarden is altijd de vraag: is dit schaalbaar?\nOptie 1: Vertical scaling De makkelijke oplossing is \u0026ldquo;scaling up\u0026rdquo;: meer storage, CPU, RAM, \u0026hellip; voorzien zodat er meer cycles kunnen benut worden en hopelijk ook meer transacties concurrent kunnen worden verwerkt (zie transacties basics).\nJe botst hier echter snel op hardware limitaties\u0026mdash;niet alles is opgelost met een latje RAM.\nOptie 2: Horizontal scaling In plaats van \u0026ldquo;omhoog\u0026rdquo; te gaan en meer hardware in hetzelfde systeem te steken, kunnen we ook meer hardware op verschillende plaatsen in het netwerk zetten: scaling out in clusters. Dit noemen we horizontaal scalen: meer kleintjes die gedistribueerd hetzelfde doen.\nDeze oplossing introduceert echter een ander probleem: data consistency is niet altijd gegarandeerd. Als ik iets in één server van een cluster bewaar, wordt dit dan onmiddellijk in de andere ook bewaard? Wat als er eentje uitvalt, en dat net mijn access point was? Op welke manier wordt die data verdeeld binnen de cluster? Enzovoort. Distributed computing is een erg complex domein binnen de informatica. We raken in dit vak enkel de top van de ijsberg aan.\nWat is een \u0026ldquo;cluster\u0026rdquo; precies? Denk aan een verzameling van grote data centers: twee of meer fysieke centra waar enorm veel servers geplaatst worden. Eén server kan je eigen laptop zijn. Je kan ook verschillende virtuele servers op je laptop draaien: dat is een node. (We hanteren hier de hierarchie van elementen volgens Cassandara) Cluster \u0026laquo; Data Center \u0026laquo; Rack \u0026laquo; Server \u0026laquo; Node\nEen typische relationele database, met zijn ACID eigenschappen, maakt horizontaal schalen dus moeilijk. Consistentie en availability maakt partitioning tot een uitdaging. Dit is ook zichtbaar in het CAP probleem; of \u0026ldquo;Consistency, Availability, Partitioning Tolerance\u0026rdquo; probleem. Wil je inzetten op partitioning, dan is de kans groot dat je zal moeten inboeten op consistency en availability. De volgende figuur illustreert dit probleem:\nHet CAP probleem. src: freecodecamp.org\rFlexibiliteit van horizontal scaling krijgen we door af te stappen van een typische RDBMS, en te kijken naar wat er kan als de R (relational) wegvalt\u0026mdash;ofwel noSQL databases. De populariteit hiervan groeide exponentieel sinds scalability een groter probleem werd: denk aan gigantische data warehouses van Amazon, Google\u0026rsquo;s zoek engine, Facebook pagina\u0026rsquo;s, enzovoort. NoSQL systemen garanderen ook consistentie\u0026mdash;alleen niet onmiddellijk: dit heet eventual consistency.\nDus, horizontal scaling is eenvoudiger met NoSQL:\nEr is géén relationele data; Er is géén (onmiddellijke) consistentie\u0026mdash;dus ook geen coordinatie overhead!; Dit is zeer goed scalable. NoSQL basics Een vergelijking van eigenschappen tussen een relationele en niet-relationele database systeem:\nEigenschap Relationeel NoSQL Data paradigma relationeel 4 types: key/val, docs, \u0026hellip; (s3.2) Distributie Single-node Distributed Scalability Vertical Horizontal, replication Structuur Schema-based Flexible Querty taal SQL Specialized (JavaScript) Transacties ACID BASE Features views/procs/\u0026hellip; basic API Data vol. \u0026ldquo;normal\u0026rdquo; \u0026ldquo;huge amounts\u0026rdquo; *BASE staat voor Basically Available, Soft state, Eventual concistency\nMerk op dat het niet altijd de beste oplossing is om naar een NoSQL DB te grijpen. Wanneer dan wel of niet? De volgende vragen kunnen hierbij helpen:\nBevat data veel/weinig relaties? Komt er enorm veel data/sec. binnen? Replication vereisten? Scripting mogelijkheden? Bestaande kennis in bedrijf? \u0026hellip; Klassieke relationele databases zijn nog steeds een van de meestgebruikte ter wereld, maar dat wil niet zeggen dat er geen (populaire) alternatieven zijn. Kijk eens naar de db-engines.com ranking trends op db-engines.com:\nDe drie bovenste lijnen zijn Oracle, MySQL en Microsoft SQL Server, de drie giganten die alledrie relationele DBMS systemen zijn. PostgresQL, de oranje stijgende lijn, is volgende\u0026mdash;ook SQL. Maar daarnaast volgen MongoDB, Cassandra, Redis, DynamoDB, \u0026hellip;\u0026mdash;allemaal verschillende soorten noSQL alternatieven.\nNoSQL Types 4 NoSQL types. src: improgrammer.net\rEr zijn, zoals bovenstaande figuur aangeeft, 4 grote groepen van NoSQL systemen:\n1. Document stores. Hier bewaar je een \u0026ldquo;document\u0026rdquo; in, dat meestal in JSON-formaat is, zoals:\n{ \u0026#34;bedrag\u0026#34;: 100.3, \u0026#34;gebruiker\u0026#34;: \u0026#34;Jos Klakmans\u0026#34;, \u0026#34;Stad\u0026#34;: \u0026#34;Diepenbeek\u0026#34;, \u0026#34;certificaten\u0026#34;: [{ \u0026#34;type\u0026#34;: 1, \u0026#34;naam\u0026#34;: \u0026#34;Master in de bliebloe\u0026#34; }, { \u0026#34;type\u0026#34;: 2, \u0026#34;naam\u0026#34;: \u0026#34;Bachelor in de blakkiela\u0026#34; }] } Merk op dat hier geen relaties worden gelegd, alhoewel dat wel kan: bijvoorbeeld document 1 kan een property { id: 1 } hebben, en document 2 { id: 2, relatedDocumentId: 1 }. Dit echter veel gebruiken zal een performance hit geven: document stores dienen voornamelijk om gigantisch veel onafhankelijke data te bewaren, op een ongestructureerde manier. Er zijn geen table definities: een key meer of minder maakt niet uit.\nNoSQL: { name: 'Jos' } -\u0026gt; { name: 'Jos', well-behaved: true }. Geen INSERT INTO student(name) VALUES (\u0026quot;Jos\u0026quot;) dus! Ook hier wordt intern hashing gebruikt (zie onder): Het document { name: 'Jos' } wordt intern opgeslaan als { name: 'Jos', _id: 23235435 }. Data retrieval snelheid blijft belangrijk, dus extra indexen/views kunnen door de gebruiker zelf worden aangemaakt (zie volgende hoofdstukken).\nOm documenten te ordenen worden soms wel collecties aangemaakt, maar dit is bijna altijd optioneel!\nWe zullen ons in deze cursus focussen op document stores. Zie NoSQL - document stores om een idee te hebben hoe dit in de praktijk gebruikt wordt.\n2. Graph-based oplossingen. Wat als we toch veel relationele gegevens hebben, maar het nog steeds over (1) ongestructureerde data gaat en (2) te veel is voor in één klassiek RDBMS systeem te bewaren? Als de relaties de data zelf zijn, dan hebben we een grafen-gebaseerde oplossing nodig. Hier zijn géén dure JOIN statements nodig om de relaties ad-hoc te maken. Een typische toepassing hiervan zou social graphs zijn.\nEen voorbeeld subgraph visualisatie in Neo4j.\rStel dat je alle boeken wilt ophalen geschreven door een bepaalde auteur (= de relatie). In SQL, waar de data typisch in twee tabellen leeft (book en author), heb je een (impliciete) JOIN nodig:\nSELECT book, title FROM book, author, books_authors\rWHERE author.id = books_authors.author_id\rAND book.id = books_authors.book_id\rAND author.name = \u0026#34;De Jos\u0026#34; Maar in Cypher, de querytaal van grafendatabase Neo4J, ziet die query er als volgt uit:\nMATCH (b:Book) \u0026lt;- [ :WRITTEN_BY]-(a:Author)\rWHERE a.name = \u0026#34;De Jos\u0026#34;\rRETURN b.title Data wordt op basis van WRITTEN_BY relatie eigenschap opgehaald. Relationele data\u0026mdash;de letterlijke relaties\u0026mdash;zijn hier altijd expliciet, en niet verborgen in foreign key constraints.\n3. Key-Value stores. Dit is de eenvoudigste soort, waarbij gewoon blobs van data in een hash table opgeslagen worden, zoals jullie gewoon zijn in Java:\nMap\u0026lt;String, Persoon\u0026gt; leeftijden = new HashMap\u0026lt;\u0026gt;(); leeftijden.put(\u0026#34;Wilfried\u0026#34;, new Persoon(\u0026#34;Wilfried\u0026#34;, 20)); leeftijden.put(\u0026#34;Seppe\u0026#34;, new Persoon(\u0026#34;Seppe\u0026#34;, 30)); leeftijden.put(\u0026#34;Bart\u0026#34;, new Persoon(\u0026#34;Bart\u0026#34;, 40)); leeftijden.put(\u0026#34;Jeanne\u0026#34;, new Persoon(\u0026#34;Jeanne\u0026#34;, 18)); Hash functies In dit voorbeeld stopt de HashMap met bestaan zodra die out of scope gaat op je eigen machine, maar er zijn ook distributed hash tables. Hier is de hash functie het belangrijkste onderdeel, die de onderliggende key genereerd en dus bepaald in welke \u0026ldquo;bucket\u0026rdquo; een waarde wordt opgeslagen\u0026mdash;en dus ook, op welke server in een cluster. Een goede hash functie moet (1) deterministisch zijn: atlijd dezelfde hash waarde voor dezelfe input genereren; (2) uniform zijn: er moet een goede verdeling zijn van de output range; en (3) een vaste grootte hebben zodat het makkelijker is voor de data structuur om de hash waarde te bewaren.\nVrijwel alle NoSQL databases gebruiken achterliggend hashing technieken om horizontal scalability makkelijker te maken. Als alle hash values mooi verdeeld worden, kan dit ook mooi over verschillende databases verdeeld worden.\nPartioning/sharding In bovenstaand voorbeeld worden de persoonsgegevens verspreid over 3 verschillende servers door de hashing \u0026ldquo;index\u0026rdquo; (mod3 + 1). Data partitioning noemen we ook wel sharding waarbij een individuele partitie een shard is. Om zo efficient mogelijk te partitioneren schakel je best servers aan elkaar in een soort van \u0026ldquo;ring\u0026rdquo;, zoals in dit schema:\nRing partitioning vereist wel consistent hashing functies, anders klopt de node verdeling (de kleuren in het schema) niet meer. Om zo effient mogelijk data door te geven (replication, zie later NoSQL: replication) hebben nodes weet van elkaar. Het is echter nog steeds niet mogelijk om de ACID regels te volgen: een gedistribueerd systeem zoals deze ring kan nooit én consistent én available én partition tolerant zijn.\nWat is dan een oplossing voor NoSQL systemen? BASE in plaats van ACID:\nBasically Available (BA); elke (gebruikelijk HTTP-based) request ontvangt een respons, hetzij een 200 (OK), hetzij een 4xx/5xx (een externe/interne fout). Ook al zijn niet alle nodes geupdate, toch kan er al een 201 worden teruggegeven\u0026mdash;asynchroon dus. Soft state (S); sate kan wijzigen, ook zonder input! We weten dus nooit exact wat er in de shards zit. Read requests zijn soms out-of-date omdat een shard update in de ring partitie plaats aan het vinden was, maar dat één bepaalde shard nog niet bereikte\u0026hellip; Eventually Consistent (E); NoSQL biedt de \u0026ldquo;ooit is het wel consistent\u0026rdquo; mode aan. In de praktijk verschilt het van NoSQL database tot database systeem hoe dicht deze BASE regels tegen de ACID regels aanleunen. De document-based CouchDB, die we later zullen in detail bekijken, ondersteunt ook vormen van transacties en dergelijke, wat het eerder iets ACID-achtig maakt.\nMemcached Memcached is een distributed in-memory key/value store die op grote schaal gebruikt kan worden als caching mechanisme. Systemen als Memcached zijn enorm performant en worden vaak gebruikt als caching database die geplaatst wordt voor de eigenlijke RDBMS:\ngraph LR;\ruser[User]\rcache{Cache DB}\rdb{Relationele DB}\ruser --\u003e|Haal genres op| cache\rcache --\u003e|cache hit| user cache --\u003e|cache miss| db\rdb --\u003e|refresh| cache\rHet feit dat Netflix Memcached sponsort zegt genoeg. Memcached gebruiken is erg eenvoudig en gewoon een kwestie van de API in Java/Kotlin aan te spreken om data te feeden/op te halen.\nEen simpel Memcached voorbeeld is terug te vinden onder key-value stores: memcached.\n4. Wide-column databases. Wide-column, of column-based databases, zijn eigenlijk relationele databases op zijn kop\u0026mdash;letterlijk.\nWat is het grootste nadeel van het queryen van relationele databases? Deze zijn row-based: als je alle genres uit een BOEK tabel wilt halen, zal je alle rijen moeten afgaan en daar een DISTINCT op doen\u0026mdash;alles behalve performant. Bijvoorbeeld:\nid genre title price\r1 Fantasy book bla 10\r2 Fantasy another title 20\r3 horror wow-book 10 Hoe haal ik hier alle genres op? SELECT DISTINCT(genre) FROM boeken. Wat is de gemiddelde prijs? SELECT AVG(price) FROM boeken\u0026mdash;ook een erg dure operatie indien er miljoenen records aanwezig zijn. Een snelheidswinst valt te boeken door te werken met indexen, maar daar lossen we niet alles mee op.\nWat nu als je de kolommen als rijen beschouwt, op deze manier:\ngenre: fantasy:1,2 horror: 3\rtitle: book bla:1, another title:2 wow-book: 3\rprice: 10:1,3 20:2 Wat is nu de gemiddelde prijs? Haal 1 \u0026ldquo;rij\u0026rdquo; op en deel door het aantal. Welke genres zijn er zoal? De eerste rij is al onmiddellijk het antwoord! We verzamelen hier dus vertical slices van data, wat erg belangrijk kan zijn voor Business Intelligence (BI): super-linked data tussen de \u0026ldquo;echte\u0026rdquo; row-based data.\nDe meest gebruikte column-DB is Cassandra. Op de website staat:\nManage massive amounts of data, fast, without losing sleep.\nCassandra komt met in-memory buffers, tracking \u0026amp; monitoring, \u0026hellip;\nCase Studies Welke database systemen\u0026mdash;of een combinatie ervan\u0026mdash;denk je dat de volgende grote bedrijven hanteren voor hun producten?\nhttps://www.benl.ebay.be/ Hint: https://www.slideshare.net/jaykumarpatel/cassandra-at-ebay-13920376 (2012) https://www.army.mil/ Hint: https://go.neo4j.com/rs/710-RRC-335/images/Neo4j-case-study-US-army-EN-US.pdf (2019) https://spotify.com/ Hint: https://engineering.atspotify.com/2015/01/09/personalization-at-spotify-using-cassandra/ (2015) https://uber.com/ Hint: http://highscalability.com/blog/2016/9/28/how-uber-manages-a-million-writes-per-second-using-mesos-and.html (2016) Denkvragen Is een RDBMS of een NoSQL database geschikter om aan \u0026ldquo;Big Data\u0026rdquo; te doen? Waarom wel/niet? Waarom vereist ring partitioning consistent hashing? Wat heeft een hashing functie te maken met het horizontaal kunnen schalen van data in een DBMS? Waarom gebruiken zo veel grote bedrijven een combinatie van verschillende DBMS systemen? Zie je hier ook nadelen in? Wanneer denk je dat een column-based database als Cassandra nuttig zou zijn? Leg het verschil tussen ACID en BASE uit in functie van de typische eigenschappen van een database. Waarom werkt vertical scaling niet? Waarom wel? "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/apis/jdbc-jdbi/",
	"title": "2. JDBC en JDBI",
	"tags": [],
	"description": "",
	"content": "1.1 Java Database Connectivity (JDBC) 1.1.1 Hoe verbind ik Java met de DB? JDBC is een interface in de JDK die ons in staat stelt om een connectie te openen naar een database. JDBC is een API: een abstracitelaag of een protocol. Dit betekent dat we met JDBC kunnen verbinden naar eender welke server van eender welke flavor: een Oracle SQL, MSSQL, of SQLite database. De database vendor wordt verborgen achter de JDBC laag. Voor deze oefeningen beperken we ons tot SQLite.\nUpdate van de cursustekst en oefeningen zijn onderweg, tegen de volgende les van 29/03 zullen we alles overschakelen naar MYSQL dat jullie eerder al gebruikten met XAMP en phpmyadmin. Enige verschillen met MYSQL zijn:\nMYSQL SQLITE AUTO_INCREMENT AUTOINCREMENT BOOLEAN BOOL Voor elke database moet er dus een vendor-specifieke driver als dependency worden toegevoegd. In het geval van SQLite is dit de sqlite-jdbc driver, de sqlite-jdbc package. JDBC zelf leeft in java.sql en is een integraal onderdeel van de JDK: dit moeten we dus niet apart oplijsten als dependency of downloaden.\ngraph LR;\rJava[Java]\rJDBC[JDBC]\rSQLITE[SQLite-JDBC]\rDB[(SQLite Database)]\rsubgraph Java space\rsubgraph JDK\rJava -.-\u003e JDBC\rend\rJDBC --\u003e SQLITE\rend\rsubgraph DB space\rSQLITE --\u003e DB\rend\rDe sqlite-jdbc package zorgt voor de brug tussen onze Java applicatie en de database, maar we spreken die aan via JDBC.\nEnkele belangrijke statements:\nEen connectie naar een database vastleggen: var connection = DriverManager.getConnection(\u0026quot;jdbc:sqlite:mydb.db\u0026quot;); Een SELECT query uitvoeren: var s = connection.createStatement(); var result = s.executeQuery(\u0026quot;...\u0026quot;); var cell = result.getString(\u0026quot;column\u0026quot;); Een INSERT/UPDATE/\u0026hellip; query uitvoeren (die de structuur of inhoud van de database wijzigt): var s = connection.createStatement(); s.executeUpdate(\u0026quot;...\u0026quot;); Het volgende voorbeeld opent een verbinding naar een DB, maakt een tabel aan, voegt een record toe, en telt het aantal records:\nprivate Connection connection; public void createDb() throws SQLException { connection = DriverManager.getConnection(\u0026#34;jdbc:sqlite:mydb.db\u0026#34;); var s = connection.createStatement(); s.executeUpdate(\u0026#34;CREATE TABLE mijntabel(nr INT); INSERT INTO mijntabel(nr) VALUES(1);\u0026#34;) s.close(); } public void verifyDbContents() throws SQLException { var s = connection.createStatement(); var result = s.executeQuery(\u0026#34;SELECT COUNT(*) FROM mijntabel;\u0026#34;); var count = result.getInt(0); s.close(); assert count == 1; } Gradle dependency: laatste versie van sqlite-jdbc in mvnrepository.com.\nMerk op dat SQLException een checked exception is die je constant moet meespelen in de method signature of expliciet moet opvangen. Het probleem van een try { } catch { } finally { } block is dat in de finally je ook geen close() kan uitvoeren zonder opnieuw een try block te openen\u0026hellip; Inception!\nHet connection.close() statement moet er voor zorgen dat voor elke request de connection netjes wordt afgesloten. Een database heeft meestal een connection pool van x aantel beschikbare connections, bijvoorbeeld 5. Als een connection per request niet wordt gesloten, heeft de voglende bezoeker van onze website geen enkele kans om zijn zoekquery te lanceren, omdat de database dan zegt dat alle connecties zijn opgebruikt!\nMerk op dat de String jdbc:sqlite:mydb.db een lokale SQLite database file aanmaakt op het huidig relatief pad, zodat je met SQLite Explorer data kan inspecteren. Deze file wordt herbruikt: indien je een tabel aanmaakt de eerste keer, gaat dit de tweede keer crashen met table already exists. Houd hier dus rekening mee (e.v.t. met IF NOT EXISTS). Je kan ook een in-memory database aanmaken, die volledig in RAM leeft en bij elke opstart opnieuw wordt aangemaakt, met de String jdbc:sqlite:memory.\nWerk je met een andere database maar heb je geen idee hoe die speciale connection string te vormen? Geen probleem, daarvoor dient https://www.connectionstrings.com/. Bijvoorbeeld, een connectie naar de Microsoft Azure cloud kan met de volgende syntax:\nServer=tcp:myserver.database.windows.net,1433;Database=myDataBase;User ID=mylogin@myserver;Password=myPassword;Trusted_Connection=False;Encrypt=True; Het is de connection string die bepaalt welke dependency binding gebruikt wordt! Dit noemen we late binding: er is geen expliciete referentie naar iets van SQLite in de Java code; we werken enkel met JDBC zelf. Als je de vendor driver vergeet toe te voegen als Gradle dependency gebeurt er dit:\nException in thread \u0026#34;main\u0026#34; java.sql.SQLException: No suitable driver found for jdbc:sqlite:mydb.db\rat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:702)\rat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:251)\rat Demo.main(Demo.java:8) In-memory databases (ConStr. jdbc:sqlite:memory), die met een lege database vertrekken, en constant CREATE TABLE() statements issuen, vervuilen je broncode. Als je veel SQL moet uitvoeren is het beter om dit in een .sql bestand te bewaren in src/main/resources en eenmalig in te lezen als SQL met new String(Files.readAllBytes(Paths.g));, om te kunnen uitvoeren via statement.executeUpdate(). Zie het jdbc-repo-start project op GitHub als voorbeeld.\n1.1.2 Queries/Objecten in JDBC Stel dat we dezelfde studenten willen inladen in een Student klasse instantie: van de TABLE STUDENT naar de class Student. In geval van JDBC is dat veel handwerk:\nMaak een verbinding met de database. Voer de SELECT statements uit. Loop door de ResultSet en maak een nieuwe Student instantie aan. Vang alle mogelijke fouten zelf op: wat met lege kolommen, null? Wat met INTEGER kolommen die je wilt mappen op een String property? Om van de huidige resultatenrij naar de volgende te springen in ResultSet gebruikt men de methode next() in een typisch while() formaat:\nvar result = statement.executeQuery(\u0026#34;SELECT * FROM iets\u0026#34;); while(result.next()) { var eenString = result.getString(\u0026#34;kolomnaam\u0026#34;); // doe iets! } Zie ook ResultSet Oracle Javadoc.\nAangezien we reeds hebben kennis gemaakt met de (beperkte) API, schakelen we onmiddellijk over naar de oefeningen:\n1.1.3 Oefeningen Gebruik voor de oefeningen de student tabel statements uit RDBMS Transacties - Failures \u0026amp; Rollbacks.\nMaak (én test!) een klasse StudentRepository die de volgende methode implementeert. Zoals je ziet is het de bedoeling dat de JDBC Connection instance elders wordt aangemaakt, bijvoorbeeld in een aparte ConnectionManager klasse. public class StudentRepository { public StudentRepository(Connection connection); public List\u0026lt;Student\u0026gt; getStudentsByName(String name); } Hoe zou je bovenstaande StudentRepository unit (integratie) testen, zonder de \u0026ldquo;productie database\u0026rdquo; op te vullen met testdata? (Hint: kijk naar het constructor argument). Hoe kan je getStudentsByName() testen zonder de volgende oefening afgewerkt te hebben, die nieuwe studenten bewaren pas mogelijk maakt? Breid dit uit met saveNewStudent(Student). Breid dit uit met updateStudent(Student). Wat moet je doen als deze student nog niet in de database zit? Welke gegevens update je wel en welke niet? Merk op dat elke keer als je je project opstart je geen CREATE TABLE student kan uitvoeren als je een file-based SQLite bestand hanteert: eens de tabel is aangemaakt geeft een nieuwe create foutmeldingen. DROP TABLE IF EXISTS student; lost dit op, maar daardoor ben je ook altijd je data kwijt. Hoe los je dit probleem op? Stel dat een Student is ingeschreven in een Cursus met properties naam (vb. \u0026ldquo;databases\u0026rdquo;) en ects (vb. 4). Maak een CursusRepository om nieuwe cursussen te bewaren. Hoe link je de Student klasse met de Cursus klasse? wat verandert er in de query van getStudentsByName()? Tips:\nexecuteUpdate() van een Statement is erg omslachtig als je een string moet stamenstellen die een INSERT query voorstelt (haakjes, enkele quotes, \u0026hellip;). Wat meer is, als de input van een UI komt, kan dit gehacked worden, door zelf de quote te sluiten in de string. Dit noemt men SQL Injection, en om dat te vermijden gebruik je in JDBC de prepareStatement() methode. Zie JDBC Basics: Prepared Statements. De String die je meegeeft bevat in de plaats van parameters een vraagteken: INSERT INTO STUDENT(bla, bla) VALUES(?, ?). Die parameters vul je daarna aan met preparedStatement.setString() of setInt(). Op die manier is de code zowel netjes als injectie-vrij! Als je data wenst op te halen dat is verspreid over verschillende tabellen, is de kans groot dat een JOIN SQL statement nodig is. Probeer eerst de query te schrijven in de SQLite DB Browser tool. De Java objecten opvullen is de laatste taak. "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/nosql/keyvaluestores/",
	"title": "2. Key-value stores",
	"tags": [],
	"description": "",
	"content": "1.1 Persistente Hashmaps De eenvoudigst mogelijke noSQL database die gebruik maakt van key/values is een simpele HashMap\u0026lt;K,V\u0026gt; die je zelf serialiseert naar een flat file op de HDD. Een netwerk share kan dit bestand delen, maar locking systemen zullen moeten ingebouwd worden om te voorkomen dat dit bestand corrupt wordt.\nDe \u0026ldquo;oude\u0026rdquo; manier om dit te doen op de JVM is gebruik te maken van FileOutputStream:\npublic static void main(String[] args) throws IOException { var db = new HashMap\u0026lt;String, Object\u0026gt;(); db.put(\u0026#34;joske\u0026#34;, new Student(\u0026#34;Joske\u0026#34;, 11)); var file = new File(\u0026#34;database.db\u0026#34;); var f = new FileOutputStream(file); var s = new ObjectOutputStream(f); s.writeObject(db); s.close(); } Inlezen werkt op dezelfde manier, met FileInputStream en ObjectInputStream. Hoe je Student klasse wordt geserialiseerd kan je zelf kiezen, maar een vereiste is dat je de interface Serializable implementeert!\nMet bovenstaande interface kan je de student terug uitlezen:\nvar s = new ObjectInputStream(new FileInputStream(\u0026#34;database.db\u0026#34;)); Map\u0026lt;String, Object\u0026gt; map = (Map\u0026lt;String, Object\u0026gt;) s.readObject(); s.close(); Student joske = (Student) map.get(\u0026#34;joske\u0026#34;); System.out.println(joske.getName()); 1.1.1 Oefeningen Werk bovenstaand voorbeeld uit en persisteer een aantal studenten met de volgende klasse: public class Student { private final String name; private final int age; public Student(String name, int age) { this.name = name; this.age = age; } } 1.2 Distributed Hashmaps: Memcached We kunnen eenvoudig een verbinding maken met een (of meerdere) Memcached server via de Memcached Java client van net.spy.spymemcached (zie mvn repo: https://mvnrepository.com/artifact/net.spy/spymemcached). Dit hoeft maar één regel code te zijn: (zie memcached javadocs)\nvar client = new MemcachedClient(new InetSocketAddress(\u0026#34;127.0.0.1\u0026#34;, 11211)); // bewaar een student onder key \u0026#34;joskey\u0026#34; voor één uur (3600s) client.set(\u0026#34;joskey\u0026#34;, 3600, new Student(\u0026#34;Jos\u0026#34;, 20)); // retrieve object var restoredStudent = (Student) client.get(\u0026#34;Jos\u0026#34;); De client code vereist een werkende memcached server zoals https://www.memcached.org, in bovenstaand voorbeeld draaiend op poort 11211. Je kan dit zelf compileren onder UNIX of Msys in Windows. We gaan voor de oefeningen hier niet verder op in.\nDenkvragen Welke beperkingen zijn er verbonden aan het geserialiseerd database bestand doorgeven aan andere medestudenten? Op welke manier kan je zo verschillende \u0026lsquo;clients\u0026rsquo; verbinden aan één database \u0026lsquo;server\u0026rsquo;? "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/nosql/documentstores/",
	"title": "3. Document stores",
	"tags": [],
	"description": "",
	"content": "0. Data filtering: recap Wat is een \u0026ldquo;mapreduce\u0026rdquo; functie nu weer precies? Weet je nog, in het eerstejaarsvak BES, in Python? Stel, we hebben een array [1, 2, 3, 4] en willen alle elementen verdubbelen. Dat kan erg eenvoudig met een list(map(lambda...)) statement:\nrange = [1, 2, 3, 4] result = list(map(lambda x: x * 2, range)) print(result) Hier gebruikten we een \u0026ldquo;lambda\u0026rdquo; om voor elk element een functie los te laten, die dat element transformeert, ofwel \u0026ldquo;mapt\u0026rdquo;. Python\u0026rsquo;s map() functioneert exact hetzelfde als JavaScript\u0026rsquo;s map()\u0026mdash;evenals reduce() en filter(). Omdat we met een JS-based document store gaan werken is het belangrijk om te weten hoe je bovenstaande principes in JavaScript uitvoert.\nOefening 1 Zoek leerlingen ouder dan 20 en geef hun naam terug. De leerlingen zitten in de volgende JS array: const studenten = [{age: 11, name: 'jos'}, {age: 21, name: 'jef'}].\nOplossing:\nstudenten.filter(function(student) { return student.age \u0026gt; 20 }).map(function(student) { return student.name }) // kan ook met oneliner: studenten.filter(s =\u0026gt; s.age \u0026gt; 20).map(s =\u0026gt; s.name) filtered = filter(lambda student: student.age \u0026gt; 20, studenten) list(map(lambda student: student.name, filtered)) Kopieer bovenstaand voorbeeld in je browser developer console en kijk wat er gebeurt. Het resultaat zou een openklapbare Array [ \u0026quot;jef\u0026quot; ] moeten zijn.\nWe chainen (sequentieel combineren) hier dus filter() en daarna map(). De filter() geeft student Jef terug in een array ([{age: 21, name: 'jef'}]), waarna de map() voor elk element in die array (maar eentje), een transformatie doorvoert: van {age: 21, name: 'jef'} naar 'jef' via student.name.\nOefening 2 Wat is de som van de leeftijden van de studenten? 11 + 21 = 32. Hoe kunnen we dit functioneel schrijven met behulp van een reduce()?\nOplossing:\nstudenten.map(function(student) { return student.age }).reduce(function(age1, age2) { return age1 + age2 }) // kan ook met oneliner: studenten.map(s =\u0026gt; s.age).reduce((a, b) =\u0026gt; a + b) mapped = map(lambda student: student.age, studenten) reduce(lambda age1, age2: age1 + age2, mapped) Kan jij bedenken waarom we hier een map() nodig hebben voor de reduce()?\nMeer informatie: zie Mozilla Developer web docs: map() en reduce/filter. Wanneer je jezelf familiair gemaakt hebt met deze drie functionele (en essentiele!) data manipulatie methodes kan je overgaan tot de hoofdzaak van dit hoofdstuk\u0026mdash;CouchDB en noSQL queries.\n1. Eenvoudige CouchDB Queries Lui in die zetel liggen, en vanaf de bank met gemak query\u0026rsquo;s lanceren? Geen probleem met CouchDB, een open source NoSQL JSON-based document store.\nMango CouchDB heeft een eenvoudige ingebouwde query syntax genaamd Mango. Documentatie op https://github.com/cloudant/mango en http://127.0.0.1:5984/_utils/docs/intro/api.html#documents. Selecteer een database, klik op \u0026ldquo;run a query with Mango\u0026rdquo;:\n{ \u0026#34;selector\u0026#34;: { \u0026#34;year\u0026#34;: 3 } } De selector attribute bepaalt op welke keys er wordt gefilterd. Indexen leggen op zwaar belaste \u0026ldquo;kolommen\u0026rdquo; (keys dus) is in geval van miljarden records zeker geen overbodige luxe.\nMango werkt met een selector syntax (zie documentatie) die impliciet bovenstaande omzet naar {\u0026quot;year\u0026quot;: {\u0026quot;$eq\u0026quot;: 3}}. Er zijn ook andere dollar-based operatoren. Geneste attributes kan je raadplegen met de . separator: {\u0026quot;student.name\u0026quot;: {\u0026quot;eq\u0026quot;: \u0026quot;Joske\u0026quot;}}.\nEen ander voorbeeld: Zoek leerlingen ouder dan 20 en geef hun naam terug:\nfunction(doc) { if(doc.age \u0026gt; 20) { emit(doc._id, doc.name); } } De functie emit(key, value) beslist in welke hoedanigheid een document wordt teruggeven. In dit geval geven we de doc.name terug: de naam van de leerling. We filteren met een simpele if() in de code zelf! Dit kunnen we ook functioneel schrijven in pure JavaScript, los van CouchDB en zijn Mango API, met filter()\u0026mdash;zie de data filtering introductie hierboven.\nNog een ander voorbeeld: van 10 rijen de som teruggeven. In SQL doe je dit met een GROUP BY en COUNT, maar daar bestaat geen alternatief voor in NoSQL, behalve de kracht van JS reduce():\nfunction(keys, values, rereduce) { return values.reduce(function(a, b) { return a + b }) } Opnieuw, hetzelfde kan ook met \u0026ldquo;plain old JavaScript\u0026rdquo;, zoals in de data filtering recap aangegeven ([1, 2, 3, 4].reduce(a, b =\u0026gt; a + b)).\nJe kan in Mango de map() en de reduce() uiteraard ook combineren, net zoals je in JS kan chainen. Hieronder berekenen we bijvoorbeeld de gemiddelde leeftijd van \u0026ldquo;oudere\u0026rdquo; studenten (ouder dan 20 jaar):\nfunction map(doc) { if(doc.age \u0026gt; 20) { emit(doc._id, doc.age); } } function reduce(keys, values, rereduce) { return sum(values) / values.length; } Wat is het verschil tussen function(a, b) {} en (a, b =\u0026gt; ? (Bijna) geen (die jullie moeten kennen). De arrow notatie (=\u0026gt;) is de nieuwe syntax voor anonieme functies aan te maken in JavaScript, en in CouchDB/Mango werken we nog met de oude notatie omdat (1) dit door Couch wordt gegenereerd en (2) de meeste voorbeelden in de documentatie nog zo werken. Dus, function hallokes() { console.log('sup') } is exact hetzelfde als let hallokes = () =\u0026gt; { console.log('sup') }. Zie MDN docs: Arrow function expressions voor meer informatie.\nLET OP:\nreduce() schiet (misschien) in actie als map() nog bezig is. We gaan hier later nog verder op in in NoSQL - Advanced queries.\nDe CouchDB API interface: alles via HTTP(S) curl is een snelle cmd-line tool waarbij je via -X kan meegeven of het over een HTTPs GET, POST, PUT, \u0026hellip; gaat. De DB locatie en poort met het juiste endpoint zijn hier de belangrijkste factoren. Een bepaald document raadplegen doe je met:\ncurl -X GET http://127.0.0.1:5984/[database]/[id] Het resultaat is altijd een geldig JSON object (ook al geef je een ongeldige ID mee): curl -X GET \u0026quot;http://127.0.0.1:5984/courses/aalto-university;bachelor-data-science;professional-development;1\u0026quot;\n{\u0026#34;_id\u0026#34;:\u0026#34;aalto-university;bachelor-data-science;professional-development;1\u0026#34;,\u0026#34;_rev\u0026#34;:\u0026#34;1-f7872c4254bfc2e0e5507502e2fafd6f\u0026#34;,\u0026#34;title\u0026#34;:\u0026#34;Professional Development\u0026#34;,\u0026#34;url\u0026#34;:\u0026#34;https://oodi.aalto.fi/a/opintjakstied.jsp?OpinKohd=1125443391\u0026amp;haettuOpas=-1\u0026#34;,\u0026#34;university\u0026#34;:\u0026#34;Aalto University\u0026#34;,\u0026#34;country\u0026#34;:\u0026#34;Finland\u0026#34;,\u0026#34;category\u0026#34;:\u0026#34;professional\u0026#34;,\u0026#34;ECTS\u0026#34;:5,\u0026#34;year\u0026#34;:1,\u0026#34;optional\u0026#34;:true,\u0026#34;skills\u0026#34;:[\u0026#34;motivate self\u0026#34;,\u0026#34;oral communication\u0026#34;,\u0026#34;self-directed learning\u0026#34;,\u0026#34;self-reflection\u0026#34;,\u0026#34;give/receive feedback\u0026#34;,\u0026#34;set/keep timelines\u0026#34;,\u0026#34;show initiative\u0026#34;],\u0026#34;course\u0026#34;:\u0026#34;Bachelor Data Science\u0026#34;,\u0026#34;lo\u0026#34;:\u0026#34;\u0026lt;br/\u0026gt;Learning Outcomes \u0026lt;br/\u0026gt;Being able to effectively communicate one\u0026#39;s strenghts and professional capacities\u0026lt;br/\u0026gt;Finding one’s own academic and professional interests and taking initiative in one’s own learning\u0026lt;br/\u0026gt;Planning and prototyping one\u0026#39;s own professional development\u0026lt;br/\u0026gt; \u0026lt;br/\u0026gt;Content \u0026lt;br/\u0026gt;The course is integrated to the Aaltonaut program to promote reflection, skill articulation and initiative. The course comprises workshops on different themes related to developing professional skills, independently building a learning portfolio, and taking part in feedback, reflection and goal setting activities.\u0026lt;br/\u0026gt;\u0026lt;br/\u0026gt; \u0026#34;} Indien ongeldig: {\u0026quot;error\u0026quot;:\u0026quot;not_found\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;missing\u0026quot;}.\nIndien geen toegang: {\u0026quot;error\u0026quot;:\u0026quot;unauthorized\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;You are not authorized to access this db.\u0026quot;}. Zie \u0026ldquo;LET OP\u0026rdquo; hieronder\u0026mdash;gebruik het -u argument.\n2. Oefeningen: Voorbereidingswerk Download CouchDB via https://couchdb.apache.org. Download de testdatabase JSON file Maak een nieuwe databases aan via de Fauxton Web-based admin tool. Open CouchDB, ga naar \u0026ldquo;Open Admin Console\u0026rdquo; of surf zelf naar http://127.0.0.1:5984/_utils/. Maak een database aan genaamd \u0026lsquo;courses\u0026rsquo;. Importeer de test JSON met curl in cmdnline: curl -d @dump.db -H \u0026#34;Content-Type: application/json\u0026#34; -X POST http://127.0.0.1:5984/courses/_bulk_docs LET OP:\nBij het aanmaken van een database kan je kiezen tussen partitioned en non-partitioned. Kies hiervoor non-partitioned. Het kan zijn dat CURL een security fout geeft. Bij het installeren van CouchDB moet je een admin username/password meegeven. Voeg aan het einde van je curl commando dit toe: -u username:wachtwoord. Nadien kan je in Fauxton op F5 drukken en zou je dit moeten zien:\nIk heb voor jullie de dump genomen door het omgekeerde (exporteren) te doen:\ncurl -X GET http://127.0.0.1:5984/courses/_all_docs\\?include_docs\\=true \u0026gt; dump.db (Voor mensen op Windows-curl: verander \\ naar /. Ook; bij meegeven van JSON data: enkele quotes \u0026rsquo;\u0026rsquo; vervangen door dubbele \u0026quot;\u0026quot; en dubbele in de enkele escapen met backlash \u0026quot;).\nDaarna volgt wat post-processing (rows wordt docs, elke doc moet in de root array zitten en _rev moet weg) om tot bovenstaande dump.db filte te komen. Dit hebben wij handmatig voor jullie gedaan, zodat de downloadbare file klaar is om te importeren.\n3. Oefeningen met Fauxton/Curl Schrijf een Mango query die cursussen ophaalt waarbij het aantal ECTS punten groter is dan 5. Hoe voer je de query uit oefening 1 uit, zonder de Admin console, maar met curl? Selecteer alle documenten die als skill de waarde self-reflection én show initiative bevatten. Probeer zelf een dump te nemen van je eigen database zoals hierboven beschreven, met het _all_docs endpoint. Wat gebeurt er als je die dump opnieuw wilt importeren via het _bulk_docs endpoint? Maak een nieuwe database genaamd studenten. POST via curl enkele nieuwe documenten, met als template { name: $naam, age: $age, favouriteCourses: [$course1, $course2]} naar deze DB. Controleer in Fauxton of de records correct zijn ingegeven. Verzin zelf wat Mango queries om studenten te filteren. Maak een index aan op age voor je studenten database. Merk op dat indexes, zichtbaar in http://127.0.0.1:5984/_utils/#database/studenten/_index ook worden beschouwd als documenten op zich! Tip: CouchDB heeft een eenvoudige ingebouwde query syntax genaamd Mango. Documentatie op https://github.com/cloudant/mango en https://docs.couchdb.org/en/stable/api/database/find.html. Lees eerst na hoe dit in elkaar zit!\n4. Java Client API Als je geen toegang hebt tot de admin console, of je wenst vanuit een Java programma records weg te schrijven naar een Couch database (of query\u0026rsquo;s uit te voeren), dan heb je de Java API nodig.\nIn principe kan je met eender welke HTTP client REST calls uitvoeren en de responses zelf verwerken. Om het jezelf gemakkelijker te maken, gebruiken we hier ter illustratie LightCouch.\nLees de LightCouch Getting Started guide. Maak een nieuw gradle 6 project met de volgende dependencies:\ndependencies {\rimplementation group: \u0026#39;org.lightcouch\u0026#39;, name: \u0026#39;lightcouch\u0026#39;, version: \u0026#39;0.2.0\u0026#39;\r} In je java/main/resources map dien je een couchdb.properties file aan te maken die verwijst naar de DB URL/poort/naam (zie getting started):\ncouchdb.name=testdb\rcouchdb.createdb.if-not-exist=true\rcouchdb.protocol=http\rcouchdb.host=127.0.0.1\rcouchdb.port=5984\rcouchdb.username=\rcouchdb.password= Vanaf dan is het heel eenvoudig: Maak een CouchDbClient instantie aan. Nu kan je .save(), .shutdown() en .find() uitvoeren. Wat kan je bewaren? POJO (Plain Old Java Objects) klassen\u0026mdash;of in geval van Kotlin, data objects\u0026mdash;waarbij alle members automatisch worden geserialiseerd.\nLightCouch oefeningen Maak zoals hierboven beschreven een nieuw gradle project aan (IntelliJ?) en voeg LightCouch toe als dependency. Probeer naar een nieuwe database enkele objecten weg te schrijven. Gebruik hiervoor een Student klasse met als velden name en age (respectievelijk String en int als type). Controleer of dit is aangekomen in de admin console. Dat ziet er dan hopelijk zo uit: { \u0026#34;_id\u0026#34;: \u0026#34;387a34be062140e4be1390e846242114\u0026#34;, \u0026#34;_rev\u0026#34;: \u0026#34;1-742f438439fd68bc6c67ca0d615f1469\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Joske\u0026#34;, \u0026#34;age\u0026#34;: 10 } Probeer de views en query\u0026rsquo;s even uit. Zoek bijvoorbeeld alle studenten in List\u0026lt;Student\u0026gt; en druk de namen af door middel van println(). Denkvragen Wat is het verschil tussen een key/value store en een document store? Kan je een verklaring geven waarom NoSQL databases zonder DB SCHEME werken, als je weet dat bijvoorbeeld CouchDB plain JSON objecten kan bewaren? Wat is het verschil tussen het bewaren van een JSON object via Curl en het bewaren van een POJO via LightCouc (De Client API verschillen zelf niet in rekening gebracht)? "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/apis/jpa/",
	"title": "3. JPA en Hibernate",
	"tags": [],
	"description": "",
	"content": "2.1 Wat is JPA? JPA of de Java Persistence API is een deel van Java EE (Java Enterprise Platform), een set van specificaties die initiëel de JDK SE 8 versie uitbreidden met \u0026ldquo;enterprise\u0026rdquo; features zoals distributed computing en web services. J2EE wordt vooral ingezet als het gaat over grote applicaties die bedrijven ontwikkelen voor andere bedrijven (zogenaamde \u0026ldquo;B2B\u0026rdquo;, Business 2 Business, of Enterprise Software Development).\nOndertussen is J2EE omgevormd tot Jakarta EE. Dat betekent ook dat JPA recent officieel werd vervangen door de Jakarta Persistence API. Je zal merken dat de javax.persistence dependency die wij gebruiken niet meer wordt geupdate. Pas dus op met recente Stack Overflow links!\n2.1.1 Maar wat is de JPA API nu precies? De API, levend in de package javax.persistence, is een manier om relationele data voor te stellen in enterprise Java applicaties, door middel van Objecten. Het is dus een mapping tool die object/relationale (meta)data bewerkt en verwerkt. JPA heeft ook zijn eigen query language, JPQL, die het eenvoudiger moet maken om queries te schrijven in Java code zelf in plaats van in SQL, die vertaald worden naar SQL. Dit vereenvoudigt refactoring en vermindert mogelijke fouten in de SQL string die te laat naar boven komen (nu compiletime ipv runtime, aangezien Java statisch getypeerd is).\nJPA is niet meer dan een specificatie die de interfaces en annotaties voorziet. De implementatie, en de klasses, worden overgelaten aan vendors, waarvan voor JPA 2.2 de volgende vendors beschikbaar zijn:\nDataNucleus EclipseLink Hibernate OpenJPA JPA 2.2 Gradle dependency: compile group: 'javax.persistence', name: 'javax.persistence-api', version: '2.2'\n2.2 Wat is Hibernate ORM? Volgens de hibernate.org website:\nYour relational data. Objectively.\nHibernate is dé populairste object-relational mapper in Java die de JPA standaard implementeert. Hibernate heeft zowel een eigen API als een JPA specificatie, en kan dus overal waar JPA nodig is ingeschakeld worden. Het wordt vaak in omgevingen gebruikt waar performantie belangrijk is, en waar enorm veel data en gebruikers data transferreren.\nBelangrijk startpunt: Hibernate getting started guide Ook Hibernate werkt met modules, zoals Jdbi3. We gebruiken hibernate-core; via Gradle: compile group: 'org.hibernate', name: 'hibernate-core', version: '5.4.23.Final'\nHet gebruik van Hibernate geeft meestal een aantal mogelijkheden:\nGebruik de Native Hibernate API en hbm.xml mapping (Zie \u0026ldquo;2. Tutorial Using Native Hibernate APIs and hbm.xml Mapping\u0026rdquo;) Gebruik de Native Hibernate API en annotaties (Zie \u0026ldquo;3. Tutorial Using Native Hibernate APIs and Annotation Mappings\u0026rdquo;) Gebruik de JPA interface (Zie \u0026ldquo;4. Tutorial Using the Java Persistence API (JPA)\u0026rdquo;) Waarvan wij #3 gaan hanteren.\n2.2.1 Hibernate/JPA Bootstrapping JPA bootstrappen kan - net zoals JDBC en Jdbi - vrij eenvoudig met een statische klasse Persistence die een sessionFactory object aanmaakt. Elke session factory stelt een verbinding voor tussen de Java code en de Database zelf. Om te kunnen werken met objecten moet je vanuit de session factory de entity manager creëren. Vanaf dan kan er worden gewerkt met de database via de entity manager instantie.\nvar sessionFactory = Persistence.createEntityManagerFactory(\u0026#34;be.kuleuven.mijnmooiepackage\u0026#34;); var entityManager = sessionFactory.createEntityManager(); // do stuff with it! // entityManager.createQuery(...) javax.persistence.Persistence gaat op zoek naar een persistence.xml bestand in de map src/main/resources/META-INF. Die bevat alle connectiegegevens en instellingen. De persistence XML file is de belangrijkste file van je hele applicatie, waar caching strategie, driver management, table autocreation, \u0026hellip; allemaal in wordt bepaald!\nEen voorbeeld XML file:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;persistence version=\u0026#34;2.1\u0026#34; xmlns=\u0026#34;http://xmlns.jcp.org/xml/ns/persistence\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://xmlns.jcp.org/xml/ns/persistence http://xmlns.jcp.org/xml/ns/persistence/persistence_2_1.xsd\u0026#34;\u0026gt; \u0026lt;persistence-unit name=\u0026#34;be.kuleuven.studenthibernate.domain\u0026#34;\u0026gt; \u0026lt;description\u0026gt;Studenten JPA Test\u0026lt;/description\u0026gt; \u0026lt;provider\u0026gt;org.hibernate.jpa.HibernatePersistenceProvider\u0026lt;/provider\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;property name=\u0026#34;javax.persistence.jdbc.driver\u0026#34; value=\u0026#34;org.sqlite.JDBC\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;javax.persistence.jdbc.url\u0026#34; value=\u0026#34;jdbc:sqlite:studenten.db\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;javax.persistence.jdbc.user\u0026#34; value=\u0026#34;\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;javax.persistence.jdbc.password\u0026#34; value=\u0026#34;\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;javax.persistence.schema-generation.database.action\u0026#34; value=\u0026#34;drop-and-create\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;hibernate.dialect\u0026#34; value=\u0026#34;org.hibernate.dialect.SQLiteDialect\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;hibernate.connection.autocommit\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;hibernate.show_sql\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;hibernate.flushMode\u0026#34; value=\u0026#34;ALWAYS\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;hibernate.cache.use_second_level_cache\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;hibernate.cache.provider_class\u0026#34; value=\u0026#34;org.hibernate.cache.NoCacheProvider\u0026#34; /\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/persistence-unit\u0026gt; \u0026lt;/persistence\u0026gt; Bevat onder andere de volgende belangrijke properties:\njavax.persistence JDBC driver/url. Merk op dat achterliggend dus nog steeds JDBC wordt gebruikt! Dat betekent ook dat we de sqlite dependency sqlite-jdbc van de groep org.xerial nog steeds nodig hebben. schema-generation properties: drop-and-create betekent dat tabellen die niet bestaan automatisch worden aangemaakt. Geen CREATE TABLE statements meer nodig, dus. hibernate.dialect: voor vendor-specifieke queries te genereren moet Hibernate weten welke database wij hanteren. Dit staat los van de jdbc driver! Hiervoor gebruiken we het dialect van dependency compile group: 'com.zsoltfabok', name: 'sqlite-dialect', version: '1.0'. Flush modes, auto-commit instellingen, caching, e.a. Dit gaat ver buiten de scope van deze cursus. show_sql print de gegenereerde queries af in de console, handig om te zien hoe Hibernate intern werkt, en om te debuggen. Er ontbreekt hierboven nog een belangrijk gegeven: elke entity (domein object dat een tabel voorstelt in de code) moet met fully qualified name in een \u0026lt;class/\u0026gt; tag onder \u0026lt;persistence-unit/\u0026gt; worden toegevoegd. Anders herkent JPA het object niet, en heeft hij geen idee welke kolommen te mappen op welke properties. Die metadata zit namelijk in de entity klasse zelf.\nMeer informatie: zie hibernate.org documentatie en A beginners guide to JPA persistence xml.\n2.2.2 Hibernate/JPA Peristence/querying Nu de verbinding tussen de DB en Hibernate/JPA tot stand werd gebracht, is het tijd om gebruik te maken van de kracht van de library.\nOm kolommen te kunnen mappen op properties voorziet JPA een aantal annotaties als meta-data op het domeinobject zelf. Dat betekent dat DB beschrijving netjes bij het object waar het hoort wordt geplaatst. Bijvoorbeeld:\n@Entity data class Huis( @Column(name = \u0026#34;beschr\u0026#34;) var beschrijving: String, @Column var prijs: Int? = null, @Column @Id @GeneratedValue var id: Int = 0) @Entity public class Huis { @Column @Id @GeneratedValue private int id; @Column(name = \u0026#34;beschr\u0026#34;) private String beschrijving; @Column private int prijs; } In Kotlin zijn types standaard not-nullable. Denk goed na over de mogelijke waardes van elk type: kan er ooit null in komen? Indien ja werk je met Kotlin\u0026rsquo;s optional alternatief: suffixen met een ?. Not-nullable types die later dan de constructor een waarde krijgen toegewezen worden aangeduid met lateinit. Zie Null safety Kotlin docs. Om Kotlins data class te laten samenwerken met oudere Java APIs zoals JPA/Hibernate, die niet kunnen omgaan met immutability, moeten we nog een extra plugin installeren: de no-arg plugin: id(\u0026quot;org.jetbrains.kotlin.plugin.jpa\u0026quot;) version \u0026quot;1.5.21\u0026quot; in de gradle plugins block. Die plugin genereert de nodige no-arg constructoren die JPA nodig heeft.\nHet datatype kan ook worden ingesteld met @Column (merk op dat de kolomnaam van de tabel in de DB kan en mag wijzigen van de property name in Java), bijvoorbeeld voor temporele waardes waar enkel de tijd of datum wordt bijgehouden op DB niveau. Merk op dat @Id nodig is op een @Entity - zonder primary key kan JPA geen object persisteren. @GeneratedValue is er omdat wij niet telkens de ID willen verhogen, maar dat willen overlaten aan de database vanwege de AUTOINCREMENT. Bij elke persist() gaat Hibernate de juiste volgende ID ophalen, dat zich vertaalt in de volgende queries in sysout:\nHibernate: select next_val as id_val from hibernate_sequence Hibernate: update hibernate_sequence set next_val= ? where next_val=? Hibernate: insert into Student (goedBezig, naam, voornaam, studnr) values (?, ?, ?, ?) De tabelnaam kan je wijzigen met de @Table annotatie op klasse niveau.\nInserts/updates Hoe bewaar ik een entity? entityManager.persist(object). That\u0026rsquo;s it!\nHoe update ik een entity, als properties zijn gewijzigd? .merge(object)\nMerk op dat in de Sysout output geen query wordt gegenereerd. Hibernate houdt alles in zijn interne cache bij, en zal pas flushen naar de database wanneer hij acht dat dat nodig is. Dat kan je zelf triggeren door entityManager.flush() te gebruiken (kan alleen in een transactie) - of het commando te wrappen met een transactie:\nwith(entityManager) { getTransaction().begin() persist(dingdong) getTransaction().commit() } entityManager.getTransaction().begin(); entityManager.persist(dingdong); entityManager.getTransaction().commit(); Zonder dit, en met herbruik van dezelfde entity manager in SQLite, is er een kans dat je SELECT query niets teruggeeft, omdat de INSERT nog niet werd geflushed. De interne werking van combinatie JDBC+SQLite+JPA+Hibernate is zeer complex en zou een cursus van 20 studiepunten vereisen\u0026hellip;\nQueries Hoe query ik in JPA? Dit kan op verschillende manieren. We beperken ons hier tot de JPA Criteria API. Een voorbeeld. Gegeven een huizenlijst, waarvan we huizen willen teruggeven die onder de 200.000 kosten. In SQL zou dit SELECT * FROM huizen WHERE prijs \u0026lt; 200000 zijn. In Criteria API:\nval criteriaBuilder = entityManager.getCriteriaBuilder() val query = criteriaBuilder.createQuery(Huis::class.java) val root = query.from(Huis::class.java) query.where(criteriaBuilder.equal(root.get\u0026lt;Int\u0026gt;(\u0026#34;prijs\u0026#34;), 200000)) return entityManager.createQuery(query).getResultList() var criteriaBuilder = entityManager.getCriteriaBuilder(); var query = criteriaBuilder.createQuery(Huis.class); var root = query.from(Huis.class); query.where(criteriaBuilder.equal(root.get(\u0026#34;prijs\u0026#34;), 200000)); return entityManager.createQuery(query).getResultList(); Voor simpele queries zoals deze is dat inderdaad omslachtig, maar de API is zeer krachtig en kan automatisch complexe queries genereren zonder dat wij ons moe moeten maken. Merk op dat wij geen enkele letter SQL zelf schrijven. Alles is java code, wat het eenvoudig maakt om te refactoren, redesignen, statische code analyse op te doen, unit testen, \u0026hellip; Lees meer over criteria API:\nVoorbeeld 2 Programmatic Criteria Queries Voorbeeld 3 TutorialsPoint Criteria API Voorbeeld 4 Using \u0026ldquo;In\u0026rdquo; in Criteria API Controleer in de sysout output welke query Hibernate uiteindelijk genereert. Dat ziet er zo uit:\nselect student0_.studnr as studnr1_0_, student0_.goedBezig as goedbezi2_0_, student0_.naam as naam3_0_, student0_.voornaam as voornaam4_0_ from Student student0_ where student0_.naam=? 2.2.3 Oefeningen Quickstart project: examples/hibernate-jpa-start in de cursus repository (download repo zip)\nHet is opnieuw tijd voor onze studentendatabase. Open of kopiëer het project van 1. jdbc en jdbi (of start met het quickstart project). We voorzien een derde implementatie van de StudentRepository interface, naast de JDBC en Jdbi3 versies: StudentRepositoryJpaImpl. Probeer een nieuwe student te bewaren én daarna dezelfde student op te halen en af te drukken in sysout. Wat heb je daar weer voor nodig? (Scroll up!) Een configuratiebestand in resources/META-INF. Entities, zoals onze Student klasse. Bootstrappen van de EntityManager. Een repository implementatie die de EntityManager gebruikt (tip: constructor injectie!) Modelleer ook de log tabel uit 1. Failures/rollbacks. Bewaar een log record bij elke wijziging van student (aanmaken, wijzigen). Vergeet geen \u0026lt;class/\u0026gt; entry toe te voegen in je persistence.xml! Anders krijg je de volgende fout: Exception in thread \u0026#34;main\u0026#34; java.lang.IllegalArgumentException: Not an entity: class be.kuleuven.studenthibernate.domain.Student\rat org.hibernate.metamodel.internal.MetamodelImpl.entity(MetamodelImpl.java:566)\rat org.hibernate.query.criteria.internal.QueryStructure.from(QueryStructure.java:127)\rat org.hibernate.query.criteria.internal.CriteriaQueryImpl.from(CriteriaQueryImpl.java:158) 2.2.4 JDBC VS Jdbi3 VS JPA JDBC: Low-level relationele mapping tussen Java en DB. Wordt door alle high-level API\u0026rsquo;s gebruikt. Omslachtig (checked Exceptions, beperkte interface), erg kort bij SQL. Functionaliteit: minimaal. Jdbi3: High-level relationele mapping no-nonsense API bovenop JDBC die in feite alle negatieve kenmerken van JDBC wegwerkt. Nog steeds kort bij SQL, maar meer object-friendly door Fluent/Declarative API. Functionaliteit: nog steeds basic, maar wel met gebruiksgemak. JPA en vendors: High-level object-relational mapper bovenop JDBC waarbij entities centraal staan en compatibiliteit met Java EE is ingebouwd. Genereert SQL (zelf raw queries schrijven kan nog steeds, maar wordt afgeraden). Functionaliteit: enorm uitgebreid. Kies altijd bewust voor één bepaald framework in plaats van \u0026ldquo;random\u0026rdquo; of \u0026ldquo;uit ervaring\u0026rdquo;: JPA/Hibernate is vaak overkill voor simpele applicaties, JDBC is vaak té low-level en bevat veel boilerplating, terwijl Jdbi3 daartussen ligt.\nZijn er nog alternatieven? Uiteraard, en meer dan één\u0026hellip; Maar dat reikt buiten de scope van deze cursus.\n2.3 Many-to-one relaties in Hibernate/JPA De grootste kracht van JPA hebben we nog steeds niet gezien: in plaats van één of meerdere entiteiten onafhankelijk te mappen, kunnen we ook relaties mappen en Hibernate alles op SQL-niveau laten afhandelen. Nooit meer JOIN statements schrijven, hoera!\u0026hellip; Niet altijd. Soms wil je de queries anders aanpakken dan Hibernate ze genereert omwille van performantie redenen. In dat geval zal je nog steeds moeten teruggrijpen naar native SQL - of veel tijd investeren in de correcte configuratie van de Hibernate/JPA/JDBC installatie.\nEen concreet voorbeeld. Een Docent entiteit geeft les aan verschillende studenten:\n@Entity data class Docent( @Id @GeneratedValue var docentennummer: Int, @Column var naam: String, @OneToMany(mappedBy = \u0026#34;docent\u0026#34;) var studenten: List\u0026lt;Student\u0026gt; ) @Entity public class Docent { @Id @GeneratedValue private int docentennummer; @Column private String naam; @OneToMany(mappedBy = \u0026#34;docent\u0026#34;) private List\u0026lt;Student\u0026gt; studenten; } De @OneToMany annotatie zorgt voor de link tussen de studenten- en docententabel: het is wel nog nodig om een omgekeerde mapping property genaamd docent toe te voegen op de Student klasse:\n@Entity data class Student( // ... @ManyToOne(fetch = FetchType.LAZY) @JoinColumn(name = \u0026#34;docent_nr\u0026#34;) var docent: Docent? ) @Entity public class Student { // ... @ManyToOne(fetch = FetchType.LAZY) @JoinColumn(name = \u0026#34;docent_nr\u0026#34;) private Docent docent; } Op die manier kan je van docenten onmiddellijk zien aan wie ze lesgeven (one to many), en van een student van wie hij of zij les krijgt (many to one). De data wordt in de studententabel bewaard, in kolom docent_nr. Andere configuraties zoals tussentabellen zijn uiteraard ook mogelijk.\nPersisteren we nu een nieuwe docent waar een reeds bewaarde student in de lijst werd toegevoegd:\nprivate fun docentenTest(entityManager: EntityManager, student: Student) { val wouter: Docent(\u0026#34;Wouter\u0026#34;).apply { geefLesAan(student) } with(entityManager) { begin() persist(wouter) commit() } } private static void docentenTest(EntityManager entityManager, Student student) { var wouter = new Docent(\u0026#34;Wouter\u0026#34;); wouter.geefLesAan(student); entityManager.getTransaction().begin(); entityManager.persist(wouter); entityManager.getTransaction().commit(); } Geeft in Hibernate:\nHibernate: select next_val as id_val from hibernate_sequence Hibernate: update hibernate_sequence set next_val= ? where next_val=? Hibernate: insert into Docent (naam, docentnummer) values (?, ?) SQLite browser:\nWaar is onze docent_nr data? De methode geefLesAan voegt enkel toe aan de studentenlijst, maar de relatie moet voor beide entities kloppen:\nfun geefLesAan(student: Student) { studenten.add(student) student.docent = this } public void geefLesAan(Student student) { studenten.add(student); student.setDocent(this); } Zonder de tweede regel wordt de kolom niet ingevuld. Geeft nu:\nHibernate: select next_val as id_val from hibernate_sequence Hibernate: update hibernate_sequence set next_val= ? where next_val=? Hibernate: insert into Docent (naam, docentnummer) values (?, ?) Hibernate: update Student set docent_nr=?, goedBezig=?, naam=?, voornaam=? where studnr=? Bingo, een UPDATE statement in de studententabel. SQLite Browser:\n2.3.1 Oefeningen Implementeer de Docent klasse zoals hierboven. Wat gebeurt er als je studenten opvraagt? Wat gebeurt er als je een docent van een student opvraagt? De FetchType.LAZY schiet in gang. Verander dit naar EAGER. Kijk in de Hibernate output wat er verandert op SQL niveau en verifiëer dat er nu een LEFT OUTER JOIN in de SELECT van de student staat. Pas op het moment dat de data van de docent effectief nodig is, zoals bij het afdrukken, wordt een SELECT query gelanceerd bij lazy-loading. Bijvoorbeeld:\nval student = entityManager.find(Student::class.java, jos.studentennummer) println(\u0026#34;student ${student.naam}\u0026#34;); println(\u0026#34; -- heeft als docent ${student.docent.naam}\u0026#34;) var student = entityManager.find(Student.class, jos.getStudentenNummer()); System.out.println(\u0026#34;student \u0026#34; + student.getNaam()); System.out.println(\u0026#34; -- heeft als docent \u0026#34; + student.getDocent().getNaam()); Geeft als sysout output:\nHibernate: select student0_.studnr as studnr1_1_0_, student0_.docent_nr as docent_n5_1_0_, student0_.goedBezig as goedbezi2_1_0_, student0_.naam as naam3_1_0_, student0_.voornaam as voornaam4_1_0_ from Student student0_ where student0_.studnr=?\rstudent Lowiemans\rHibernate: select docent0_.docentnummer as docentnu1_0_0_, docent0_.naam as naam2_0_0_ from Docent docent0_ where docent0_.docentnummer=?\r-- heeft als docent Wouter Merk op dat de eerste System.out.println vóór de docenten SELECT query komt. Een eager-loaded docent geeft andere output:\nHibernate: select student0_.studnr as studnr1_1_0_, student0_.docent_nr as docent_n5_1_0_, student0_.goedBezig as goedbezi2_1_0_, student0_.naam as naam3_1_0_, student0_.voornaam as voornaam4_1_0_, docent1_.docentnummer as docentnu1_0_1_, docent1_.naam as naam2_0_1_ from Student student0_ left outer join Docent docent1_ on student0_.docent_nr=docent1_.docentnummer where student0_.studnr=?\rstudent Lowiemans\r-- heeft als docent Wouter Tip: entityManager.clear() of close() een nieuwe aanmaken kan helpen om de persistence context te flushen ter test.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/transacties/",
	"title": "3. RDBMS Transacties",
	"tags": [],
	"description": "",
	"content": "Transaction management Zie menu links.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/apis/",
	"title": "4. Database APIs",
	"tags": [],
	"description": "",
	"content": "Database APIs Zie menu links.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/nosql/",
	"title": "5. NoSQL",
	"tags": [],
	"description": "",
	"content": "NoSQL Databases Zie menu links.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/",
	"title": "Index",
	"tags": [],
	"description": "",
	"content": " Databases Laatste aanpassingen voor academiejaar 2023\u0026mdash;2024.\nPlanning nr datum onderwerp 01 vr 16-02-2024 RDBMS \u0026amp; SQL: Basics, DB Componenten 02 vr 23-02-2024 ER-schema 03 di 27-02-2024 ACID \u0026amp; SQL Deel 1 04 vr 08-03-2024 SQL deel 2 05 vr 15-03-2024 RDBMS transacties: basics, concurrency control 06 vr 22-03-2024 DB APIs: basics, JDBC, JDBI 07 di 26-03-2024 DB APIs: JPA \u0026amp; Hibernate 08 di 16-04-2024 Re Transacties: rollbacks, concurrency in practice 09 vr 26-04-2024 NoSQL 1: intro HC, key/value en document stores 10 vr 03-05-2024 NoSQL 2: advanced concepts, case studies 11 vr 17-05-2024 XML Data Storage, Big Data \u0026amp; Analytics 12 do 23-05-2024 Reserve Cursus noties Er worden telkens blokken van 3 uur ingepland voor dit vak. Er zijn geen traditionele hoorcolleges voorzien. Alle noties zijn via deze website te raadplegen (tenzij anders vermeld):\nInhoudsopgave SQL: Database Basics DB Componenten ER-schema Transacties I: ACID SQL: DDL SQL: DML SQL DB APIs: API Basics \u0026amp; layered tiers JDBC en JDBI JPA en Hibernate Extra oefeningen Transacties: Transacties II: Management Basics Concurrency control Failures/Rollbacks Transacties III: in de praktijk NoSQL: NoSQL Basics Key/Value stores Document stores Advanced map/reduce queries Replication XML \u0026amp; Big Data Storage XML Basics XSD Schemas XPath Queries Big Data Basics Big Data: Warehousing \u0026amp; BI Syllabus Lesgevers: Coördinerend Verantwoordelijke: prof. dr. Kris Aerts (kris.aerts@kuleuven.be) assistent lesgever: ing. Arne Duyver (arne.duyver@kuleuven.be) Kantoor: Technologiecentrum Diepenbeek, Groep ACRO. Cursusbeschrijving Dit opleidingsonderdeel focust enerzijds op drie soorten databases:\nrelationele databases de NoSQL-alternatieven XML databases En anderzijds op twee toepassingen:\nprogrammeren van database-gestuurde applicaties via API\u0026rsquo;s een inleiding in Big Data Vereiste voorkennis Basiskennis van een Object-Geörienteerde programmeertaal als Java of C# Basiskennis van het UNIX systeem, werken met commandline Doelstellingen Zie ook Studiegids UHasselt\nDe context en het overzicht worden aangereikt in de eerste lessen van dit vak.\nAls practicum wordt een grotere probleemstelling als project uitgewerkt. Alle aan te leren aspecten van databases komen in dit project aan bod. Studenten kunnen facultatief buiten het practicum extra thematische oefeningen oplossen.\nKalender Zie Mytimetable UHasselt.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/extra/",
	"title": "X. Extras",
	"tags": [],
	"description": "",
	"content": "Extra informatie Zie menu links.\n"
}]