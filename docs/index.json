[
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/apis/basics/",
	"title": "1. API Basics",
	"tags": [],
	"description": "",
	"content": "Layered Application Tiers In software engineering worden applicaties logisch opgesplitst in verschillende \u0026ldquo;tiers\u0026rdquo;. Een typische 3-Tier webapplicatie bestaat uit 3 lagen: de laag die de gebruiker te zien krijgt\u0026mdash;de UI, bestaande uit HTML en CSS, de backend\u0026mdash;een server waar de requests naartoe worden gestuurd en die de aanvragen verwerkt, en een data laag die onze database voorstelt. Onderstaand schema vat dit samen (via Trevor N. Mudge):\n   In de praktijk variëert deze tier benadering van project tot project.\nTot nu toe in dit vak hebben we ons toegelegd op Tier 3: de data laag. Zonder frontend applicatie laag kan een gebruiker echter niet interageren met deze database; er it dus minstens één extra tier nodig. Bovenstaand schema kwam terug in het vak Software Engineering Skills; namelijk de SESsy library webapp, die ook bestaat uit drie conceptuele lagen.\nOm ons in het vak databases te kunnen focusen op de data en de integratie van de data met de software gaan wij ons toeleggen op Tier 2 + 3. Het webgedeelte valt weg en om een UI te maken herbruiken we de opgebouwde JavaFX kennis van het eerstejaarsvak Software Ontwerp in Java (INF1). We gaan dus terug Java/Kotlin applicaties maken en die verbinden met onze database schema\u0026rsquo;s. Een simpele 2-tier applicatie is ook wel een client-server applicatie genoemd. In ons geval is de server de database, die in principe op een andere machine kan gedeployed worden. Voor de oefeningen vereenvoudigen we dit systeem door gebruik te maken van een embedded database die in het lokaal geheugen kan draaien.\nWe teren dus op de volgende kennis:\n Het opstellen van Gradle projecten in Java of Kotlin (SES en AppDev); JavaFX UIs bouwen (INF1); Databases ontwerpen en koppelen (Databases).  Problemen met je JDK versie en Gradle versies? Raadpleeg de Gradle Compatibiility Matrix. Gradle 6.7 of hoger ondersteunt JDK15. Gradle 7.3 of hoger ondersteunt JDK17. Let op met syntax wijzigingen bij Gradle 7+! Je Gradle versie verhogen kan door de URL in gradle/gradlew.properties te wijzigen.\n Gradle dependency of Git source control problemen? Grijp terug naar de cursus van SES.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/bigdata/basics/",
	"title": "1. Big Data Basics",
	"tags": [],
	"description": "",
	"content": "De Big in Big Data mag je letterlijk nemen. IBM berekende onlangs dat wij allemaal 2.5 quintillion bytes aan data genereren. Elke minuut meer dan 350.000 tweets, 75.000 uren van Netflix video streams, meer dan 35.000 Apple store apps gedownload, enzovoort.\nDe term Big Data is al sinds eind de jaren negentig aan een opmars bezig. We kunnen \u0026ldquo;grote datasets\u0026rdquo; categoriseren afhankelijk van wat we noemen de vijf Vs:\n Volume\u0026mdash;Het gaat (uiteraard) over een alsmaar groeiend \u0026ldquo;groot volume\u0026rdquo; aan data; Velocity\u0026mdash;De snelheid waarmee de data in en uit systemem vloeit die altijd maar toeneemt; Variety\u0026mdash;De range aan data types breidt altijd maar uit (JSON, XML, RDBMS, noSQL, files, \u0026hellip;); Veracity\u0026mdash;Hoe waarheidsgetrouw is de data eigenlijk wel? Data vertoont alsmaar vaker inconsistenties/ambiguiteit; Value\u0026mdash;Wat heb je aan al die data zonder er iets waardevol mee te doen (zoals een crutiale business beslissing)?    src: tistory.com  Denk aan de biljoenen mensen die dagelijks Facebook gebruiken en gigantische volumes aan foto\u0026rsquo;s en tekst uploaden. Het aantal gebruikers dat gestaag steeg (velocity) en de variëteit van data zoals APIs tussen Facebook en anderen om elders in te loggen met je account, video en fotomateriaal in plaats van enkel tekst, integratie met WhatsApp/Instagram, \u0026hellip; Maar hoeveel fake data zit er wel niet tussen, en hoeveel accounts worden misbruikt? Hoeveel data lekken en gevoelige data bevat het? (veracity). Vooral uw persoonsgegevens is voor Meta, het bedrijf achter Facebook, letterlijk goud waard, en verkoopt het door aan derden (value), vaak zonder jouw toestemming!\nNog een leuk voorbeeld: de winkel https://ebay.com/ heeft een data warehouse van 45 petabytes\u0026mdash;ofwel 45.000 terabytes!\nUit de vorige hoofdstukken blijkt dat een traditioneel RDBMS systeem niet goed kan scalen (zie nosql introductie). Echter, een NoSQL DB is slechts één component in het gehele Big Data ecosysteem. In de praktijk gaat het over veel pools, clusters, servers, heterogene DB systemen, files, APIs, \u0026hellip; allemaal gecombineerd (zie data warehousing lakes). Het beheren van een Big Data systeem gaat niet over één DB systeem, maar over het beheren van verschillende parameters (snelheid, grootte van input, connecties tussen systemen, \u0026hellip;). De analyse van de inhoud ervan is vaak een taak voor gespecialiseerde data scientists.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/sql/rdbms-basics/",
	"title": "1. Database Basics",
	"tags": [],
	"description": "",
	"content": "Een database is niet meer dan een verzameling van gegevens. DBMS (Database Management System) is de software waarmee databases beheerd of aangemaakt kunnen worden.\n1. Waarom een database gebruiken? Een database wordt ook maar gewoon opgeslagen op een file system. Dus waarom kan ik dan niet zelf files gebruiken om mijn data op te slaan?\nDatabases bieden een aantal key features:\n Performant (index management) Betere integratie met andere applicaties DBMS voor bewerken of ophalen van data Concurrency ondersteuning Security \u0026amp; Privacy van data \u0026hellip;  In het tweedejaarsvak Besturingssystemen en C leerde je dat IO manipulatie heel dure operaties zijn. Een erg groot bestand openen of een seek() operatie uitvoeren daarop, duizenden bestanden tegelijkertijd openen voor data access, \u0026hellip;\u0026mdash;allemaal voorbeelden van nadelen waar een database de oplossing kan bieden.\n2. Database Model De data die zich in een database bevindt wordt op een specifieke manier opgeslagen. De structuur waarop deze data bijgehouden wordt, noemen we het database model.\nEen database model bestaat uit meerdere data modellen. Een data model beschrijft één specifiek object.\nWe zien hetzeflde eigenlijk terug als we denken aan Java of Kotlin. We definiëren hoe een klasse eruit ziet. Bijvoorbeeld volgende klasse:\ndata class Book(val isbn: string, val title: string, val author: string, val price: double) public class Book { String isbn; String title; String author; double price; public Book(isbn, title, author, price) { this.isbn = isbn; this.title = title; this.author = author; this.price = price; } }  Dit kunnen we ook in een database bepalen. Daar zou het data model van de tabel Book er bijvoorbeeld als volgt kunnen uitzien:\nclassDiagram class Book{ isbn: NVARCHAR(50) title: NVARCHAR (500) author: NVARCHAR (500) price: DECIMAL(10,4) }  Net als we in code state kunnen hebben wanneer we onze klasses instantiëren:\nvar book = Book(\u0026#34;0765326353\u0026#34;, \u0026#34;The Way of Kings\u0026#34;, \u0026#34;Brandon Sanderson\u0026#34;, 24.99) var book = new Book(\u0026#34;0765326353\u0026#34;, \u0026#34;The Way of Kings\u0026#34;, \u0026#34;Brandon Sanderson\u0026#34;, 24.99);  Zo kunnen we ook state hebben in onze database:\n   isbn title author price     0765326353 The Way of Kings Brandon Sanderson 24.99    Een voorbeeld van een simpel database model voor de inventaris van een bibliotheek zou er ongeveer als volgt kunnen uitzien:\nclassDiagram Book \"0..*\" -- \"1..*\" Genre Book \"1..*\" -- \"1\" Author class Author{ id: INT name: NVARCHAR firstName: NVARCHAR } class Genre{ id: INT description: NVARCHAR } class Book{ isbn: NVARCHAR title: NVARCHAR author: INT price: DECIMAL genre: INT }  "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/sql-ddl-dml/ddl/",
	"title": "1. DDL",
	"tags": [],
	"description": "",
	"content": "Data Defintion Language is de taal die we gebruiken om de structuur van onze database te veranderen. We kunnen hiermee tabellen aanmaken, wijzigen of verwijderen. Maar ook indexen, views, triggers of stored procedures worden hiermee aangemaakt.\nZowat elke RDBMS heeft tooling om DDL te doen via een handige interface, in plaats van dit zelf uit te schrijven. In de praktijk ga je waarschijnlijk met beiden in contact komen. We gaan DB Browser for SQLite gebruiken tijdens onze lessen.\nOefening Kijk naar de Chinook database en maak een schematische voorstelling van hoe deze database eruit ziet. Je kan hiervoor Mermaid gebruiken, of een eigen tool of pen en papier.\nViews aanmaken Een view is eigenlijk een specifieke query die we een vaste naam geven.\nAls ik een view wil maken van alle tracks van het Rock genre, dan doe ik dat als volgt:\nCREATE VIEW rock_tracks AS SELECT tracks.* FROM tracks INNER JOIN genres ON genres.GenreId = tracks.GenreId WHERE genres.Name = \u0026#39;Rock\u0026#39; Vanaf dit punt kan ik in een nieuwe query het volgende uitvoeren:\nSELECT * FROM rock_tracks Oefening  Schrijf een view die de naam van elke track geeft, alsook de naam van het album en de artiest. Gesorteerd op artiest, album en dan track.  "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/nosql/basics/",
	"title": "1. NoSQL Basics",
	"tags": [],
	"description": "",
	"content": "Het schaalbaarheid probleem Het probleem met RDMS (relationele database management systems) is vaak schaalbaarheid. Gezien de ACID data validity voorwaarden is altijd de vraag: is dit schaalbaar?\nOptie 1: Vertical scaling De makkelijke oplossing is \u0026ldquo;scaling up\u0026rdquo;: meer storage, CPU, RAM, \u0026hellip; voorzien zodat er meer cycles kunnen benut worden en hopelijk ook meer transacties concurrent kunnen worden verwerkt (zie transacties basics).\n   Je botst hier echter snel op hardware limitaties\u0026mdash;niet alles is opgelost met een latje RAM.\nOptie 2: Horizontal scaling In plaats van \u0026ldquo;omhoog\u0026rdquo; te gaan en meer hardware in hetzelfde systeem te steken, kunnen we ook meer hardware op verschillende plaatsen in het netwerk zetten: scaling out in clusters. Dit noemen we horizontaal scalen: meer kleintjes die gedistribueerd hetzelfde doen.\n   Deze oplossing introduceert echter een ander probleem: data consistency is niet altijd gegarandeerd. Als ik iets in één server van een cluster bewaar, wordt dit dan onmiddellijk in de andere ook bewaard? Wat als er eentje uitvalt, en dat net mijn access point was? Op welke manier wordt die data verdeeld binnen de cluster? Enzovoort. Distributed computing is een erg complex domein binnen de informatica. We raken in dit vak enkel de top van de ijsberg aan.\nWat is een \u0026ldquo;cluster\u0026rdquo; precies? Denk aan een verzameling van grote data centers: twee of meer fysieke centra waar enorm veel servers geplaatst worden. Eén server kan je eigen laptop zijn. Je kan ook verschillende virtuele servers op je laptop draaien: dat is een node. (We hanteren hier de hierarchie van elementen volgens Cassandara) Cluster \u0026laquo; Data Center \u0026laquo; Rack \u0026laquo; Server \u0026laquo; Node\n Een typische relationele database, met zijn ACID eigenschappen, maakt horizontaal schalen dus moeilijk. Consistentie en availability maakt partitioning tot een uitdaging. Dit is ook zichtbaar in het CAP probleem; of \u0026ldquo;Consistency, Availability, Partitioning Tolerance\u0026rdquo; probleem. Wil je inzetten op partitioning, dan is de kans groot dat je zal moeten inboeten op consistency en availability. De volgende figuur illustreert dit probleem:\n  Het CAP probleem. src: freecodecamp.org  Flexibiliteit van horizontal scaling krijgen we door af te stappen van een typische RDBMS, en te kijken naar wat er kan als de R (relational) wegvalt\u0026mdash;ofwel noSQL databases. De populariteit hiervan groeide exponentieel sinds scalability een groter probleem werd: denk aan gigantische data warehouses van Amazon, Google\u0026rsquo;s zoek engine, Facebook pagina\u0026rsquo;s, enzovoort. NoSQL systemen garanderen ook consistentie\u0026mdash;alleen niet onmiddellijk: dit heet eventual consistency.\nDus, horizontal scaling is eenvoudiger met NoSQL:\n Er is géén relationele data; Er is géén (onmiddellijke) consistentie\u0026mdash;dus ook geen coordinatie overhead!; Dit is zeer goed scalable.  NoSQL basics Een vergelijking van eigenschappen tussen een relationele en niet-relationele database systeem:\n   Eigenschap Relationeel NoSQL     Data paradigma relationeel 4 types: key/val, docs, \u0026hellip; (s3.2)   Distributie Single-node Distributed   Scalability Vertical Horizontal, replication   Structuur Schema-based Flexible   Querty taal SQL Specialized (JavaScript)   Transacties ACID BASE   Features views/procs/\u0026hellip; basic API   Data vol. \u0026ldquo;normal\u0026rdquo; \u0026ldquo;huge amounts\u0026rdquo;    Merk op dat het niet altijd de beste oplossing is om naar een NoSQL DB te grijpen. Wanneer dan wel of niet? De volgende vragen kunnen hierbij helpen:\n Bevat data veel/weinig relaties? Komt er enorm veel data/sec. binnen? Replication vereisten? Scripting mogelijkheden? Bestaande kennis in bedrijf? \u0026hellip;  Klassieke relationele databases zijn nog steeds een van de meestgebruikte ter wereld, maar dat wil niet zeggen dat er geen (populaire) alternatieven zijn. Kijk eens naar de db-engines.com ranking trends op db-engines.com:\n   De drie bovenste lijnen zijn Oracle, MySQL en Microsoft SQL Server, de drie giganten die alledrie relationele DBMS systemen zijn. PostgresQL, de oranje stijgende lijn, is volgende\u0026mdash;ook SQL. Maar daarnaast volgen MongoDB, Cassandra, Redis, DynamoDB, \u0026hellip;\u0026mdash;allemaal verschillende soorten noSQL alternatieven.\nDoe eens een gokje: welk database systeem denk je dar onderstaande websites gebruiken? relationeel of niet-relationeel?\n https://www.vdab.be/vindeenjob/vacatures https://www.immoweb.be https://twitter.com (hint 1) (hint 2) https://people.cs.kuleuven.be/~wouter.groeneveld/courses/ Blog websites zoals Brain Baking of Digging The Digital (hint: een van beiden is een valstrik)  NoSQL Types   4 NoSQL types. src: improgrammer.net  Er zijn, zoals bovenstaande figuur aangeeft, 4 grote groepen van NoSQL systemen:\n1. Document stores. Hier bewaar je een \u0026ldquo;document\u0026rdquo; in, dat meestal in JSON-formaat is, zoals:\n{ \u0026#34;bedrag\u0026#34;: 100.3, \u0026#34;gebruiker\u0026#34;: \u0026#34;Jos Klakmans\u0026#34;, \u0026#34;Stad\u0026#34;: \u0026#34;Diepenbeek\u0026#34;, \u0026#34;certificaten\u0026#34;: [{ \u0026#34;type\u0026#34;: 1, \u0026#34;naam\u0026#34;: \u0026#34;Master in de bliebloe\u0026#34; }, { \u0026#34;type\u0026#34;: 2, \u0026#34;naam\u0026#34;: \u0026#34;Bachelor in de blakkiela\u0026#34; }] } Merk op dat hier geen relaties worden gelegd, alhoewel dat wel kan: bijvoorbeeld document 1 kan een property { id: 1 } hebben, en document 2 { id: 2, relatedDocumentId: 1 }. Dit echter veel gebruiken zal een performance hit geven: document stores dienen voornamelijk om gigantisch veel onafhankelijke data te bewaren, op een ongestructureerde manier. Er zijn een table definities: een key meer of minder maakt niet uit.\nNoSQL: { name: 'Jos' } -\u0026gt; { name: 'Jos', well-behaved: true }. Geen INSERT INTO student(name) VALUES (\u0026quot;Jos\u0026quot;) dus! Ook hier wordt intern hashing gebruikt (zie onder): Het document { name: 'Jos' } wordt intern opgeslaan als { name: 'Jos', _id: 23235435 }. Data retrieval snelheid blijft belangrijk, dus extra indexen/views kunnen door de gebruiker zelf worden aangemaakt (zie volgende hoofdstukken).\nOm documenten te ordenen worden soms wel collecties aangemaakt, maar dit is bijna altijd optioneel!\nWe zullen ons in deze cursus focussen op document stores. Zie NoSQL - document stores om een idee te hebben hoe dit in de praktijk gebruikt wordt.\n2. Graph-based oplossingen. Wat als we toch veel relationele gegevens hebben, maar het nog steeds over (1) ongestructureerde data gaat en (2) te veel is voor in één klassiek RDBMS systeem te bewaren? Als de relaties de data zelf zijn, dan hebben we een grafen-gebaseerde oplossing nodig. Hier zijn géén dure JOIN statements nodig om de relaties ad-hoc te maken. Een typische toepassing hiervan zou social graphs zijn.\n  Een voorbeeld subgraph visualisatie in Neo4j.  Stel dat je alle boeken wilt ophalen geschreven door een bepaalde auteur (= de relatie). In SQL, waar de data typisch in twee tabellen leeft (book en author), heb je een (impliciete) JOIN nodig:\nSELECT book, title FROM book, author, books_authors WHERE author.id = books_authors.author_id AND book.id = books_authors.book_id AND author.name = \u0026quot;De Jos\u0026quot; Maar in Cypher, de querytaal van grafendatabase Neo4J, ziet die query er als volgt uit:\nMATCH (b:Book) \u0026lt;- [ :WRITTEN_BY]-(a:Author) WHERE a.name = \u0026quot;De Jos\u0026quot; RETURN b.title Data wordt op basis van WRITTEN_BY relatie eigenschap opgehaald. Relationele data\u0026mdash;de letterlijke relaties\u0026mdash;zijn hier altijd expliciet, en niet verborgen in foreign key constraints.\n3. Key-Value stores. Dit is de eenvoudigste soort, waarbij gewoon blobs van data in een hash table opgeslagen worden, zoals jullie gewoon zijn in Java:\nMap\u0026lt;String, Persoon\u0026gt; leeftijden = new HashMap\u0026lt;\u0026gt;(); leeftijden.put(\u0026#34;Wilfried\u0026#34;, new Persoon(\u0026#34;Wilfried\u0026#34;, 20)); leeftijden.put(\u0026#34;Seppe\u0026#34;, new Persoon(\u0026#34;Seppe\u0026#34;, 30)); leeftijden.put(\u0026#34;Bart\u0026#34;, new Persoon(\u0026#34;Bart\u0026#34;, 40)); leeftijden.put(\u0026#34;Jeanne\u0026#34;, new Persoon(\u0026#34;Jeanne\u0026#34;, 18)); var leeftijden = hashMapOf( \u0026#34;Wilfried\u0026#34; to Persoon(\u0026#34;Wilfried\u0026#34;, 20), \u0026#34;Seppe\u0026#34; to Persoon(\u0026#34;Jaqueline\u0026#34;, 30), \u0026#34;Bart\u0026#34; to Persoon(\u0026#34;Bart\u0026#34;, 40), \u0026#34;Jeanne\u0026#34; to Persoon(\u0026#34;Jeanne\u0026#34;, 18))  Hash functies In dit voorbeeld stopt de HashMap met bestaan zodra die out of scope gaat op je eigen machine, maar er zijn ook distributed hash tables. Hier is de hash functie het belangrijkste onderdeel, die de onderliggende key genereerd en dus bepaald in welke \u0026ldquo;bucket\u0026rdquo; een waarde wordt opgeslagen\u0026mdash;en dus ook, op welke server in een cluster. Een goede hash functie moet (1) deterministisch zijn: atlijd dezelfde hash waarde voor dezelfe input genereren; (2) uniform zijn: er moet een goede verdeling zijn van de output range; en (3) een vaste grootte hebben zodat het makkelijker is voor de data structuur om de hash waarde te bewaren.\n   Vrijwel alle NoSQL databases gebruiken achterliggend hashing technieken om horizontal scalability makkelijker te maken. Als alle hash values mooi verdeeld worden, kan dit ook mooi over verschillende databases verdeeld worden.\n   Paritioning/sharding In bovenstaand voorbeeld worden de persoonsgegevens verspreid over 3 verschillende servers door de hashing \u0026ldquo;index\u0026rdquo; (mod3 + 1). Data partitioning noemen we ook wel sharding waarbij een individuele partitie een shard is. Om zo efficient mogelijk te partitioneren schakel je best servers aan elkaar in een soort van \u0026ldquo;ring\u0026rdquo;, zoals in dit schema:\n   Ring partitioning vereist wel consistent hashing functies, anders klopt de node verdeling (de kleuren in het schema) niet meer. Om zo effient mogelijk data door te geven (replication, zie later NoSQL: replication) hebben nodes weet van elkaar. Het is echter nog steeds niet mogelijk om de ACID regels te volgen: een gedistribueerd systeem zoals deze ring kan nooit én consistent én available én partition tolerant zijn.\nWat is dan een oplossing voor NoSQL systemen? BASE in plaats van ACID:\n Basically Available (BA); elke (gebruikelijk HTTP-based) request ontvangt een respons, hetzij een 200 (OK), hetzij een 4xx/5xx (een externe/interne fout). Ook al zijn niet alle nodes geupdate, toch kan er al een 201 worden teruggegeven\u0026mdash;asynchroon dus. Soft state (S); sate kan wijzigen, ook zonder input! We weten dus nooit exact wat er in de shards zit. Read requests zijn soms out-of-date omdat een shard update in de ring partitie plaats aan het vinden was, maar dat één bepaalde shard nog niet bereikte\u0026hellip; Eventually Consistent (E); NoSQL biedt de \u0026ldquo;ooit is het zel consistent\u0026rdquo; mode aan.  In de praktijk verschilt het van NoSQL database tot database systeem hoe dicht deze BASE regels tegen de ACID regels aanleunen. De document-based CouchDB, die we later zullen in detail bekijken, ondersteunt ook vormen van transacties en dergelijke, wat het eerder iets ACID-achtig maakt.\nMemcached Memcached is een distributed in-memory key/value store die op grote schaal gebruikt kan worden als caching mechanisme. Systemen als Memcached zijn enorm performant en worden vaak gebruikt als caching database die geplaatst wordt voor de eigenlijke RDBMS:\ngraph LR; user[User] cache{Cache DB} db{Relationele DB} user --|Haal genres op| cache cache --|cache hit| user cache --|cache miss| db db --|refresh| cache  Het feit dat Netflix Memcached sponsort zegt genoeg. Memcached gebruiken is erg eenvoudig en gewoon een kwestie van de API in Java/Kotlin aan te spreken om data te feeden/op te halen.\nEen simpel Memcached voorbeeld is terug te vinden onder key-value stores: memcached.\n4. Wide-column databases. Wide-column, of column-based databases, zijn eigenlijk relationele databases op zijn kop\u0026mdash;letterlijk.\nWat is het grootste nadeel van het queryen van relationele databases? Deze zijn row-based: als je alle genres uit een BOEK tabel wilt halen, zal je alle rijen moeten afgaan en daar een DISTINCT op doen\u0026mdash;alles behalve performant. Bijvoorbeeld:\nid genre title price 1 Fantasy book bla 10 2 Fantasy another title 20 3 horror wow-book 10 Hoe haal ik hier alle genres op? SELECT DISTINCT(genre) FROM boeken. Wat is de gemiddelde prijs? SELECT AVG(price) FROM boeken\u0026mdash;ook een erg dure operatie indien er miljoenen records aanwezig zijn. Een snelheidswinst valt te boeken door te werken met indexen, maar daar lossen we niet alles mee op.\nWat nu als je de kolommen als rijen beschouwt, op deze manier:\ngenre: fantasy:1,2 horror: 3 title: book bla:1, another title:2 wow-book: 3 price: 10:1,3 20:2 Wat is nu de gemiddelde prijs? Haal 1 \u0026ldquo;rij\u0026rdquo; op en deel door het aantal. Welke genres zijn er zoal? De eerste rij is al onmiddellijk het antwoord! We verzamelen hier dus vertical slices van data, wat erg belangrijk kan zijn voor Business Intelligence (BI): super-linked data tussen de \u0026ldquo;echte\u0026rdquo; row-based data.\nDe meest gebruikte column-DB is Cassandra. Op de website staat:\n Manage massive amounts of data, fast, without losing sleep.\n Cassandra komt met in-memory buffers, tracking \u0026amp; monitoring, \u0026hellip;\nCase Studies Welke database systemen\u0026mdash;of een combinatie ervan\u0026mdash;denk je dat de volgende grote bedrijven hanteren voor hun producten?\n    https://www.benl.ebay.be/ Hint: https://www.slideshare.net/jaykumarpatel/cassandra-at-ebay-13920376 (2012)      https://www.army.mil/ Hint: https://go.neo4j.com/rs/710-RRC-335/images/Neo4j-case-study-US-army-EN-US.pdf (2019)      https://spotify.com/ Hint: https://engineering.atspotify.com/2015/01/09/personalization-at-spotify-using-cassandra/ (2015)      https://uber.com/ Hint: http://highscalability.com/blog/2016/9/28/how-uber-manages-a-million-writes-per-second-using-mesos-and.html (2016)  Denkvragen  Is een RDBMS of een NoSQL database geschikter om aan \u0026ldquo;Big Data\u0026rdquo; te doen? Waarom wel/niet? Waarom vereist ring partitioning consistent hashing? Wat heeft een hashing functie te maken met het horizontaal kunnen schalen van data in een DBMS? Waarom gebruiken zo veel grote bedrijven een combinatie van verschillende DBMS systemen? Zie je hier ook nadelen in? Wanneer denk je dat een column-based database als Cassandra nuttig zou zijn? Leg het verschil tussen ACID en BASE uit in functie van de typische eigenschappen van een database. Waarom werkt vertical scaling niet? Waarom wel?  "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/sql/",
	"title": "1. RDBMS",
	"tags": [],
	"description": "",
	"content": "RDBMS Zie menu links.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/transacties/basics/",
	"title": "1. Transaction Mgmt. Basics",
	"tags": [],
	"description": "",
	"content": "SQL DBMS systemen zijn eerst en vooral multi-user systemen. Om zowel verschillende gebruikers te kunnen behandelen als nog steeds de ACID regels ondersteunen, is er een systeem nodig dat soms gebruikers \u0026ldquo;in wacht\u0026rdquo; zet. Stel je voor dat Jens en Jolien tegelijkertijd data lezen én updaten\u0026mdash;in dezelfde tabel, hetzelfde record. Jens leest uit \u0026ldquo;de rekening staat op 100 EUR\u0026rdquo; en Jolien haalt er 10 EUR vanaf. Wie mag eerst? Kan dit tegelijkertijd? Jens krijgt te horen dat er 100 EUR op de rekening staat, terwijl in werkelijkheid dit 10 EUR minder is.\n0. Waarom transacties? Heel simpel. Dit is het verkeer zonder transacties:\n   Dit met:\n   Om Atomicity, Consistency, Isolation, Durability te garanderen is er dus een transactie manager nodig die alles in goede banen leidt op het moment dat verschillende gebruikers data gaan raadplegen en/of manipuleren. Dit principe is ruwweg hetzelfde als task management van het vak Besturingssystemen en C\u0026mdash;maar dan op database-applicatie niveau.\n1. Wat is een transactie? Een transactie is een set van database operaties (bij relationele databases dus een aantal SQL operaties), dat door één gebruiker of applicatie als één unit of work aanzien wordt. Bijvoorbeeld, Jens wilt geld overschrijven van zijn rekening naar die van Jolien. Dit gaat meestal in verschillende stappen:\n Haal €10 van balans van Jens; Stort €10 op balans van Jolien.  graph LR; JN[Rekening van Jens] JL[Rekening van Jolien] JN --|10 EUR| JL  Dit is één transactie\u0026mdash;het zou nooit mogen gebeuren dat er €10 verdwijnt van Jens' account zonder dat Jolien dat geld ontvangt. Met andere woorden, er kan niets tussen stap 1 en stap 2 komen: geen systeem crash, geen andere gebruiker (bijvoorbeeld Marianne die Jens €20 voor zijn verjaardag stort op de rekening). Dit is één \u0026ldquo;unit of work\u0026rdquo;: als er iets misloopt zou alles teruggedraaid moeten worden. Dus, een transactie heeft als resultaat ofwel success, ofwel failure, maar niets tussenin. Indien dit succesvol wordt afgerond zou het DBMS systeem moeten garanderen dat het geld effectief op Jolien\u0026rsquo;s rekening staat. Indien het faalde zou het DBMS systeem moeten garanderen dat Jens zijn geld niet kwijt is.\nIn de praktijk worden veel verschillende transacties tegelijkertijd uitgevoerd\u0026mdash;eventueel door verschillende gebruikers. Er moet dus iemand zijn die dit beheert, en dat is de transactie manager. Wie beslist of Jens eerst zijn geld mag afhalen, of dat Marianne eerst zijn verjaardagscadeau mag overmaken op de rekening? Wie beslist dat tussen stap 1 en 2 bij de transfer van het geld van Jens naar Jolien niemand mag tussenkomen? Juist: de transactie manager. Hier zijn verschillende strategieën voor, zoals we later zullen zien in Concurrency Control.\n2. Het beheren van transacties Formeel gezien wordt er een transactie afgelijnd door aan te kondigen wanneer een transactie begint en wanneer hij stopt, zodat de manager de juiste acties kan doorvoeren. De gebruiker kan met SQL ook zelf een transactie terugdraaien als er een programmafout voorkomt, bijvoorbeeld met een try { ... } catch(Exception ex) { rollback }. Meer hierover in sectie failures/rollbacks.\nDe transactie manager, die afgelijnde transacties ontvangt, kan dit dan in een schedule zetten, om te beslissen welke (delen van) transacties wanneer moeten worden uitgevoerd, net zoals Round Robin CPU scheduling algoritmes. Uiteindelijk wordt er een status toegekend aan een transactie:\n Committed\u0026mdash;het is gelukt en de data is permanent gepersisteerd. Aborted\u0026mdash;Een error tijdens het uitvoeren van de transactie.  Indien er halverwege de abort data is gewijzigd moet dit worden teruggezet, of worden rollbacked. Vorige versies van data moet dus ook worden bijgehouden. Jens' rekening kan bijvoorbeeld €90 zijn initieel, hij haalt er €10 af om over te maken wat dit tot €80 maakt, maar er loopt iets mis: de rollback triggert het terugdraaien van het getal 80 naar de originele 90.\nDit is een pseudocode voorbeeld van bovenstaande afgelijnde transactie:\nBEGIN TRANSACTION; UPDATE account SET waarde = waarde - :over_te_maken_bedrag WHERE eigenaar = 'Jens' UPDATE account SET waarde = waarde + :over_te_maken_bedrag WHERE eigenaar = 'Jolien' COMMIT; Transacties kosten CPU en RAM en zijn configureerbaar maar dus gelimiteerd in aantal. De manager kan worden ingesteld tot bijvoorbeeld ondersteunen van maximum 10 transacties tegelijkertijd.\nDBMS Componenten bij een transactie Een voorbeeld van een transactie workflow (de nummers komen overeen met het schema):\n  DBMS componenten aan het werk tijdens een transactie. src: pdbmbook.com   De manager waarschuwt de scheduler dat er een nieuwe transactie moet worden ingepland. Deze optimaliseert dit naar throughput (zie BESC); De recovery en stored data manager worden op de hoogte gebracht. Deze optimaliseert disk access: het zou kunnen dat DB reads/writes via een buffer verlopen omdat fysieke file operaties duur zijn; De scheduler is nu klaar om input te ontvangen en uit te voeren in de juiste volgorde; Dit triggert mogelijks interactie met de stored data manager (het effectief wegschrijven van wijzigingen); De uitkomst wordt doorgegevan via een output area: ofwel is het gelukt (5b), ofwel is het mislukt (5a), waardoor de recovery manager zijn werk moet doen om dingen terug te draaien.  3. Wat als er iet misgaat? Hoe werkt dat blokje \u0026ldquo;recovery manager\u0026rdquo; precies? Een DBMS systeem gebruikt achterliggend een logfile als belangrijk element om eventuele recoveries te kunnen doorvoeren. Een logfile bevat in principe redundante data: in het beste geval wordt dit nooit gebruikt. Maar in het geval dat er ook maar iets misloopt is het van groot belang dat de log entries kunnen worden gebruikt om de data terug te zetten.\nVoor elke transactie en operatie wordt relevante informatie geregistreerd in de logfile als een log record. Deze bevat de volgende informatie:\n Een unieke Log ID; Een unieke Transactie identifier om de records te kunnen koppelen aan de transacties; Een markering voor de start van de transactie + tijd + type (read/write/read-write combo) aan te duiden; Database record identifiers en operaties (select/insert/\u0026hellip;.) die bij de transactie horen; before images: een snapshot van de data voordat de transactie werd doorgevoerd. Deze worden gebruikt om een undo uit te voeren; after images: een snapshot van de data nadat de transactie werd doorgevoerd. Deze worden gebruikt om een redo uit te voeren, moest bijvoorbeeld een fysieke file write mislukken en hier een retry op worden toegepast.  Er wordt altijd eerst in de logfile geschreven: dit noemen we een write-ahead log strategy. Op die manier is de DBMS manager voorbereid op een mogelijke rollback. Alle updates worden dus eerst naar de logfile geschreven voordat er iets fysiek veranderd op de harde schijf. Merk op dat de \u0026ldquo;logFILE\u0026rdquo; ook (gedeeltelijk) in-memory kan zijn.\nWat kan er zoal misgaan? Failures worden in drie groepen opgedeeld:\n Transaction failures: fouten in de logica van de transactie, zoals verkeerde input, incorrecte variabelen, statements die niet kloppen, etc. Sommige applicaties vangen dit al op voordat het naar de DBMS gaat. System failures: DB of OS crashes op de server, bijvoorbeeld door stroomonderbrekingen of bugs in de database zelf. Het zou kunnen dat de DBMS buffer inhoud hierdoor leeg raakt en delen van data niet teruggezet kunnen worden. Media failures: Storage access fouten door bijvoorbeeld disk crashes, een storing in het netwerk, etc. Het zou kunnen dat de logfile niet toegankelijk is.  Het is de moeite waard om even te kijken naar de laatste 2 groepen en hoe daar recovery processen precies werken.\nSystem Recovery Veronderstel dat er 5 transacties door de DBMS worden verwerkt. Tc duidt een checkpoint aan van de data in de buffer. Er treedt een systeemfout op rechts bij Tf:\n  UNDO/REDO operaties voor 5 \u0026#39;kapotte\u0026#39; transacties. src: pdbmbook.com  We bekijken de 5 transacties afzonderlijk:\n T1\u0026mdash;Aangezien deze succesvol werd gecommit voor de systeemfout én voor de snapshot Tc, hoeft hier niets voor te gebeuren na een crash. T2\u0026mdash;Deze transactie is ook compleet voor Tf, maar er zit nog data in de buffer van de snapshot Tc die niet naar disk geschreven werd. Hier is dus een REDO nodig. T3\u0026mdash;Deze transactie was nog bezig bij de crash van Tf. We hebben niet alle data in de buffer: er is dus transactie data verloren gegaan: een UNDO dus. T4\u0026mdash;Deze transactie is gelukt maar alle data is nog steeds pending to disk (bij T2 was dit een deel): REDO. T5\u0026mdash;De DBMS scheduler had deze net ingepland toen het systeem crashte. Het is niet nodig om hier is van terug te draaien omdat er niks pending was (na de Tc checkpoint).  Media Recovery Wat doe jij als er een harde schijf gerashed is van je computer? Bidden voor een werkende backup? Indien fysieke files niet meer toegankelijk zijn is een \u0026ldquo;media recovery\u0026rdquo; afhenkelijk van data redundancy principes. Hopelijk heb je een backup strategie voorzien. Voor database systemen wordt dit streng toegepast en moeten we een recovery doorvoeren via een mirror op een andere HDD in RAID, op een cloud backup, een offline backup, \u0026hellip;\nOm de failover time te minimaliseren wordt dit vaak automatisch opgezet. Een harde schijf kan in een server in RAID-1 modus geplaatst worden: die functioneert als 100% clone van de andere. Indien er één van beide HDDs faalt, neemt onmiddellijk de andere het werk over, zodat gebruikers zo goed als geen last hebben van de media failure. Systemen als backup copies door iets te \u0026ldquo;archiveren\u0026rdquo; (een .tar.gz of .zip op bepaalde tijdstippen aan de kant zetten) vereist meestal meer werk om terug te zetten. Backups nemen betekent ook beslissen of het een full of incremental backup zal zijn, waarbij je (1) alle files apart zet, of (2) enkel de wijzigingen ten opzichte van vorige snapshots.\nEen goede backup strategie\u0026mdash;dit geldt zowel voor databases als voor je eigen data!!\u0026mdash;volgt het 1-2-3 backup principe:\n Zorg voor minstens drie backups van je data, waarvan twee lokaal maar op verschillende media (bvb, verschillende servers, op HDD en op USB, \u0026hellip;), en één off-site kopie, zoals cloud-based backup systemen als Dropbox, Google Drive, Backblaze\u0026rsquo;s Cloud Storage.  Dan hebben we het nog niet over security gehad\u0026hellip;\nDenkvragen  Waarom kan je niet gewoon media recovery strategieën toepassen bij systeemcrashes? Waarom wel, maar is dat misschien geen goed idee? Als er verschillende transacties tegelijkertijd aan één record iets wijzigen, welke problemen zie jij dan zoal? Hoe zou je dat door de transaction manager laten oplossen? Kan je zo twee verschillende oplossingen bedenken? Wat is alweer het verschil tussen UNDO en REDO recovery technieken? Als ier iets misgaat op applicatieniveau, bijvoorbeeld een crash in je Java applicatie, moet de DBMS dan iets doen, of moet de programmeur dan iets doen, om ACID te blijven garanderen? Wat zou er volgens jou moeten gebeuren als twee personen tegelijkertijd op bol.com een item bestellen waarvan maar één hoeveelheid in stock is? Wie trekt hier aan het korte eind? Hoe vangen grote webwinkels dit probleem op?  "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/xml/basics/",
	"title": "1. XML Basics",
	"tags": [],
	"description": "",
	"content": "XML Data Storage XML staat voor Extensible Markup Language. Het is een taal die we gebruiken om met tags gegevens te structureren. Een tag opent zich op volgende manier: \u0026lt;boek\u0026gt; en sluit op deze manier: \u0026lt;/boek\u0026gt;. Je herkent misschien het gebruik van deze tags van HTML? Dat komt omdat HTML en XML allebei gegroeid zijn uit dezelfde taal (SGML).\nWaarom XML gebruiken? XML is nog steeds een vaak voorkomende manier om data te structureren en definiëren. Denk bijvoorbeeld aan webhook calls waarbij je kan kiezen tussen een response te krijgen in XML of JSON. Al krijgt JSON de laaste jaren meer en meer voorkeur omwille van zijn makkelijke en leesbare syntax, toch zijn er nog instanties waarbij XML de enige optie is.\nVoorbeeld \u0026lt;boeken\u0026gt; \u0026lt;boek\u0026gt; \u0026lt;titel\u0026gt;De gouden kooi\u0026lt;/titel\u0026gt; \u0026lt;auteur\u0026gt;A.F.Th. van der Heijden\u0026lt;/auteur\u0026gt; \u0026lt;jaar\u0026gt;1981\u0026lt;/jaar\u0026gt; \u0026lt;/boek\u0026gt; \u0026lt;boek\u0026gt; \u0026lt;titel\u0026gt;Het diner\u0026lt;/titel\u0026gt; \u0026lt;auteur\u0026gt;Herman Koch\u0026lt;/auteur\u0026gt; \u0026lt;jaar\u0026gt;2009\u0026lt;/jaar\u0026gt; \u0026lt;/boek\u0026gt; \u0026lt;boek\u0026gt; \u0026lt;titel\u0026gt;De ontdekking van de hemel\u0026lt;/titel\u0026gt; \u0026lt;auteur\u0026gt;Harry Mulisch\u0026lt;/auteur\u0026gt; \u0026lt;jaar\u0026gt;1982\u0026lt;/jaar\u0026gt; \u0026lt;/boek\u0026gt; \u0026lt;/boeken\u0026gt; Wat opvalt is dat we in XML maar 1 root element hebben. De \u0026lt;boeken\u0026gt; tag is het root element van dit voorbeeld en er is geen enkele andere tag op dit niveau. Daarbinnen kunnen we dan wel meerdere keren het \u0026lt;boek\u0026gt; element definiëren.\nOefening  Voeg zelf een boek toe aan het bovenstaande voorbeeld Schrijf zelf een XML bestand dat studenten omschrijft. Volgende elementen moeten aanwezig zijn: Naam, leeftijd en studierichting.  "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/transacties/concurrency-control/",
	"title": "2. Concurrency Control",
	"tags": [],
	"description": "",
	"content": "De transactie management scheduler (zie transacties - basics) is verantwoordelijk om verschillende transacties correct in te plannen zonder dat er data problemen of clashes optreden.\n1. Problemen? Welke problemen? Denk terug aan het bank transfer probleem van de vorige sectie. Veronderstel dat deze keer zowel Jens als Marianne €10 willen overmaken naar Jolien. Als we dat als volgt doen:\n Verminder bedrag van source rekening Verhoog bedrag van destination rekening  Dan zou het kunnen dat bij het uitlezen van #2, Jolien\u0026rsquo;s rekening op €100 staat. Maar als de transactie van Marianne dit ook leest als €100, en niet wacht tot de €110 die het zou moeten zijn na de commit van de transactie van Jens, dan gaat in totaal Marianne slechts €10 rijker zijn in plaats van twee keer dat bedrag. Oeps!\ngraph LR; JN[Rekening van Jens] JL[Rekening van Jolien] ML[Rekening van Marianne] JN --|10 EUR| JL ML --|10 EUR| JL  Hieronder volgen een aantal veel voorkomende concurrency problemen die de transaction scheduler uitdagen.\nA. Lost Updates Dit is exact bovenstaande situatie. Het UPDATE statement van Jens' transactie (verhoog Jolien\u0026rsquo;s rekening met 10) is \u0026ldquo;verloren\u0026rdquo;, omdat Marianne hier tussen komt, en haar UPDATE die terug ongedaan maakt:\n   time T1 (Marianne) T2 (Jens) bedrag     1  begin trans 100   2 begin trans read(bedrag): 100 100   3 read(bedrag): 100 bedrag = bedrag + 10 100   4 bedrag = bedrag + 10 write(bedrag) 110   5 write(bedrag) commit 110 (oeps)   6 commit  110    Dit voorbeeld illustreert dat, alhoewel beide transacties 100% correct zijn, er toch nog problemen kunnen optreden als transacties elkaar gaan storen. Het spreekt voor zich dat als T1 data zou lezen en schrijven uit een andere rij of tabel, dit geen probleem zou zijn\u0026mdash;in dit specifieke voorbeeld.\nB. Dirty Reads Een \u0026ldquo;dirty read\u0026rdquo; probleem is het lezen van \u0026ldquo;dirty\u0026rdquo; data\u0026mdash;data die eigenlijk voor de andere transactie nog niet zichtbaar mat zijn omdat het hier over uncommitted data gaat. Als Marianne\u0026rsquo;s read(bedrag) toch het juiste bedrag zou inlezen (110), voordat Jens' transactie compleet is, maar op een of andere manier is die transactie teruggedraaid, dan spreken we over een dirty read, en krijgt Jolien onterecht toch €20, terwijl Jens zijn €10 mag houden. It prints money!\n   time T1 (Marianne) T2 (Jens) bedrag     1  begin trans 100   2  read(bedrag): 100 100   3  bedrag = bedrag + 10 100   4 begin trans write(bedrag) 110   5 read(bedrag): 110  110   6 bedrag = bedrag + 10 ROLLBACK! 120 (oeps)   7 write(bedrag)  120   8 commit  120    C. Inconsistent Analysis Bij inconsistente analyse tussen twee transacties gaat het over een sequentie van verschillende dirty reads die de situatie alleen maar verergeren, zelfs zonder de eventuele rollback. Stel dat het over te schrijven bedrag in stukjes van €2 wordt overgeschreven, waarbij telkens tussenin een read(bedrag) plaats vindt\u0026mdash;die natuurlijk de data van de andere transactie inleest. Het resultaat is, opnieuw, een veel te grote som, en een mogelijks erg blije Jolien.\nWe laten een schematische voorstelling van dit probleem als oefening voor de student.\n\u0026hellip; En meer Er zijn nog verschillende andere mogelijkheden waarbij de scheduler de bal kan misslaan. Bijvoorbeeld door unrepeateable reads: transactie T1 leest dezelfde rij verschillende keren in maar verkrijgt telkens andere waardes (wat niet zou mogen) vanwege andere transacties die ook met die rij bezig zijn.\nOf wat dacht je van phantom reads: transactie T2 is bezig met rijen effectief te verwijderen, terwijl T1 deze toch nog inleest. Het zou kunnen dat hierdoor verschillende rijen ontstaan (T2 rollback, T1 die een nieuwe rij maakt), of dat voorgaande bestaande rijen verdwijnen door T2, waardoor de transactie van T1 mogelijks faalt.\nTeruggrijpende naar ons Jolien voorbeeld, stel dat Jens Jolien €5 wilt betalen per klusje dat ze gedaan heeft. Klusjes worden opgeslagen in een aparte tabel, maar ondertussen kan Jolien een nieuw klusje afvinken, waardoor Jens' transactie een phantom read krijgt:\n   time T1 (Jens) T2 (Jolien) klusjes     1 read 1: SELECT * FROM klusjes WHERE naam = 'Jolien' (2)  2   2   2   3 random ander werk INSERT INTO klusjes ... 3   4   3   5 read 2: SELECT * FROM klusjes WHERE naam = 'Jolien' (3, oeps)  3   6 sort 3x5 op rekening (teveel)  3   7 commit      Bijgevolg verkgijt T1 inconsistente data: de ene keer 2, de andere keer 3\u0026mdash;vergeet niet dat het goed zou kunnen dat T2 nog teruggedraaid wordt.\n2. Scheduler oplossingen Wat is de simpelste manier om bovenstaande problemen allemaal integraal te vermijden? Juist ja\u0026mdash;sequentieel transacties verwerken.\nA. Serial scheduling Met serial scheduling is T2 verplicht te wachten op T1 totdat die zijn zaakje op orde heeft. De lost update transactie flow van hierboven ziet er dan als volgt uit:\n   time T1 (Marianne) T2 (Jens) bedrag     1  begin trans 100   2  read(bedrag): 100 100   3  bedrag = bedrag + 10 100   4  write(bedrag) 110   5  commit 110   6 begin trans  110   7 read(bedrag): 110  110   8 bedrag = bedrag + 10  120   9 write(bedrag)  120   10 commit  120    Wat valt je op als je naar de time kolom kijkt? Serial scheduling duurt nu 10 ticks t.o.v. 6 bij de potentiële lost update\u0026mdash;da\u0026rsquo;s een redelijk grote performance hit van 40%! Serial scheduling lost misschien wel alles op, maar daardoor verliezen we alle kracht van het woord parallel: dit is in essentie non-concurrency.\nWat zijn dan betere scheduling alternatieven?\nB. Optimistic scheduling Bij \u0026ldquo;optimistic\u0026rdquo; scheduling gaan we ervan uit dat conflicten tussen simultane transacties nauwelijks voorkomen. Met andere woorden, we benaderen het probleem (misschien te) optimistisch. Transacties mogen gerust tegelijkertijd lopen als ze bijvoorbeeld verschillende tabellen of stukken data in dezelfde tabel bewerken\u0026mdash;zolang er geen conflict is, geniet paralellisatie de voorkeur.\nBij optimistische schedulers worden alle transactie operaties doorgevoerd. Wanneer deze klaar zijn voor een eventuele COMMIT, wordt er gecontroleerd op potentiële conflicten. Indien geen, success. Indien wel, abort en ROLLBACK.\nMerk op dat rollback operaties erg dure operaties zijn: de manager moet graven in de logfile, moet beslissen of er UNDO/REDO operaties moeten worden uitgevoerd, er is mogelijke trage disc access (I/O), \u0026hellip; Als je vaak rollbacks hebt/verwacht is optimistic scheduling nog steeds geen performant alternatief.\n C. Pessimistic scheduling Bij \u0026ldquo;pessimistic\u0026rdquo; scheduling gaan we van het omgekeerde uit: transacties gaan heel zeker conflicteren. De scheduler probeert transactie executies te verlaten om dit zo veel mogelijk te vermijden. Een serial scheduler is een extreem geval van een pessimistic scheduler.\nLocking In de praktijk wordt locking gebruikt op een pre-emptive manier (zie besturingssystemen: scheduling algorithms) om toch transacties waar mogelijk concurrent te laten doorlopen. Bij transacties die schrijven in plaats van die enkel lezen zullen locks eerder nodig zijn. Er bestaan uiteraard erg veel verschillende locking technieken/algoritmes.\nWe maken onderscheid tussen twee groepen:\n exclusive locks: als T1 een exclusieve lock neemt, kan er geen enkele andere transactie op die database worden uitgevoerd. Dit is een erg strict systeem, denk aan serial scheduling. shared locks: zolang T1 een lock neemt op een object (zie onder), krijgt het de garantie dat geen enkele andere transactie dat object kan manipuleren totdat de lock terug wordt vrijgegeven (eventueel ook door middel van een rollback). Locks worden \u0026ldquo;gedeeld\u0026rdquo;: T1 krijgt write access, en T2 moet wachten met schrijven, maar mag wel lezen.  De database \u0026ldquo;objecten\u0026rdquo; waar een lock op genomen kan worden zijn onder andere (van kleine locks naar groot):\n row locks; column locks; page locks (delen van een tabel zoals stored in files); table locks; databas locks (bvb een file lock in SQLite);  Een lock op één rij in beslag genomen door T1 betekent dat voor diezelfde tabel T2 nog steeds bedragen kan wijzigen van een andere rekening. Column locks kunnen tot meer wachttijd leiden. Page locks zijn \u0026ldquo;stukken\u0026rdquo; van een tabel (rijen voor x en erna). Een page is een chunk van een tabel die op die manier wordt opgeslaan. Dit verschilt van DB implementatie tot implementatie. Tenslotte kan een hele tabel gelockt worden\u0026mdash;of de hele tablespace\u0026mdash;wat meer pessimistisch dan optimistisch is.\nLocks zijn onderhevig aan dezelfde nadelen als rollbacks: ze zijn duur. Als er erg veel row locks zijn op een bepaalde tabel kan dit veel CPU/RAM in beslag nemen. In dat geval kan de lock manager beslissen om aan lock escalation te doen: de 100 row locks worden één page of table lock. Dit vermindert resource gebruik drastisch\u0026mdash;maar zou transacties ook langer kunnen laten wachten. You win some, you lose some\u0026hellip;\n Problemen bij oplossen van problemen: deadlocks Stel dat Jens cash geld wilt deponeren, en Marianne hem ook geld wenst over te schrijven. Voordat Marianne dat doet koopt ze eerst nog een cinema ticket. Jens wil ook een ticket in dezelfde transactie. Het gevolg is dat T1 en T2 oneindig op elkaar blijven wachten. Dat ziet er zo uit:\ngraph LR; C{Cinema tabel} R{Rekening tabel} J[Jens] M[Marianne] J --|deposit 10| R M --|transfer 10| R M --|koop ticket| C J --|koop ticket| C  De kruisende pijlen duiden al op een conflict:\n   time T1 (Jens) T2 (Marianne)      1 begin tarns     2  begin tarns    3 update rekening (acquire lock R)     4  update cinema (acquire lock C)    5 poging tot update cinema (WACHT)     6  poging tot update rekening (WACHT)     Deze (simpele) deadlock kan gelukkig gedetecteerd worden door het DBMS systeem. Die zal één van beide transacties als \u0026ldquo;slachtoffer\u0026rdquo; kiezen en die transactie terugdraaien\u0026mdash;meestal gebaseerd op welke het makkelijkste is om terug te draaien. Het probleem is dat de meeste applicaties niet onmiddellijk voorzien zijn op zo\u0026rsquo;n onverwachte rollback. Dit resulteert meestal in een negatieve gebruikerservaring.\nDeadlocks en algoritmes om dit te detecteren en op te lossen zijn erg complexe materie. Het volstaat om bovenstaand eenvoudig voorbeeld te kennen, en te weten hoe dat aangepakt zou kunnen worden\u0026mdash;bijvoorbeeld met starvation, timeouts, en priority shift principes zoals ook gezien in het vak Besturingssystemen en C.\nZie ook A beginners guide to DB deadlocks.\nIsolation levels Pessimistic locking kan veel problemen opvangen, maar ten koste van performantie\u0026mdash;wat meestal belangrijker is. Voor veel transacties is het oké om met een minimum aan conflicten de throughput van transacties zo hoog mogelijk te houden. De meeste DBMS systemen zijn hier flexibel in: je kan wat we noemen isolation levels instellen, dat meestal bestaat uit de volgende vier opties (van low naar high isolation):\n Read uncommited\u0026mdash;Dit laat toe om \u0026ldquo;uncommited\u0026rdquo; data te lezen (dat problemen geeft, zie boven), en wordt meestal gebruikt in combinatie met read-only transacties. Read committed\u0026mdash;Gebruikt short-term read locks en long-term write locks, en lost zo het inconsistent analysis/lost update probleem op, maar is niet krachtig genoeg om phantom reads tegen te houden. Repeatable read\u0026mdash;Gebruikt long-term read \u0026amp; write locks. Een transactie kan zo dezelfde rij verschillende keren opnieuw lezen zonder conflicten van insert/updates van andere transacties. Het phantom read probleem is echter nog steeds niet opgelost. Serializable\u0026mdash;het krachtigste isolation level dat in theorie aansluit met serial scheduling.  Een short-term lock wordt enkel vastgehouden gedurende het interval dat nodig is om een operatie af te ronden, terwijl long-term locks een protocol volgen en meestal tot de transactie commited/rollbacked is vastgelegd zijn.\nMerk op dat voor elke database implementatie de selectie van een isolation level andere gevolgen kan hebben! Zie de tabellen in https://github.com/changemyminds/Transaction-Isolation-Level-Issue. Het is dus van belang de documentatie van je DB te raadplegen, zoals deze van Oracle, waarin de volgende beschrijving staat voor TRANSACTION_SERIALIZABLE: \u0026ldquo;Dirty reads, non-repeatable reads and phantom reads are prevented.\u0026rdquo;.\n We komen hier nog later op terug in concurrency in practice wanneer we bijvoorbeeld bij JPA of Hibernate aangeven welk isolation level gewenst is.\nDenkvragen  Waarom is het phantom read probleem niet opgelost bij isolation level 3 (repeatable read)? Kan je nog andere situaties verzinnen waarin een deadlock kan voorkomen? Welk isolation level of scheduling algoritme lost dit op? Wat is de verantwoordelijkheid van de DBMS\u0026rsquo;s transactie management systeem in verhouding tot de ACID eigenschappen? Welke impact heeft lock granulariteit op transactie throughput?  "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/bigdata/datawarehousing/",
	"title": "2. Data Warehousing &amp; BI",
	"tags": [],
	"description": "",
	"content": "Tot nu toe hebben we ons toegelegd op het zo optimaal mogelijk bewaren en ophalen van data\u0026mdash;rekening houdend met integriteit en anderen ACID/BASE principes. Maar wat zijn we hier nu allemaal mee, los van een werkende applicatie? In dit hoofdstuk gaan we data benaderen vanuit business perspectief.\nEen bedrijf kan gebaseerd op de miljoenen eenheden data dat het verzameld, op verschillende plekken en in verschillende formaten, beter beslissingen nemen. Strategische business beslissingen worden meestal op verschillende niveau\u0026rsquo;s genomen:\n Niveau 1 noemen we het operationeel niveau. Hier worden dagelijkse beslissingen genomen op korte termijn, vaak zonder al te veel naar de toekomst te kijken. Denk maar aan verschillende verkopen, implementatie beslissingen vanuit business perspectief, enzovoort. Niveau 2 noemen we het tactisch niveau. Middle management probeert hier op middellange termijn (bijvoorbeeld een maand/kwartaa/jaar) een vooruitblik te doen en gebaseerd daarop een partnerschap aan te gaan of af te wijzen. Niveau 3 noemen we het strategisch niveau. Senior management neemt beslissingen op dit niveau om het bedrijf op lange termijn (5 jaar of misschien zelfs langer) op koers te houden.  Stel dat jij een bedrijf van 100 man hebt. Hoe beslis je waarin te investeren, om binnen 5 jaar niet failliet te zijn, maar misschien uit te groeien tot een bedrijf van 150 man? Hier kan data helpen met beslissen. De term Business Intelligence (BI) slaat hier op: de set van activiteiten, technieken, en tools om (1) patronen in data van het verleden te herkennen en (2) voorspellingen te maken naar te toekomst toe.\nEen bijkomend probleem is dat je groot bedrijf enorm veel data heeft:\n Het genereert dagelijks facturen en sales; Werknemers gebruiken de tikklok die weer data voorstelt; Je eindgebruikers interageren met jullie software, wat misschien verspreid zit over verschillende systemen; De helpdesk beheert tickets; HR houdt indexen van lonen bij en iemand beheert de fleet van bedrijfswagens; \u0026hellip;  Het is duidelijk dat één simpele SELECT sales FROM income niet voldoende gaat zijn voor het management om beslissingen te helpen maken. We hebben een data warehouse nodig.\n  src: sqlhammer.com  Probeer op bovenstaand schema, een voorbeeld van hoe moderne data warehouses werken in een groot bedrijf, alle verschillende componenten te identificeren. Links staat de data die binnenkomt, en rechts het resultaat van de analyse. We bespreken hieronder kort elk blok. Experimentatie met de praktische kant, door middel van libraries als Apache Hadoop, is een optionele oefening voor de student.\nWe beginnen met de grote blauwe blok: een \u0026ldquo;data warehouse\u0026rdquo;.\nEen Data Warehouse (DW) Wat is een data warehouse? Volgens de uitvinder, Bill Inmon:\n A data warehouse is a (1) subject-oriented, (2) integrated, (3) time-variant, and (4) non-volatile collection of data in support of management\u0026rsquo;s decision-making process.\n Dat klinkt ingewikkelder dan het is:\n Subject-oriented; de data is gecentreerd rond subjecten ofwel klanten, producten, sales, etc. De data is niet gecentreerd rond transacties of applicaties. Het moet managers helpen een beslissing maken, niet developers helpen ontwikkelen. Integrated; het is één grote structuur met als input verschillende andere DB sources met elk hun eigen formaat. Hier is dus conversie voor nodig: zie verder. Time-variant; een data warehouse bewaart data als een series van snapshots: bij intervallen van bijvoorbeeld elk kwartaal wordt data vernieuwd. Non-volatile; data is voornamelijk read-only (na initieel inladen): de belangrijkste operaties zijn dus loading \u0026amp; retrieval.  Bekijk de volgende schematische weergave van een typische data warehouse:\ngraph BT; WH[(Data Warehouse)] RDBMS1[[RDBMS 1]] RDBMS2[[RDBMS 2]] XML[/XML\\] MAIL[/E-MAIL\\] ETL1{{ETL}} ETL2{{ETL}} ETL3{{ETL}} ETL4{{ETL}} ETL1 -- WH ETL2 -- WH ETL3 -- WH ETL4 -- WH RDBMS1 -- ETL1 RDBMS2 -- ETL2 XML -- ETL3 MAIL -- ETL4  Aan de onderkant zie je verschillende bronnen van data\u0026mdash;zeer waarschijnlijk op zichzelf relationele of niet-relationele databases, XML, emails, HTML, andere losse CSV bestanden, \u0026hellip; Die moeten vanwege het integrated principe allemaal in één grote blok als snapshot worden bewaard zodat het management deze makkelijk kan queryen. Daarom moet er voor élke data source een ETL of Extraction, Transformation, and Loading proces worden opgestart: bepaalde attributen in de XML veranderen van structuur, de datum in RDBMS1 is opgeslaan als YYYY-MM-DD maar in RDBMS2 als DD-MM-YYYY, afrondingsverschillen worden weggewerkt, etc etc. Merk op dat niet altijd alle gegevens genormaliseerd worden. Een data warehouse kan dus best ook gedenormaliseerde data bevatten, maar dat komt minder frequent voor.\nEen data warehouse is dus geaggregeerde en opgekuiste data dankzij de ETLs. Er is vooral high-level data te vinden die kan gebruikt worden voor tactische, en vooral strategische beslissingen, maar minder voor operationele. Daarvoor kijk je best gewoon naar de bronnen zelf.\nHet opzetten van de ETL is waarschijnlijk 80% van het werk, dit is héél tijdsintensief!\nQ: Over hoeveel data gaat het in een data warehouse? A: Veel. Erg veel. Er zijn warehouses (vandaar ook \u0026ldquo;warenhuis\u0026rdquo; en niet zomaar \u0026ldquo;database\u0026rdquo; of \u0026ldquo;servertje\u0026rdquo;) van 12 petabytes, wat 12000 terabytes is. Bedenk hoeveel data wij elke minuut genereren: hoeveel tweets, hoeveel beurstransacties, hoeveel commits, \u0026hellip;\n In sommige gevallen wenst men niet onmiddellijk alle data in de productie warehouse te bewaren, maar eest nog een staging area op te zetten. Deze warehouse staat voor de \u0026ldquo;echte\u0026rdquo; en en kan bijvoorbeeld worden gebruikt om intensieve machine learning algoritmes op te laten draaien zonde dat de performantie van de effectieve warehouse in het gedrang komt. Zo\u0026rsquo;n staging warehouse noemen we een operational data store. (zie schema bovenaan: links van het Hadoop logo).\nVoor BI systemen om effectief te zijn, moet de data ook kwalitatief zijn. Gebaseerd op \u0026ldquo;rommel\u0026rdquo; een grote toekomstgerichte business planning maken is een recept voor mislukking\u0026mdash;en mogelijks faillisement. Dus: Garbage In, Garbage Out (GIGO). ETLs moeten correct zijn, en het is ook een kwestie van de juiste data op te nemen in je warehouse. Niet alles hoeft of kan van belang zijn.\nRDBMS vs DW Hoe verhoudt een data warehouse zich ten opzichte van een typisch transactionele database?\n    Transactional system Data Warehouse     Usage Day to day ops Decision support mngt   Latency real-time periodic snapshots   Design app-oriented subject-oriented   Normalization normalized (sometimes also) denormalized data   Manipulation insert/update/delete/select insert (once)/select   Transaction mngt important less of a concern   Type of queries many simple few complex, some ad-hoc    Mini DWs: Data Marts In de praktijk is één gigantische data warehouse, afhankelijk van de grootte van het bedrijf, niet bruikbaar. Data snapshot storage wordt meestal in functionele stukken opgeslagen, misschien opgedeeld per business unit, zoals het bedrijf ook is ingedeeld:\ngraph BT; WH[(Data Warehouse)] DM1[(Mart 1: Sales)] DM2[(Mart 2: Accounting)] DM3[(Mart 3: Finances)] DM1 -- WH DM2 -- WH DM3 -- WH  Elke mart wordt op zijn beurt gevoed via een ETL zoals het eerste schema in dit hoofdstuk.\nHet voordeel van zo\u0026rsquo;n opdeling in data marts is (1) focused content en (2) uiteraard performantiewinst. De managers van sales moeten niet onnodig in de accounting mart queries afvuren en omgekeerd, alhoewel het hoger management natuurlijk nog steeds graag een overzicht van alles heeft in bepaalde verslagen.\nData Lakes Soms zijn data warehouses en hun marts niet flexibel genoeg om de gigantische (en eindeloze) stroom aan data te kunnen opslaan. Vergeet niet dat ETLs ook veel processorkracht vereisten, en een snapshot maken maar op een vaste periode gebeurt. In dat geval is een data lake handig: letterlijk een meer waar alle inkomende data (relatief) ongestructureerd wordt ingedumpt (zie lichtblauwe balk op schema bovenaan).\nWanneer voedt men een lake en wanneer een warehouse? Een lake wordt vooral gebruikt voor native data\u0026mdash;in zijn ruw formaat. Hier is nog geen ETL aan bod gekomen. Als het over ruwe signaaldata gaat, clickstreams, social media feeds, server logs, etc, dan is een data lake interessanter.\nNet omdat dit allemaal ruwe data is, is het analyseren van die data werk voor specialisten: dit zijn de \u0026ldquo;advanced analytics\u0026rdquo; op het bovenstaande schema. Hier zijn data scientists mee bezig. De gemiddelde bedrijfsmanager heeft hier echter niets aan! Een data lake is dus niet voldoende om bedrijfsbeslissingen te kunnen helpen maken\u0026mdash;de voornaamste reden waarom we met warehousing bezig zijn. Vaak wordt data van een lake nog doorgesluisd naar een operational data store, die op zijn beurt data laat doordruppelen naar de productie warehouse. Het wordt ingewikkeld\u0026hellip;\nData warehousing wordt ook aangeboden in de cloud. Data lakes worden vaak in de cloud gehost om kosten te drukken aangezien hier nog grotere hoeveelheden data wordt bewaard. Een voorbeeld hiervan is Amazon Redshift, dat wordt gebruikt door Nasdaq. Ze verwerken er 70 miljoen records per dag: https://aws.amazon.com/solutions/case-studies/nasdaq-case-study/.\n "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/sql/rdbms-components/",
	"title": "2. Database Componenten",
	"tags": [],
	"description": "",
	"content": "1. Three Layer Architecture    Logical Layer De Logical Layer is waar we bepalen hoe onze data gestructureerd wordt. Hier bepalen we wat voor data we bijhouden, hoe die data eruitziet en hoe die zich gedraagt ten op zichte van onze andere datamodellen.\nEnkele voorbeelden hiervan zijn:\n Een BOEK mag door maximum 0 of 1 PERSONEN ontleend worden. Een PERSOON mag meerdere BOEKEN ontlenen. Een PERSOON is een subtype van een GEBRUIKER.  Oefening  Hoe zou een database model van een bibliotheek eruit zien? Teken zelf eens uit hoe dit gemodelleerd zou kunnen worden. Hoe houdt ik bij dat een boek uitgeleend werd? Wat als ik ook andere dingen wil uitlenen uit de bibliotheek, zoals DVD\u0026rsquo;s of eBooks?  Internal Layer De Internal Layer houdt zich bezig met alle details over hoe de data bewaard wordt. Sommige van de concepten die hier aan bod komen zijn de volgenden:\n Index management Constraint definities (uniek, referentieel, \u0026hellip;) Gepartitioneerde tabellen \u0026hellip;  Deze technologieën hebben allemaal te maken met performantie of data integriteit. We willen onze data op een zo\u0026rsquo;n performante manier opslaan én nog belangrijker op een zo performante manier terug ophalen.\nIndexatie Data wordt ongestructureerd bijgehouden in een tabel. Een tabel is eigenlijk niet meer dan een ongesorteerde lijst van gegevens. Bij elke nieuw element wordt dat aan het eind van de lijst toegevoegd.\nWat als we nu uit een lijst van miljoenen boeken de verzamelde werken van Tolkien willen ophalen? In plaats van door de hele lijst één voor één te gaan zoeken, kunnen we gelukkig gebruik maken van indexen.\nEen index is een inhoudstafel die we bijhouden van een bepaald aantal velden van onze tabel. Stel we hebben een Book tabel met miljoenen rijen, waaronder de volgende:\n   id isbn title author price     1345 0765326353 The Way of Kings Brandon Sanderson 24.99   6789 0395177111 The Hobbit J.R.R. Tolkien 24.99   3240 0812511816 The Eye of the World Robert Jordan 24.99   8939 0358439191 The Lord of the Rings J.R.R. Tolkien 24.99   1230 0143111582 Dune Frank Herbert 24.99    Als we een index zouden leggen op de author kolom dan zou die volgende informatie kunnen bevatten:\n   author id     Brandon Sanderson 1345   Frank Herbert 1230   J.R.R. Tolkien 6789   J.R.R. Tolkien 8939   Robert Jordan 3240    Een index houdt een mini-tabel bij van de velden die aan de index worden toegevoegd in combinatie met het identity1 veld. Deze tabel is wel gesorteerd op de velden uit de index, wat zoekopdrachten versnelt.\nConstraints We kunnen onze tabellen behoeden van corrupte data te bevatten door constraints te gebruiken. Het ISBN veld is bijvoorbeeld een uniek veld en mag nooit een waarde bevatten die al gekend is in onze database. Hiervoor kunnen we een unique constraint toevoegen. Bij data insertion gaat de database zelf nakijken of deze value al bestaat en zo ja wordt het toevoegen van de record geblokkeerd. Zo behouden we onze data integriteit.\nAndere voorbeelden van constraints kunnen zijn:\n De prijs van een boek moet groter dan 0 zijn Een boek kan niet verwijderd worden als het ooit werd uitgeleend  Gepartitioneerde tabellen Sommige tabellen in productie omgevingen bevatten immense hoeveelheden aan data. We spreken over een grootorde van meerdere miljarden rijen. Hoe groter een tabel wordt, hoe trager het wordt om data op te halen. Het maakt niet uit hoeveel indexen we hebben gelegd, of welke SSD schijven we onderliggend op de fysieke storage hebben zitten. Meer data gaat altijd gelijk staan aan tragere data retrieval.\nOm tegen te gaan dat we tabellen krijgen die té groot worden en we daar niet meer zinvol data van kunnen ophalen bestaan hier een paar oplossingen voor. Het partitioneren van tabellen is er eentje van.2\nNeem als voorbeeld een bank, die elke overschrijving van een rekening moet bewaren. De overschrijving tabel zou kunnen gepartitioneerd worden op jaar. Zodat er nog steeds 1 tabel overschrijving is, maar waarbij we die op de fysieke schijf opsplitsen per jaar, en elke op bijvoorbeeld de recentste 3 jaren index management voor bijhouden. De andere jaren kunnen nog steeds opgevraagd worden maar niet met dezelfde performantie als de meest recente data.\nExternal Layer De External Layer is wat we van onze database laten zien aan de buitenwereld. Dit zijn views van data. Een view is een virtuele representatie van data. We schrijven een query op onze tabellen en bewaren deze query als een view. Op deze manier kunnen we garanderen aan integrerende applicaties dat onze data er steeds hetzelfde gaat uitzien en tevens beschermen van informatie die voor het integrerende systeem niet relevant is.\nIn onze bibliotheek kunnen we een aantal views osptellen op basis van de noden van de verschillende applicaties. In het online platform waar je boeken kan uitlenen is het niet nodig de informatie over een auteur als een aparte entiteit weer te geven. We kunnen de tabel van Authors dus verbergen en enkel een view aanbieden op niveau van Books die er als volgt zou uitzien:\nclassDiagram class LendingAppBooks{ isbn: NVARCHAR title: NVARCHAR author: NVARCHAR price: DECIMAL genre: NVARCHAR }  Voor de inventaris applicatie moeten we wel in staat zijn om nieuwe boeken en auteurs toe te voegen. Daar kunnen de views er dan als volgt uitzien:\nclassDiagram InventoryBooks \"1..*\" -- \"1\" InventoryAuthors class InventoryAuthors{ id: INT name: NVARCHAR firstName: NVARCHAR } class InventoryBooks{ isbn: NVARCHAR title: NVARCHAR author: INT price: DECIMAL }  2. Catalog Dit is het hart van de de database. Dit bevat alle metadata die zich in de database bevindt. Onder andere, de tabellen; views; stored procedures; \u0026hellip;\nDe SQL standaard om deze informatie in te bewaren is in INFORMATION_SCHEMA. Niet alle SQL Database providers voldoen hier echter aan. SQLite doet dit niet en daar vind je die informatie in de tabel sqlite_master.\n3. Database Languages SQL is onderverdeeld in twee verschillende talen. Enerzijds heb je DDL (Data Definition Language). Dit gebruik je om de database structuur te wijzigen. Nieuwe tabellen toevoegen, indexen aanmaken, views verwijderen, \u0026hellip;\nAnderzijds heb je DML (Data Manipulation Language). Dit gebruik je voor alle CRUD (Create, Read, Update, Delete) acties op data. Hier gaan we in een volgend hoofdstuk verder op in gaan.\n  Eigenlijk niet het Identity veld, maar het veld dat in de Clustered Index zit van de tabel. Als er dan in de query meer informatie nodig is om op te halen kan die via die manier de rest van de data ophalen. \u0026#x21a9;\u0026#xfe0e;\n Archivatie is een andere oplossing. \u0026#x21a9;\u0026#xfe0e;\n   "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/sql-ddl-dml/dml/",
	"title": "2. DML",
	"tags": [],
	"description": "",
	"content": "Data Modification Language is de taal die we gebruiken om de data van onze database te bekijken of aan te passen. Met DML kunnen we CRUD operaties uitvoeren. Create, Read, Update en Delete.\nSELECT SELECT is het commando dat we gebruiken om data op te vragen uit de database.\n SELECT { DISTINCT } expression FROM table { WHERE condition } LIKE operator LIKE wordt gebruikt om wildcard searches uit te voeren. Deze kan enkel gebruikt worden op alfanumerieke velden.\n% is een match anything character voor een onbeperkt aantal karakters (0 tot n). Zo matcht Gen% met volgende waardes: Gen, Genk, Gent, Genève, Genua, \u0026hellip;\n_ is een match anything character voor één karakter. Zo matcht Gen_ met volgende waardes: Genk, Gent, \u0026hellip; Maar niet met volgende waardes: Gen, Genève, Genua, \u0026hellip;\nNULL NULL is het ontbreken van een waarde. Het is een onbekende. We kunnen in DML niet zomaar vergelijken met NULL. We kunnen namelijk niet zeggen dat een onbekende gelijk is aan een andere onbekende.\nHieronder een overzicht van een binary AND table met True, False en NULL waardes.\n   AND True False NULL     True True False NULL   False False False False   NULL NULL False NULL    Denkvraag: Waarom is False == NULL gelijk een False?\nHieronder vinden we de binary OR table met True, False en NULL waardes.\n   OR True False NULL     True True True True   False True False NULL   NULL True NULL NULL    Als we willen vergelijken met NULL in queries, dan gebruiken we volgende code:\n\u0026lt;value\u0026gt; IS NULL\nen\n\u0026lt;value\u0026gt; IS NOT NULL\nOefeningen  Schrijf een query die alle Customers (volledige naam, customer ID en land) laat zien die niet wonen in de USA. Schrijf een query die enkel de Customers laat zien die in Brazilië wonen. Schrijf een query die alle Employees laat zien die werken in de Sales afdeling. Schrijf een query die een unieke lijst van landen laat zien uit de Invoices tabel. Schrijf een query die alle Tracks laat zien waarvoor er geen componist bekend is. Schrijf een query van alle unieke Componisten. Als de componist niet bekend is, dan moet er \u0026lsquo;Onbekend\u0026rsquo; weergegeven worden gesorteerd op naam. Schrijf een query die het maximumbedrag van alle Invoices laat zien.  JOIN Wanneer we informatie willen ophalen uit meerdere tabellen dan gebruiken we daar een JOIN statement voor. Die syntax ziet er als volgt uit:\n SELECT { DISTINCT } expression FROM table INNER JOIN other_table ON join_condition { WHERE condition } Hiermee matchen we alle data van de ene tabel met de andere tabel op de meegegeven conditie. Er bestaan drie verschillende types JOINs:\n INNER JOIN - Geeft alle resultaten die bestaan zowel in de ene als de andere tabel LEFT JOIN - Geeft alle resultaten die bestaan in de base tabel, ook al bestaan die niet in de tabel waarop we joinen RIGHT JOIN - Wordt in de praktijk zelden tot nooit gebruikt. Geeft alle resultaten die bestaan in de gejoinde tabel ook al bestaan ze niet in de base tabel.  Oefeningen  Schrijf een query die alle Invoices laat zien van alle Customers uit Brazilië. Het resultaat moet de volledige naam van de Customer, Invoice ID, Invoice Datum en Billing Country weergeven. Schrijf een query die alle Invoices laat zien voor elke Sales Agent. Het resultaat moet de volledige naam van de Sales Agent weergeven. Schrijf een query die het Invoice Totaal, de Customer naam en land en de naam van de Sales Agent weergeeft voor alle Invoices en Customers. Schrijf een query die het aantal invoice lijnen weergeeft voor Invoice ID 37. Schrijf een query die de track naam weergeeft langs elke invoice lijn. Schrijf een query die de track naam en de artiest naam weergeeft langs elke invoice lijn. Schrijf een query die alle tracks laat zien, maar geen ID\u0026rsquo;s. Het resultaat moet de album titel, het media type en het genre bevatten. Schrijf een query die alle genres weergeeft waarvoor er geen tracks bestaan.  GROUP BY Soms willen we data aggregeren. Daarvoor bestaan een aantal verschillende functies. De meest courante zijn hieronder te vinden:\n MAX() MIN() COUNT() AVG() SUM()  Elke waarde die je extra selecteert in een query bovenop een aggregate function, moet in een GROUP BY clause komen. Hoe ziet dit er dan bijvoorbeeld uit?\nSELECT BillingCity, SUM(Total) FROM Invoices GROUP BY BillingCity HAVING Als we willen filteren op een grouping function, dan gaat dat niet via een WHERE clause, dan krijg je namelijk een foutmelding:\nSELECT BillingCity, count(*) FROM invoices WHERE count(*) \u0026gt; 2 GROUP BY BillingCity    Om te filteren op een grouping function schrijven we dit in een HAVING clause.\nSELECT BillingCity, count(*) FROM invoices GROUP BY BillingCity HAVING count(*) \u0026gt; 2 Oefeningen  Schrijf een query die het aantal Invoices laat zien voor 2009 en 2011. Schrijf een query die het aantal invoices per land laat zien. Schrijf een query die per Invoice ID het aantal invoice lijnen laat zien. Schrijf een query die de naam van elke playlist laat zien, alsook het aantal tracks in elke playlist. Schrijf een query die alle data uit de Invoices tabel laat zien, aangevuld met het aantal invoice lijnen. Schrijf een query die de totale verkoopcijfers per Sales Agent laat zien. Schrijf een query die laat zien welke Sales Agent de grootste verkoopcijfers heeft voor 2009. Schrijf een query die laat zien welke Sales Agent de grootste verkoopcijfers heeft voor 2010. Schrijf een query die laat zien welke Sales Agent de grootste verkoopcijfers heeft over alle jaren heen. Schrijf een query die het aantal Customers laat zien per Sales Agent. Schrijf een query die de totale verkoopcijfers per land laat zien. In welk land werd er het meest uitgegeven? Schrijf een query die laat zien welke track er in 2013 het meest werd verkocht. Schrijf een query die laat zien wat de top 5 tracks zijn die ooit werden verkocht. Schrijf een query die laat zien wie de top 3 artiesten zijn die het meest verkocht werden. Schrijf een query die laat zien welk media type het meest verkocht werd. Schrijf een query die de tracks laat zien die meer dan 4 keer verkocht zijn.  Subqueries Een query die we uitvoeren geeft een set van resultaten terug. Die set kunnen we opnieuw gebruiken als input voor een nieuwe query. We kunnen die set op verschillende plaatsen gebruiken als input voor een nieuwe query. Hieronder een aantal voorbeelden.\nIn een WHERE clause SELECT * FROM invoice_items WHERE invoice_items.TrackId IN ( SELECT tracks.TrackId FROM tracks WHERE name LIKE \u0026#39;%hell%\u0026#39; ) In een FROM clause SELECT * FROM ( SELECT tracks.TrackId, tracks.Name FROM tracks WHERE name LIKE \u0026#39;%hell%\u0026#39; ) In een JOIN clause SELECT * FROM tracks INNER JOIN ( SELECT tracks.TrackId, tracks.Name FROM tracks WHERE name LIKE \u0026#39;%hell%\u0026#39; ) hell_tracks ON hell_tracks.TrackId = tracks.TrackId  Subqueries in een WHERE IN statement worden geëvauleerd voor elke voor elke rij uit de outer query, dus zijn eigenlijk niet zo heel performant. We kunnen dat iets verbeteren door dat te herschrijven naar een WHERE EXISTS statement. Zie hieronder.\n SELECT * FROM invoice_items WHERE EXISTS ( SELECT 1 FROM tracks WHERE name LIKE \u0026#39;%hell%\u0026#39; AND tracks.TrackId = invoice_items.TrackId ) De IN clause gaat een subquery volledig ophalen om alle rijen te hebben om dan in die lijst van rijen te kunnen zoeken. Een EXISTS clause gaat een subquery maar zo lang uitvoeren tot er een resultaat gevonden is. Als de tabel uit de subquery 1000 rijen bevat en er wordt een match gevonden op rij 200, dan gaan de andere 800 niet meer geëvauleerd worden.\nOefeningen De meeste van deze queries kunnen ook geschreven worden met een JOIN statement. Dit is echter niet waar we hier op willen oefenen. Los dus volgende oefeningen op met minstens één subquery.\n Schrijf een query die alle invoices laat zien die een track bevatten van Iron Maiden. Schrijf een query die alle invoices laat zien die verkocht werden door Margaret Park. Schrijf een query die alle genres laat zien waarvoor er geen track bestaat. Schrijf een query die alle invoices laat zien waarvan de prijs groter is dan het gemiddelde van alle invoices. Schrijf een query die alle invoices laat zien waarin een Metallica track verkocht is, waarvan de prijs groter is dan het gemiddelde van alle invoices waarin een Metallica track verkocht is.  Data manipulatie INSERT Met een INSERT Statement gaan we data toevoegen in de database. We gebruiken een column listing om aan te geven welke kolommen, in welke volgorde, we van een waarde kan voorzien. Kolommen die NULL values ondersteunen mogen uit de column listing gelaten worden.\nINSERT INTO Genres(Name) VALUES(\u0026#39;Rock\u0026#39;) Oefeningen  Voeg je favoriete album (inclusief artiest en tracks) toe aan de database.  UPDATE Met een UPDATE statement kunnen we één of meerdere waardes in een set van data aanpassen.\nUPDATE Tracks SET MediaTypeId = 1 WHERE AlbumId = 2 Oefeningen  Wijzig de UnitPrice en de Composer voor de 3e track van je toegevoegde album Wijzig de titel van je album  DELETE Hiermee kunnen we een set van data verwijderen.\nLET OP! Een DELETE statement zonder WHERE clause verwijderd alles uit de tabel!\nDELETE FROM Genre WHERE Name = \u0026#39;Rock\u0026#39; Oefeningen  Verwijder het album (inclusief artiest en tracks) dat je hierboven hebt toegevoegd.  "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/apis/jdbc-jdbi/",
	"title": "2. JDBC en JDBI",
	"tags": [],
	"description": "",
	"content": "1.1 Java Database Connectivity (JDBC) 1.1.1 Hoe verbind ik Java met de DB? JDBC is een interface in de JDK die ons in staat stelt om een connectie te openen naar een database. JDBC is een API: een abstracitelaag of een protocol. Dit betekent dat we met JDBC kunnen verbinden naar eender welke server van eender welke flavor: een Oracle SQL, MSSQL, of SQLite database. De database vendor wordt verborgen achter de JDBC laag. Voor deze oefeningen beperken we ons tot SQLite.\nVoor elke database moet er dus een vendor-specifieke driver als dependency worden toegevoegd. In het geval van SQLite is dit de sqlite-jdbc driver, de sqlite-jdbc package. JDBC zelf leeft in java.sql en is een integraal onderdeel van de JDK: dit moeten we dus niet apart oplijsten als dependency of downloaden.\ngraph LR; Java[Java] JDBC[JDBC] SQLITE[SQLite-JDBC] DB[(SQLite Database)] subgraph Java space subgraph JDK Java -.- JDBC end JDBC -- SQLITE end subgraph DB space SQLITE -- DB end  De sqlite-jdbc package zorgt voor de brug tussen onze Java applicatie en de database, maar we spreken die aan via JDBC.\nEnkele belangrijke statements:\n Een connectie naar een database vastleggen: var connection = DriverManager.getConnection(\u0026quot;jdbc:sqlite:mydb.db\u0026quot;); Een SELECT query uitvoeren: var s = connection.createStatement(); var result = s.executeQuery(\u0026quot;...\u0026quot;); var cell = result.getString(\u0026quot;column\u0026quot;); Een INSERT/UPDATE/\u0026hellip; query uitvoeren (die de structuur of inhoud van de database wijzigt): var s = connection.createStatement(); s.executeUpdate(\u0026quot;...\u0026quot;);  Het volgende voorbeeld opent een verbinding naar een DB, maakt een tabel aan, voegt een record toe, en telt het aantal records:\nprivate lateinit connection: Connection fun createDb() { connection = DriverManager.getConnection(\u0026#34;jdbc:sqlite:mydb.db\u0026#34;) // note that this requires \u0026#34;stdlib-jdk7\u0026#34; as kotlin runtime dependency  connection.createStatement().use { it.executeUpdate(\u0026#34;CREATE TABLE mijntabel(nr INT); INSERT INTO mijntabel(nr) VALUES(1);\u0026#34;) } } fun verifyDbContents() { connection.createStatement().use { val result = it.executeQuery(\u0026#34;SELECT COUNT(*) FROM mijntabel;\u0026#34;) assert result.getInt(0) == 1 } } private Connection connection; public void createDb() throws SQLException { connection = DriverManager.getConnection(\u0026#34;jdbc:sqlite:mydb.db\u0026#34;); var s = connection.createStatement(); s.executeUpdate(\u0026#34;CREATE TABLE mijntabel(nr INT); INSERT INTO mijntabel(nr) VALUES(1);\u0026#34;) s.close(); } public void verifyDbContents() throws SQLException { var s = connection.createStatement(); var result = s.executeQuery(\u0026#34;SELECT COUNT(*) FROM mijntabel;\u0026#34;); var count = result.getInt(0); s.close(); assert count == 1; }  Gradle dependency: laatste versie van sqlite-jdbc in mvnrepository.com.\nMerk op dat SQLException een checked exception is die je constant moet meespelen in de method signature of expliciet moet opvangen. Het probleem van een try { } catch { } finally { } block is dat in de finally je ook geen close() kan uitvoeren zonder opnieuw een try block te openen\u0026hellip; Inception!\nVergelijk de Kotlin implementatie met de standaard Java versie. Als het aan komt op efficiënt gebruik van oudere Java APIs zoals de SQL methodes, is Kotlin véél eenvoudiger, zowel in gebruik als in leesbaarheid. Hier maken we handig gebruik van de use extension om geen close() te moeten oproepen, en with {} om de connectionManager in te stellen zonder telkens connection. te moeten herhalen. Nog een voordeel: er is geen verschil tussen checked en unchecked exceptions. Het loont dus om ook voor dit vak te opteren voor Kotlin\u0026mdash;maar het is niet verplicht.\n Het connection.close() statement moet er voor zorgen dat voor elke request de connection netjes wordt afgesloten. Een database heeft meestal een connection pool van x aantel beschikbare connections, bijvoorbeeld 5. Als een connection per request niet wordt gesloten, heeft de voglende bezoeker van onze website geen enkele kans om zijn zoekquery te lanceren, omdat de database dan zegt dat alle connecties zijn opgebruikt!\nMerk op dat de String jdbc:sqlite:mydb.db een lokale SQLite database file aanmaakt op het huidig relatief pad, zodat je met SQLite Explorer data kan inspecteren. Deze file wordt herbruikt: indien je een tabel aanmaakt de eerste keer, gaat dit de tweede keer crashen met table already exists. Houd hier dus rekening mee (e.v.t. met IF NOT EXISTS). Je kan ook een in-memory database aanmaken, die volledig in RAM leeft en bij elke opstart opnieuw wordt aangemaakt, met de String jdbc:sqlite:memory.\nWerk je met een andere database maar heb je geen idee hoe die speciale connection string te vormen? Geen probleem, daarvoor dient https://www.connectionstrings.com/. Bijvoorbeeld, een connectie naar de Microsoft Azure cloud kan met de volgende syntax:\nServer=tcp:myserver.database.windows.net,1433;Database=myDataBase;User ID=mylogin@myserver;Password=myPassword;Trusted_Connection=False;Encrypt=True; Het is de connection string die bepaalt welke dependency binding gebruikt wordt! Dit noemen we late binding: er is geen expliciete referentie naar iets van SQLite in de Java code; we werken enkel met JDBC zelf. Als je de vendor driver vergeet toe te voegen als Gradle dependency gebeurt er dit:\nException in thread \u0026quot;main\u0026quot; java.sql.SQLException: No suitable driver found for jdbc:sqlite:mydb.db at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:702) at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:251) at Demo.main(Demo.java:8)  In-memory databases (ConStr. jdbc:sqlite:memory), die met een lege database vertrekken, en constant CREATE TABLE() statements issuen, vervuilen je broncode. Als je veel SQL moet uitvoeren is het beter om dit in een .sql bestand te bewaren in src/main/resources en eenmalig in te lezen als SQL met new String(Files.readAllBytes(Paths.g));, om te kunnen uitvoeren via statement.executeUpdate(). Zie het jdbc-repo-start project op GitHub als voorbeeld.\n 1.1.2 Queries/Objecten in JDBC Stel dat we dezelfde studenten willen inladen in een Student klasse instantie: van de TABLE STUDENT naar de class Student. In geval van JDBC is dat veel handwerk:\n Maak een verbinding met de database. Voer de SELECT statements uit. Loop door de ResultSet en maak een nieuwe Student instantie aan. Vang alle mogelijke fouten zelf op: wat met lege kolommen, null? Wat met INTEGER kolommen die je wilt mappen op een String property?  Om van de huidige resultatenrij naar de volgende te springen in ResultSet gebruikt men de methode next() in een typisch while() formaat:\nval result = statement.executeQuery(\u0026#34;SELECT * FROM iets\u0026#34;) while(result.next()) { val eenString = result.getString(\u0026#34;kolomnaam\u0026#34;) // doe iets! } var result = statement.executeQuery(\u0026#34;SELECT * FROM iets\u0026#34;); while(result.next()) { var eenString = result.getString(\u0026#34;kolomnaam\u0026#34;); // doe iets! }  Zie ook ResultSet Oracle Javadoc.\nAangezien we reeds hebben kennis gemaakt met de (beperkte) API, schakelen we onmiddellijk over naar de oefeningen:\n1.1.3 Oefeningen  Maak (én test!) een klasse StudentRepository die de volgende methode implementeert. Zoals je ziet is het de bedoeling dat de JDBC Connection instance elders wordt aangemaakt, bijvoorbeeld in een aparte ConnectionManager klasse.  class StudentRepository(val connection: Connection) { fun getStudentsByName(name: String): List\u0026lt;Student\u0026gt; } public class StudentRepository { public StudentRepository(Connection connection); public List\u0026lt;Student\u0026gt; getStudentsByName(String name); }  Breid dit uit met saveNewStudent(Student). Breid dit uit met updateStudent(Student). Wat moet je doen als deze student nog niet in de database zit? Welke gegevens update je wel en welke niet?  Tip:\n executeUpdate() van een Statement is erg omslachtig als je een string moet stamenstellen die een INSERT query voorstelt (haakjes, enkele quotes, \u0026hellip;). Wat meer is, als de input van een UI komt, kan dit gehacked worden, door zelf de quote te sluiten in de string. Dit noemt men SQL Injection, en om dat te vermijden gebruik je in JDBC de prepareStatement() methode. Zie JDBC Basics: Prepared Statements. De String die je meegeeft bevat in de plaats van parameters een vraagteken: INSERT INTO STUDENT(bla, bla) VALUES(?, ?). Die parameters vul je daarna aan met preparedStatement.setString() of setInt(). Op die manier is de code zowel netjes als injectie-vrij!  1.2 Queries/Objecten in Jdbi 3 Jdbi (Java DataBase Interface v3) is een lightweight library geschreven bovenop JDBC. Het gebruikt dus de interne Java API om te communiceren tussen de database en de Java applicatie. Echter, het maakt het leven voor ons als ontwikkelaar op heel wat vlakken véél aangenamer: waar JDBC eerder database-driven en dialect-afhankelijk is, is Jdbi eerder user-driven en met behulp van plugins dialect-onafhenkelijk.\nJDBI3 is opgedeeld in modules, waarvan wij de volgende drie gaan gebruiken:\n jdbi3-core (altijd nodig) - voor JDBC zit dit in de JDK. jdbi3-sqlite (voor de SQLite verbinding) - of andere DB driver jdb3-sqlobject - voor de eenvoudige mapping naar Plain Old Java Objects (POJOs)  Met JDBI3 wordt op de volgende manier Java met de DB verbonden:\ngraph LR; Java[Java] Jdbi[Jdbi3-core] JDBC[JDBC] JSQLITE[Jdbi3-SQLite] SQLite[SQLite-JDBC] DB[(SQLite Database)] subgraph Java space Java -- Jdbi Jdbi -- JDBC Jdbi -- JSQLITE JSQLITE -.- SQLite JDBC -.- SQLite end subgraph DB space SQLite -- DB end  Er komt dus één blokje bij tussen Java en JDBC: we gebruiken niet langer de ingebouwde JDK interfaces maar rechtstreeks de jdbi-core dependency die via JDBC de SQLite connectie maakt. De jdbi3-sqlite package is afhankelijk van sqlite-jdbc: zie artifact dependency info. Met andere worden, het wordt een transitieve dependency: deze verdwijnt uit onze build.gradle, maar wordt nog steeds meegetrokken met de rest.\nEr is ook support voor spring, jpa, guava, kotlin, \u0026hellip;\nOm bovenstaande JDBC oefening te implementeren in Jdbi3 hebben we eerst een extractie van een interface nodig voor de repository acties:\ninterface StudentRepository { fun getStudentsByName(student String): List\u0026lt;Student\u0026gt; fun saveNewStudent(student: Student) fun updateStudent(student: Student) } public interface StudentRepository { List\u0026lt;Student\u0026gt; getStudentsByName(String student); void saveNewStudent(Student student); void updateStudent(Student student); }  Nu kan StudentRepositoryJdbcImpl (hernoem bovenstaande) en onze nieuwe StudentRepositoryJdbi3Impl de interface implements-en. Denk aan de Strategy design pattern van SES: afhankelijk van een instelling kunnen we switchen van SQL leverancier, zolang de code overal de interface gebruikt.\ngraph LR; Main[Controlller] Interface{StudentRepository} Jdbc[StudentRepositoryJdbcImpl] Jdbi[StudentRepositoryJdbi3Impl] Main -- Interface Interface -- Jdbc Interface -- Jdbi  1.2.1 JDBC vs Jdbi3 Geen idee waar te beginnen? Hier: http://jdbi.org/\n1. Connection openen In plaats van JDBC\u0026rsquo;s DriverManager.getConnection() om de Connection instance te bootstrappen, gebruiken wij gewoon Jdbi.create() met ook één parameter, namelijk dezelfde ConnectionString.\n2. Query uitvoeren In plaats van de vervelende checked SQLExceptions en de createStatement() code, heb je nu de keuze om ofwel de Fluent API te gebruiken:\nreturn jdbi.withHandle(handle -\u0026gt; { return handle.createQuery(\u0026#34;SELECT * FROM student WHERE naam = :naam\u0026#34;) .bind(\u0026#34;naam\u0026#34;, student) .mapToBean(Student.class) .list(); }); ofwel de Declarative API, waarbij je met de @SqlQuery kan werken op een interface:\npublic interface StudentDao { @SqlQuery(\u0026#34;SELECT * FROM student\u0026#34;) @RegisterBeanMapper(Student.class) List\u0026lt;Student\u0026gt; getStudenten(); } Dit vereist dat je de plugin SqlObjectPlugin installeert na de Jdbi.create(): jdbi.installPlugin(new SqlObjectPlugin());. Zie jdbi.org documentatie.\nJdbi ondersteunt Kotlin met twee modules: jdbi3-kotlin en jdbi3-kotlin-sqlobject om data classes direct te binden aan een bepaalde tabel. Bovenstaande Java code (met .bind() werken) is analoog. Om verwarring te voorkomen zijn de Jdbi voorbeelden uitgewerkt in Java. Lees meer op http://jdbi.org/#_kotlin\n Herinner je je nog de SESsy Library? Die werkte ook op die manier! Kijk nog eens in https://github.com/kuleuven-diepenbeek/sessylibrary in de map src.main.java.be.kuleuven.sessylibrary.domain in klasse BooksRepository!\nMerk op dat Jdbi3 er voor kan zorgen dat de resultaten van je query automatisch worden vertaald naar een Student instantie door middel van bean mapping: de mapToBean() methode of de @RegisterBeanMapper annotatie. Die gaat via reflectie alle kolomnamen 1-op-1 mappen op properties van je object dat je wenst te mappen. Er zijn ook nog andere mogelijkheden, zoals mappen op een HashMap, ea:\n   3. Transacties, insert/update queries, \u0026hellip; Zelfstudie. Zie jdbi.org documentatie.\n1.2.2 Oefeningen Quickstart project: examples/jdbc-repo-start in in de cursus repository (download repo zip). Deze bevat reeds bovenstaande JDBC implementatie en een aantal unit testen, waarvan er nog twee falen.\n Fix eerst de falende unit testen! Herimplementeer alle methodes van de StudentRepository interface hierboven, maar dan in Jdbi3 met de Fluent API (jdbi.withHandle()). Maak een tweede klasse genaamd StudentRepositoryJdbi3. Schrijf ook een bijhorende unit test klasse (kijk voor inspiratie naar de JDBC implementatie). Om te testen of het werkt in \u0026ldquo;productie\u0026rdquo; kan je je testcode van JDBC herbruiken door de code de interface te laten gebruiken in plaats van de implementatie. Bijvoorbeeld:  fun main(args: Array\u0026lt;String\u0026gt;) { val jdbcRepo = StudentRepositoryJdbc(...) val jdbiRepo = StudentRepositoryJdbi3(...) doStuff(jdbcRepo) } fun doStuff(repository: StudentRepository) { // argunent = interface!  // uw repository.getStudentsByName, saveNewStudent, ... tests hier } public class OefeningMain { public static void main(String[] args) { var jdbcRepo = new StudentRepositoryJdbc(...); var jdbiRepo = new StudentRepositoryJdbi3(...); doStuff(jdbcRepo); } public static void doStuff(StudentRepository repository) { // argunent = interface!  // uw repository.getStudentsByName, saveNewStudent, ... tests hier  } }  Extra Oefening: Maak een nieuwe implementatie van de repository interface die via de Jdbi3 Declaratie API de queries doorgeeft naar de SQLite DB. D.w.z., lees in de Jdbi3 developer guide na hoe je de Declarative API gebruikt en verwerk dit. Tip: jdbi.withExtension(StudentDao.class, ...).  Tip:\n Neem de tijd om de JDBI documentatie uitvoerig te bekijken!  1.3 Jdbi Backend + JavaFX Frontend Met Java database access enigszins onder de knie kijken we verder dan alleen maar de \u0026ldquo;repository\u0026rdquo;. Op welke manier kunnen we onze STUDENT tabel visueel weergeven, en er studenten aan toevoegen of uit verwijderen?\nDat kan op verschillende manieren, van HTML (SESsy Library) en JavaScript API calls naar iets eenvoudiger vanuit het eerstejaarsvak INF1: JavaFX. Je kan in JavaFX eenvoudig TableView stukken positioneren op een AnchorPane en die vullen met de juiste kolommen en rijen. De data blijft uiteraard uit de SQLite DB komen via JDBC/Jdbi. De StudentRepository is dus slechts één deel van het verhaal: waar wordt deze gebruikt? In JavaFX controllers.\n1.3.1 Een Gradle JavaFX Project Er zijn een aantal aanpassingen nodig aan je build.gradle file om van een gewone Java applicatie over te schakelen naar een JavaFX-enabled applicatie. We hebben de application en javafxplugin plugins nodig onder plugins {}, verder ook een javafx {} property groep die bepaalt welke modules van JavaFX worden ingeladen:\nplugins { id 'application' id 'org.openjfx.javafxplugin' version '0.0.10' } repositories { mavenCentral() } javafx { version = \u0026quot;15\u0026quot; modules = [ 'javafx.controls', 'javafx.fxml' ] } dependencies { implementation group: 'org.xerial', name: 'sqlite-jdbc', version: '3.36.0.3' implementation group: 'org.jdbi', name: 'jdbi3-core', version: '3.24.1' implementation group: 'org.jdbi', name: 'jdbi3-sqlite', version: '3.24.1' implementation group: 'org.jdbi', name: 'jdbi3-sqlobject', version: '3.24.1' testImplementation group: 'junit', name: 'junit', version: '4.12' } group 'be.kuleuven.javasql' version '1.0-SNAPSHOT' sourceCompatibility = 1.13 mainClassName = 'be.kuleuven.javasql.SqlFxMain' Herinner je het volgende over JavaFX:\n De main klasse leidt af van Application en laadt de hoofd-.fxml file in. Controllers hebben een public void initialize() methode waar action binding in wordt gedefinieerd. .fxml files beheer je met SceneBuilder. Vergeet hier niet de link naar de fully qualified name van je controller klasse te plaatsen als AnchorPane attribuut: fx:controller=\u0026quot;be.kuleuven.javasql.controller.StudentController\u0026quot;.  Problemen met je JDK versie en Gradle versies? Raadpleeg de Gradle Compatibiility Matrix. Gradle 6.7 of hoger ondersteunt JDK15. Gradle 7.3 of hoger ondersteunt JDK17. Let op met syntax wijzigingen bij Gradle 7+! Je Gradle versie verhogen kan door de URL in gradle/gradlew.properties te wijzigen. De laatste versie van JavaFX is 17\u0026mdash;backwards compatible met JDK15 en hoger.\n Voor onze studententabel visualisatie hebben we een TableView nodig. Daarnaast eventueel Buttons om te editeren/toe te voegen/\u0026hellip; Vergeet de fx:id van de tabel niet:\n   Kolommen (en de inhoud van de rijen) definiëren we in de controller zelf:\n@FXML private lateinit var tblStudent: TableView\u0026lt;Student\u0026gt; fun initialize() { tblStudent.getColumns().clear() val col: TableColumn\u0026lt;Student, String\u0026gt; = TableColumn\u0026lt;\u0026gt;(\u0026#34;Naam\u0026#34;).apply { setCellValueFactory(f -\u0026gt; ReadOnlyObjectWrapper\u0026lt;\u0026gt;(f.getValue().getMaam())) } with(tblStudent) { getColumns().add(col) getItems().add(Student(\u0026#34;Joske\u0026#34;, \u0026#34;Josmans\u0026#34;, 124, true)) } } @FXML private TableView\u0026lt;Student\u0026gt; tblStudent; public void initialize() { tblStudent.getColumns().clear(); TableColumn\u0026lt;Student, String\u0026gt; col = new TableColumn\u0026lt;\u0026gt;(\u0026#34;Naam\u0026#34;); col.setCellValueFactory(f -\u0026gt; new ReadOnlyObjectWrapper\u0026lt;\u0026gt;(f.getValue().getMaam())); tblStudent.getColumns().add(col); tblStudent.getItems().add(new Student(\u0026#34;Joske\u0026#34;, \u0026#34;Josmans\u0026#34;, 124, true)); }  Merk op dat TableView een generisch type heeft, en we zo dus heel eenvoudig onze eigen POJO rechtstreeks kunnen mappen op de Student klasse! Als we dit opstarten krijgen we alvast één kolom te zien met de naam (f in de CellValueFactory is een wrapper waarvan de waarde de huidige student in de rij is. getNaam() zorgt ervoor dat de juiste waarde in de juiste cel komt te staan)\n   1.3.2 Oefeningen Quickstart project: examples/jdbc-fxml-start in de cursus repository (download repo zip). Deze bevat reeds bovenstaande JDBC implementatie en een leeg gekoppeld JavaFx project. Om uit te voeren, klik op \u0026ldquo;Gradle\u0026rdquo; en voer target \u0026ldquo;run\u0026rdquo; uit (dus niet op \u0026ldquo;Play\u0026rdquo; in de main klasse!).\n Werk bovenstaande voorbeeld verder uit voor alle kolommen. Voeg eerst testdata toe (getItems().add(new student...). Probeer nu de controller te linken met de repository. De tabel items moeten overeenkomen met de repository items. Proficiat, je kijkt naar \u0026ldquo;live data\u0026rdquo;! Voeg een knop Voeg Toe toe op het scherm, dat een ander FXML venster opent, waar je gegevens van de nieuwe student kan ingeven, en kan bewaren. De \u0026ldquo;bewaren\u0026rdquo; knop persisteert naar de database, sluit het venster, én refresht het studentenadmin overzichtsscherm.  Tip: Vanuit een JavaFX controller een ander scherm openen is een kwestie van een nieuwe Stage en Scene object aan te maken:\nprivate fun showScherm() { val resourceName = \u0026#34;bla.fxml\u0026#34; val root = FXMLLoader.load(this::class.java..getResource(resourceName)) as AnchorPane; val stage = Stage().apply { setScene(Scene(root)) setTitle(\u0026#34;dinges\u0026#34;) initModality(Modality.WINDOW_MODAL) show() } } private void showScherm() { var resourceName = \u0026#34;bla.fxml\u0026#34;; try { var stage = new Stage(); var root = (AnchorPane) FXMLLoader.load(getClass().getClassLoader().getResource(resourceName)); stage.setScene(new Scene(root)); stage.setTitle(\u0026#34;dinges\u0026#34;); stage.initModality(Modality.WINDOW_MODAL); stage.show(); } catch (Exception e) { throw new RuntimeException(e); } }  Zit je vast? Raadpleeg de TableView JavaDocs: https://openjfx.io/javadoc/13/javafx.controls/javafx/scene/control/TableView.html\nBekijk een voorbeeld Kotlin/JavaFX project in de github appdev-course repository.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/nosql/keyvaluestores/",
	"title": "2. Key-value stores",
	"tags": [],
	"description": "",
	"content": "1.1 Persistente Hashmaps De eenvoudigst mogelijke noSQL database die gebruik maakt van key/values is een simpele HashMap\u0026lt;K,V\u0026gt; die je zelf serialiseert naar een flat file op de HDD. Een netwerk share kan dit bestand delen, maar locking systemen zullen moeten ingebouwd worden om te voorkomen dat dit bestand corrupt wordt.\nDe \u0026ldquo;oude\u0026rdquo; manier om dit te doen op de JVM is gebruik te maken van FileOutputStream:\nfun main(args: Array\u0026lt;String\u0026gt;) { val db = mapOf(\u0026#34;Joske\u0026#34; to Student(\u0026#34;Joske\u0026#34;, 11)) val file = File(\u0026#34;database.db\u0026#34;) // handy function to auto-close streams: https://kotlinlang.org/api/latest/jvm/stdlib/kotlin.io/use.html  ObjectOutputStream(FileOutputStream(file)).use { it.writeObject(db) } } public static void main(String[] args) throws IOException { var db = new HashMap\u0026lt;String, Object\u0026gt;(); db.put(\u0026#34;joske\u0026#34;, new Student(\u0026#34;Joske\u0026#34;, 11)); var file = new File(\u0026#34;database.db\u0026#34;); var f = new FileOutputStream(file); var s = new ObjectOutputStream(f); s.writeObject(db); s.close(); }  Inlezen werkt op dezelfde manier, met FileInputStream en ObjectInputStream. Hoe je Student klasse wordt geserialiseerd kan je zelf kiezen, maar een vereiste is dat je de interface Serializable implementeert!\nMet bovenstaande interface kan je de student terug uitlezen:\nvar fromFile: Map\u0026lt;String, Student\u0026gt; ObjectInputStream(FileInputStream(\u0026#34;database.db\u0026#34;)).use { fromFile = it.readObject() as Map\u0026lt;String, Student\u0026gt; } val joske = fromFile.getValue(\u0026#34;joske\u0026#34;) println(joske.name) var s = new ObjectInputStream(new FileInputStream(\u0026#34;database.db\u0026#34;)) Map\u0026lt;String, Object\u0026gt; map = (Map\u0026lt;String, Object\u0026gt;) s.readObject(); s.close(); Student joske = (Student) map.get(\u0026#34;joske\u0026#34;); System.out.println(joske.getName());  1.1.1 Oefeningen  Werk bovenstaand voorbeeld uit en persisteer een aantal studenten met de volgende klasse:  data class Student(val name: String, val age: Int) public class Student { private final String name; private final int age; public Student(String name, int age) { this.name = name; this.age = age; } }  1.2 Distributed Hashmaps: Memcached We kunnen eenvoudig een verbinding maken met een (of meerdere) Memcached server via de Memcached Java client van net.spy.spymemcached (zie mvn repo: https://mvnrepository.com/artifact/net.spy/spymemcached). Dit hoeft maar één regel code te zijn: (zie memcached javadocs)\nvar client = new MemcachedClient(new InetSocketAddress(\u0026#34;127.0.0.1\u0026#34;, 11211)); // bewaar een student onder key \u0026#34;joskey\u0026#34; voor één uur (3600s) client.set(\u0026#34;joskey\u0026#34;, 3600, new Student(\u0026#34;Jos\u0026#34;, 20)); // retrieve object var restoredStudent = (Student) client.get(\u0026#34;Jos\u0026#34;); De client code vereist een werkende memcached server zoals https://www.memcached.org, in bovenstaand voorbeeld draaiend op poort 11211. Je kan dit zelf compileren onder UNIX of Msys in Windows. We gaan voor de oefeningen hier niet verder op in.\nDenkvragen  Welke beperkingen zijn er verbonden aan het geserialiseerd database bestand doorgeven aan andere medestudenten? Op welke manier kan je zo verschillende \u0026lsquo;clients\u0026rsquo; verbinden aan één database \u0026lsquo;server\u0026rsquo;?  "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/sql-ddl-dml/",
	"title": "2. SQL DDL &amp; DML",
	"tags": [],
	"description": "",
	"content": "SQL DDL \u0026amp; DML Zie menu links.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/xml/xsd/",
	"title": "2. XSD",
	"tags": [],
	"description": "",
	"content": "XML Schema Definition Wanneer we met XML communiceren tussen twee verschillende partijen, hebben we natuurlijk ook spelregels nodig. Daarvoor kunnen we een XML schema of XSD gebruiken. Daarin leggen we vast:\n welke tags wel of niet mogen voorkomen, in welke volgorde die moeten staan, hoe vaak een element mag voorkomen, of een element optioneel of verplicht is, het datatype van het element, welke attributen op een tag toegelaten zijn  Ons vorige XML representatie van een collectie boeken kan met volgende XSD beschreven worden:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;xs:schema xmlns:xs=\u0026#34;http://www.w3.org/2001/XMLSchema\u0026#34;\u0026gt; \u0026lt;xs:element name=\u0026#34;boeken\u0026#34; type=\u0026#34;boekenType\u0026#34;/\u0026gt; \u0026lt;xs:complexType name=\u0026#34;boekenType\u0026#34;\u0026gt; \u0026lt;xs:sequence\u0026gt; \u0026lt;xs:element name=\u0026#34;boek\u0026#34; type=\u0026#34;boekType\u0026#34; maxOccurs=\u0026#34;unbounded\u0026#34;/\u0026gt; \u0026lt;/xs:sequence\u0026gt; \u0026lt;/xs:complexType\u0026gt; \u0026lt;xs:complexType name=\u0026#34;boekType\u0026#34;\u0026gt; \u0026lt;xs:sequence\u0026gt; \u0026lt;xs:element name=\u0026#34;titel\u0026#34; type=\u0026#34;xs:string\u0026#34;/\u0026gt; \u0026lt;xs:element name=\u0026#34;auteur\u0026#34; type=\u0026#34;xs:string\u0026#34;/\u0026gt; \u0026lt;xs:element name=\u0026#34;jaar\u0026#34; type=\u0026#34;xs:integer\u0026#34;/\u0026gt; \u0026lt;/xs:sequence\u0026gt; \u0026lt;/xs:complexType\u0026gt; \u0026lt;/xs:schema\u0026gt; Het boeken element, ons root element wordt als eerste beschreven en krijgt een custom type toegekend, namelijk een zelf gedefinieerd type boekenType. Daaronder beschrijven we precies wat een boekenType is. In dit geval is het een complexType. Het bestaat namelijk uit meerdere andere elementen. We geven hier mee dat enkel het element boek mag voorkomen in ons boekType. Wat valt nog op? Dat is de toevoeging van maxOccurs=\u0026quot;unbounded\u0026quot;. Hiermee geven we aan dat dit element ongelimiteerd gebruikt mag worden. De tegenhanger van maxOccurs is minOccurs, door die de waarde 1 mee te geven bijvoorbeeld, maken we een element verplicht. De combinatie kan ook gebruikt worden. Stel dat we een ISBN nummer zouden toevoegen, dan zouden we dat als volgt kunnen doen:\n\u0026lt;xs:element name=\u0026#34;isbn\u0026#34; type=\u0026#34;xs:string\u0026#34; minOccurs=\u0026#34;1\u0026#34; maxOccurs=\u0026#34;1\u0026#34;/\u0026gt; Hierbij geven we dus aan dat het ISBN nummer een verplicht veld is, en ik maar maximaal 1 keer kan voorkomen.\nHet boekType ten slotte heeft ook zijn eigen definitie. Dit type bevat een sequence, dat betekent dat de elementen die gedefinieerd zijn onder het boekType moeten voorkomen in de volgorde dat ze zijn gedefinieerd. De elementen zelf zijn hier primitieve elementen. Daarom krijgen ze reeds bestaande types, zoals string en integer.\nJe kan je XML bestanden laten valideren tegen een XSD schema, door daar zelf logica voor te schrijven. In typische Enterprise applicaties, waarbij XML gebruikt wordt als communicatiemiddel ga je dat steeds willen doen om te verifiëren dat alle data doorgegeven werd op de op voorhand beschreven manier. Of je kan een online validatie tool gebruiken. Hiervoor kan je gedurende deze les deze XSD Validator gebruiken\nOefeningen  Maak een XSD schema voor de studenten XML die jullie in de vorige opgave hebben gemaakt. Voeg een nieuw element Gender toe aan XML en XSD.  We kunnen ons XSD schema uitbreiden door er ook attributen aan toe te voegen. Laten we een Genre attribuut definiëren op ons boek element.\n\u0026lt;xs:complexType name=\u0026#34;boekType\u0026#34;\u0026gt; \u0026lt;xs:sequence\u0026gt; \u0026lt;xs:element name=\u0026#34;titel\u0026#34; type=\u0026#34;xs:string\u0026#34;/\u0026gt; \u0026lt;xs:element name=\u0026#34;auteur\u0026#34; type=\u0026#34;xs:string\u0026#34;/\u0026gt; \u0026lt;xs:element name=\u0026#34;jaar\u0026#34; type=\u0026#34;xs:integer\u0026#34;/\u0026gt; \u0026lt;/xs:sequence\u0026gt; \u0026lt;xs:attribute name=\u0026#34;genre\u0026#34; type=\u0026#34;xs:string\u0026#34; /\u0026gt; \u0026lt;/xs:complexType\u0026gt; In XML vorm zou dat er dan als volgt uitzien:\n\u0026lt;boek genre=\u0026#34;fantasy\u0026#34;\u0026gt; \u0026lt;titel\u0026gt;The Lost Metal\u0026lt;/titel\u0026gt; \u0026lt;auteur\u0026gt;Brandon Sanderson\u0026lt;/auteur\u0026gt; \u0026lt;jaar\u0026gt;2022\u0026lt;/jaar\u0026gt; \u0026lt;/boek\u0026gt; Validaties We kunnen aan XSD ook nog validatieregels toevoegen die de data-integriteit verzekeren. Hieronder volgen een aantal voorbeelden:\nMinimum en maximumwaarde voor getal \u0026lt;xs:element name = \u0026#34;score\u0026#34;\u0026gt; \u0026lt;xs:simpleType\u0026gt; \u0026lt;xs:restriction base = \u0026#34;xs:integer\u0026#34;\u0026gt; \u0026lt;xs:minInclusive value = \u0026#34;0\u0026#34;/\u0026gt; \u0026lt;xs:maxInclusive value = \u0026#34;100\u0026#34;/\u0026gt; \u0026lt;/xs:restriction\u0026gt; \u0026lt;/xs:simpleType\u0026gt; \u0026lt;/xs:element\u0026gt; Enumeratie van waardes \u0026lt;xs:element name = \u0026#34;Score\u0026#34;\u0026gt; \u0026lt;xs:simpleType\u0026gt; \u0026lt;xs:restriction base = \u0026#34;xs:string\u0026#34;\u0026gt; \u0026lt;xs:enumeration value = \u0026#34;Laag\u0026#34;/\u0026gt; \u0026lt;xs:enumeration value = \u0026#34;Gemiddeld\u0026#34;/\u0026gt; \u0026lt;xs:enumeration value = \u0026#34;Hoog\u0026#34;/\u0026gt; \u0026lt;/xs:restriction\u0026gt; \u0026lt;/xs:simpleType\u0026gt; \u0026lt;/xs:element\u0026gt; Regex \u0026lt;xs:element name = \u0026#34;Naam\u0026#34;\u0026gt; \u0026lt;xs:simpleType\u0026gt; \u0026lt;xs:restriction base = \u0026#34;xs:string\u0026#34;\u0026gt; \u0026lt;xs:pattern value = \u0026#34;[a-z]\u0026#34;/\u0026gt; \u0026lt;/xs:restriction\u0026gt; \u0026lt;/xs:simpleType\u0026gt; \u0026lt;/xs:element\u0026gt; Oefeningen  Voeg een attribuut toe aan de studenten XML dat aangeeft of de student een Bachelor of Master volgt. Voeg voor elke student nu ook een lijst van vakken toe. Per vak willen we zien voor hoeveel studiepunten dit meetelt en een score? Voeg dit ook toe in je XML en valideer dit tegen je XSD.  "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/sql/rdbms-acid/",
	"title": "3. ACID",
	"tags": [],
	"description": "",
	"content": "ACID is een acronym die we gebruiken binnen databases dat een lijst van voorwaarden omschrijft waar dat database systeem aan moet voldoen. De regels van ACID worden over het algemeen geïmplementeerd door het concept van Transacties. ACID omschrijft vier principes:\n Atomicity Consistency Isolation Durability  De ACID principes komen in de praktijk nog verder aan bod in het hoofdstuk over RDBMS transacties, dus geen paniek als onderstaande theorie nog niet onmiddellijk duidelijk is.\nAtomicity Transacties bestaan vaak uit meerdere statements. Atomicity verwacht dat al deze statements als één geheel worden beschouwd. Ofwel faalt alles, ofwel slaagt alles. Zo wordt er nooit slechts een deel van de changes bewaard.\nHet gevolg hiervan is dat de staat van een transactie niet gezien kan worden door andere gebruikers. Stel we hebben een typische bankoverschrijving die €10 gaat overschrijven van de rekening van Alice naar de rekening van Bob.\nsequenceDiagram Note over Application,DB: BEGIN TRANSACTION DB--DB: Rekening van Alice: €100 DB--DB: Rekening van Bob: €150 Application-DB: UPDATE Account SET Amount -= 10 WHERE Owner = 'Alice' DB--DB: Rekening van Alice: €100 DB--DB: Rekening van Bob: €150 Application-DB: UPDATE Account SET Amount += 10 WHERE Owner = 'Bob' Note over Application,DB: COMMIT TRANSACTION DB--DB: Rekening van Alice: €90 DB--DB: Rekening van Bob: €160  Consistency Consistency zorgt ervoor dat een database altijd in een consistente staat moet blijven. Met andere woorden, er moet altijd voldaan worden aan de constraints die op de database gedfinieerd zijn. Dit kan een referentiële constraint zijn, als er een rij wordt verwijderd die nog gebruikt wordt in een andere tabel waar onderliggend een referentiële constraint op ligt.\nNeem bovenstaand voorbeeld waarbij Alice geld overschrijft naar de rekening van Bob. Maar nu wil ze €150 overschrijven. We hebben op de Account tabel een CHECK CONSTRAINT gedefinieerd dat de Amount altijd groter of gelijk aan 0 moet zijn. Wat gebeurt er dan?\nsequenceDiagram Note over Application,DB: BEGIN TRANSACTION DB--DB: Rekening van Alice: €100 DB--DB: Rekening van Bob: €150 Application-DB: UPDATE Account SET Amount -= 150 WHERE Owner = 'Alice' rect rgb(194, 24, 7) DB--DB: Error: Amount should be = 0 end Note over Application,DB: ROLLBACK TRANSACTION DB--DB: Rekening van Alice: €100 DB--DB: Rekening van Bob: €150  De transactie wordt teruggedraaid. Er werd geen geld afgehaald van de rekening van Alice en Bob heeft ook geen geld gekregen. We zitten opnieuw in een geldige consistente staat.\nIsolation Als je een query of transactie uitvoert op een database, ga je zelden als enige gebruiker actief zijn. Er zullen wellicht andere transacties uitgevoerd worden terwijl jij de jouwe uitvoert. Om ervoor te zorgen dat deze geen invloed hebben op elkaar worden er locks gelegd op een set van data. Daar bovenop worden isolation levels gedefinieerd die bepalen wat andere gebruikers mogen zien en lezen van andere transacties.\nDit komt meer detail aan bod in een volgend hoofdstuk.\nDurability Als we een transactie afronden en hij wordt gecommit dan is die nog steeds committed ook in het geval van een crash of stroomonderbreking. Veel DBMS providers lossen dit op door data weg te schrijven in non-volatile memory en door gebruik te maken van een transaction log.\nDat laatste is een logboek van alle acties die uitgevoerd werden op een database, die opnieuw uitgevoerd kunnen worden als een database gerestored moet worden vanaf een eerdere staat.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/nosql/documentstores/",
	"title": "3. Document stores",
	"tags": [],
	"description": "",
	"content": "0. Data filtering: recap Wat is een \u0026ldquo;mapreduce\u0026rdquo; functie nu weer precies? Weet je nog, in het eerstejaarsvak BES, in Python? Stel, we hebben een array [1, 2, 3, 4] en willen alle elementen verdubbelen. Dat kan erg eenvoudig met een list(map(lambda...)) statement:\nrange = [1, 2, 3, 4] result = list(map(lambda x: x * 2, range)) print(result) Hier gebruikten we een \u0026ldquo;lambda\u0026rdquo; om voor elk element een functie los te laten, die dat element transformeert, ofwel \u0026ldquo;mapt\u0026rdquo;. Python\u0026rsquo;s map() functioneert exact hetzelfde als JavaScript\u0026rsquo;s map()\u0026mdash;evenals reduce() en filter(). Omdat we met een JS-based document store gaan werken is het belangrijk om te weten hoe je bovenstaande principes in JavaScript uitvoert.\nOefening 1 Zoek leerlingen ouder dan 20 en geef hun naam terug. De leerlingen zitten in de volgende JS array: const studenten = [{age: 11, name: 'jos'}, {age: 21, name: 'jef'}].\nOplossing:\nstudenten.filter(function(student) { return student.age \u0026gt; 20 }).map(function(student) { return student.name }) // kan ook met oneliner: studenten.filter(s =\u0026gt; s.age \u0026gt; 20).map(s =\u0026gt; s.name) filtered = filter(lambda student: student.age \u0026gt; 20, studenten) list(map(lambda student: student.name, filtered))  Kopieer bovenstaand voorbeeld in je browser developer console en kijk wat er gebeurt. Het resultaat zou een openklapbare Array [ \u0026quot;jef\u0026quot; ] moeten zijn.\nWe chainen (sequentieel combineren) hier dus filter() en daarna map(). De filter() geeft student Jef terug in een array ([{age: 21, name: 'jef'}]), waarna de map() voor elk element in die array (maar eentje), een transformatie doorvoert: van {age: 21, name: 'jef'} naar 'jef' via student.name.\nOefening 2 Wat is de som van de leeftijden van de studenten? 11 + 21 = 32. Hoe kunnen we dit functioneel schrijven met behulp van een reduce()?\nOplossing:\nstudenten.map(function(student) { return student.age }).reduce(function(age1, age2) { return age1 + age2 }) // kan ook met oneliner: studenten.jap(s =\u0026gt; s.age).reduce(a, b =\u0026gt; a + b) mapped = map(lambda student: student.age, studenten) reduce(lambda age1, age2: age1 + age2, mapped)  Kan jij bedenken waarom we hier een map() nodig hebben voor de reduce()?\nMeer informatie: zie Mozilla Developer web docs: map() en reduce/filter. Wanneer je jezelf familiair gemaakt hebt met deze drie functionele (en essentiele!) data manipulatie methodes kan je overgaan tot de hoofdzaak van dit hoofdstuk\u0026mdash;CouchDB en noSQL queries.\n1. Eenvoudige CouchDB Queries    Lui in die zetel liggen, en vanaf de bank met gemak query\u0026rsquo;s lanceren? Geen probleem met CouchDB, een open source NoSQL JSON-based document store.\nMango CouchDB heeft een eenvoudige ingebouwde query syntax genaamd Mango. Documentatie op https://github.com/cloudant/mango en http://127.0.0.1:5984/_utils/docs/intro/api.html#documents. Selecteer een database, klik op \u0026ldquo;run a query with Mango\u0026rdquo;:\n{ \u0026#34;selector\u0026#34;: { \u0026#34;year\u0026#34;: 3 } } De selector attribute bepaalt op welke keys er wordt gefilterd. Indexen leggen op zwaar belaste \u0026ldquo;kolommen\u0026rdquo; (keys dus) is in geval van miljarden records zeker geen overbodige luxe.\nMango werkt met een selector syntax (zie documentatie) die impliciet bovenstaande omzet naar {\u0026quot;year\u0026quot;: {\u0026quot;$eq\u0026quot;: 3}}. Er zijn ook andere dollar-based operatoren. Geneste attributes kan je raadplegen met de . separator: {\u0026quot;student.name\u0026quot;: {\u0026quot;eq\u0026quot;: \u0026quot;Joske\u0026quot;}}.\nEen ander voorbeeld: Zoek leerlingen ouder dan 20 en geef hun naam terug:\nfunction(doc) { if(doc.age \u0026gt; 20) { emit(doc._id, doc.name); } } De functie emit(key, value) beslist in welke hoedanigheid een document wordt teruggeven. In dit geval geven we de doc.name terug: de naam van de leerling. We filteren met een simpele if() in de code zelf! Dit kunnen we ook functioneel schrijven in pure JavaScript, los van CouchDB en zijn Mango API, met filter()\u0026mdash;zie de data filtering introductie hierboven.\nNog een ander voorbeeld: van 10 rijen de som teruggeven. In SQL doe je dit met een GROUP BY en COUNT, maar daar bestaat geen alternatief voor in NoSQL, behalve de kracht van JS reduce():\nfunction(keys, values, rereduce) { return values.reduce(function(a, b) { return a + b }) } Opnieuw, hetzelfde kan ook met \u0026ldquo;plain old JavaScript\u0026rdquo;, zoals in de data filtering recap aangegeven ([1, 2, 3, 4].reduce(a, b =\u0026gt; a + b)).\nJe kan in Mango de map() en de reduce() uiteraard ook combineren, net zoals je in JS kan chainen. Hieronder berekenen we bijvoorbeeld de gemiddelde leeftijd van \u0026ldquo;oudere\u0026rdquo; studenten (ouder dan 20 jaar):\nfunction map(doc) { if(doc.age \u0026gt; 20) { emit(doc._id, doc.age); } } function reduce(keys, values, rereduce) { return sum(values) / values.length; }  Wat is het verschil tussen function(a, b) {} en (a, b =\u0026gt; ? (Bijna) geen (die jullie moeten kennen). De arrow notatie (=\u0026gt;) is de nieuwe syntax voor anonieme functies aan te maken in JavaScript, en in CouchDB/Mango werken we nog met de oude notatie omdat (1) dit door Couch wordt gegenereerd en (2) de meeste voorbeelden in de documentatie nog zo werken. Dus, function hallokes() { console.log('sup') } is exact hetzelfde als let hallokes = () =\u0026gt; { console.log('sup') }. Zie MDN docs: Arrow function expressions voor meer informatie.\n LET OP:\nreduce() schiet (misschien) in actie als map() nog bezig is. We gaan hier later nog verder op in in NoSQL - Advanced queries.\nDe CouchDB API interface: alles via HTTP(S) curl is een snelle cmd-line tool waarbij je via -X kan meegeven of het over een HTTPs GET, POST, PUT, \u0026hellip; gaat. De DB locatie en poort met het juiste endpoint zijn hier de belangrijkste factoren. Een bepaald document raadplegen doe je met:\ncurl -X GET http://127.0.0.1:5984/[database]/[id] Het resultaat is altijd een geldig JSON object (ook al geef je een ongeldige ID mee): curl -X GET \u0026quot;http://127.0.0.1:5984/courses/aalto-university;bachelor-data-science;professional-development;1\u0026quot;\n{\u0026quot;_id\u0026quot;:\u0026quot;aalto-university;bachelor-data-science;professional-development;1\u0026quot;,\u0026quot;_rev\u0026quot;:\u0026quot;1-f7872c4254bfc2e0e5507502e2fafd6f\u0026quot;,\u0026quot;title\u0026quot;:\u0026quot;Professional Development\u0026quot;,\u0026quot;url\u0026quot;:\u0026quot;https://oodi.aalto.fi/a/opintjakstied.jsp?OpinKohd=1125443391\u0026amp;haettuOpas=-1\u0026quot;,\u0026quot;university\u0026quot;:\u0026quot;Aalto University\u0026quot;,\u0026quot;country\u0026quot;:\u0026quot;Finland\u0026quot;,\u0026quot;category\u0026quot;:\u0026quot;professional\u0026quot;,\u0026quot;ECTS\u0026quot;:5,\u0026quot;year\u0026quot;:1,\u0026quot;optional\u0026quot;:true,\u0026quot;skills\u0026quot;:[\u0026quot;motivate self\u0026quot;,\u0026quot;oral communication\u0026quot;,\u0026quot;self-directed learning\u0026quot;,\u0026quot;self-reflection\u0026quot;,\u0026quot;give/receive feedback\u0026quot;,\u0026quot;set/keep timelines\u0026quot;,\u0026quot;show initiative\u0026quot;],\u0026quot;course\u0026quot;:\u0026quot;Bachelor Data Science\u0026quot;,\u0026quot;lo\u0026quot;:\u0026quot;\u0026lt;br/\u0026gt;Learning Outcomes \u0026lt;br/\u0026gt;Being able to effectively communicate one's strenghts and professional capacities\u0026lt;br/\u0026gt;Finding one’s own academic and professional interests and taking initiative in one’s own learning\u0026lt;br/\u0026gt;Planning and prototyping one's own professional development\u0026lt;br/\u0026gt; \u0026lt;br/\u0026gt;Content \u0026lt;br/\u0026gt;The course is integrated to the Aaltonaut program to promote reflection, skill articulation and initiative. The course comprises workshops on different themes related to developing professional skills, independently building a learning portfolio, and taking part in feedback, reflection and goal setting activities.\u0026lt;br/\u0026gt;\u0026lt;br/\u0026gt; \u0026quot;} Indien ongeldig: {\u0026quot;error\u0026quot;:\u0026quot;not_found\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;missing\u0026quot;}.\nIndien geen toegang: {\u0026quot;error\u0026quot;:\u0026quot;unauthorized\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;You are not authorized to access this db.\u0026quot;}. Zie \u0026ldquo;LET OP\u0026rdquo; hieronder\u0026mdash;gebruik het -u argument.\n2. Oefeningen: Voorbereidingswerk  Download CouchDB via https://couchdb.apache.org. Download de testdatabase JSON file Maak een nieuwe databases aan via de Fauxton Web-based admin tool. Open CouchDB, ga naar \u0026ldquo;Open Admin Console\u0026rdquo; of surf zelf naar http://127.0.0.1:5984/_utils/. Maak een database aan genaamd \u0026lsquo;courses\u0026rsquo;. Importeer de test JSON met curl in cmdnline:  curl -d @dump.db -H \u0026quot;Content-Type: application/json\u0026quot; -X POST http://127.0.0.1:5984/courses/_bulk_docs LET OP:\n Bij het aanmaken van een database kan je kiezen tussen partitioned en non-partitioned. Kies hiervoor non-partitioned. Het kan zijn dar CURL een security fout geeft. Bij het installeren van CouchDB moet je een admin username/password meegeven. Voeg aan het einde van je curl commando dit toe: -u username:wachtwoord.  Nadien kan je in Fauxton op F5 drukken en zou je dit moeten zien:\n   Ik heb voor jullie de dump genomen door het omgekeerde (exporteren) te doen:\ncurl -X GET http://127.0.0.1:5984/courses/_all_docs\\?include_docs\\=true \u0026gt; dump.db (Voor mensen op Windows-curl: verander \\ naar /. Ook; bij meegeven van JSON data: enkele quotes '' vervangen door dubbele \u0026quot;\u0026quot; en dubbele in de enkele escapen met backlash \u0026quot;).\nDaarna volgt wat post-processing (rows wordt docs, elke doc moet in de root array zitten en _rev moet weg) om tot bovenstaande dump.db filte te komen. Dit hebben wij handmatig voor jullie gedaan, zodat de downloadbare file klaar is om te importeren.\n3. Oefeningen met Fauxton/Curl  Schrijf een Mango query die cursussen ophaalt waarbij het aantal ECTS punten groter is dan 5. Hoe voer je de query uit oefening 1 uit, zonder de Admin console, maar met curl? Selecteer alle documenten die als skill de waarde self-reflection én show initiative bevatten. Probeer zelf een dump te nemen van je eigen database zoals hierboven beschreven, met het _all_docs endpoint. Wat gebeurt er als je die dump opnieuw wilt importeren via het _bulk_docs endpoint? Maak een nieuwe database genaamd studenten. POST via curl enkele nieuwe documenten, met als template { name: $naam, age: $age, favouriteCourses: [$course1, $course2]} naar deze DB. Controleer in Fauxton of de records correct zijn ingegeven. Verzin zelf wat Mango queries om studenten te filteren. Maak een index aan op age voor je studenten database. Merk op dat indexes, zichtbaar in http://127.0.0.1:5984/_utils/#database/studenten/_index ook worden beschouwd als documenten op zich!  Tip: CouchDB heeft een eenvoudige ingebouwde query syntax genaamd Mango. Documentatie op https://github.com/cloudant/mango en https://docs.couchdb.org/en/stable/api/database/find.html. Lees eerst na hoe dit in elkaar zit!\nEen uitgewerkt voorbeeld van oefening 1 en 2 in begeleidende video:\n 4. Java Client API Als je geen toegang hebt tot de admin console, of je wenst vanuit een Java programma records weg te schrijven naar een Couch database (of query\u0026rsquo;s uit te voeren), dan heb je de Java API nodig.\nIn principe kan je met eender welke HTTP client REST calls uitvoeren en de responses zelf verwerken. Om het jezelf gemakkelijker te maken, gebruiken we hier ter illustratie LightCouch.\nLees de LightCouch Getting Started guide. Maak een nieuw gradle 6 project met de volgende dependencies:\ndependencies { implementation group: 'org.lightcouch', name: 'lightcouch', version: '0.2.0' } In je java/main/resources map dien je een couchdb.properties file aan te maken die verwijst naar de DB URL/poort/naam (zie getting started):\ncouchdb.name=testdb couchdb.createdb.if-not-exist=true couchdb.protocol=http couchdb.host=127.0.0.1 couchdb.port=5984 couchdb.username= couchdb.password= Vanaf dan is het heel eenvoudig: Maak een CouchDbClient instantie aan. Nu kan je .save(), .shutdown() en .find() uitvoeren. Wat kan je bewaren? POJO (Plain Old Java Objects) klassen\u0026mdash;of in geval van Kotlin, data objects\u0026mdash;waarbij alle members automatisch worden geserialiseerd.\nLightCouch oefeningen  Maak zoals hierboven beschreven een nieuw gradle project aan (IntelliJ?) en voeg LightCouch toe als dependency. Probeer naar een nieuwe database enkele objecten weg te schrijven. Gebruik hiervoor een Student klasse met als velden name en age (respectievelijk String en int als type). Controleer of dit is aangekomen in de admin console. Dat ziet er dan hopelijk zo uit:  { \u0026#34;_id\u0026#34;: \u0026#34;387a34be062140e4be1390e846242114\u0026#34;, \u0026#34;_rev\u0026#34;: \u0026#34;1-742f438439fd68bc6c67ca0d615f1469\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Joske\u0026#34;, \u0026#34;age\u0026#34;: 10 } Probeer de views en query\u0026rsquo;s even uit. Zoek bijvoorbeeld alle studenten in List\u0026lt;Student\u0026gt; en druk de namen af door middel van println().  Denkvragen  Wat is het verschil tussen een key/value store en een document store? Kan je een verklaring geven waarom NoSQL databases zonder DB SCHEME werken, als je weet dat bijvoorbeeld CouchDB plain JSON objecten kan bewaren? Wat is het verschil tussen het bewaren van een JSON object via Curl en het bewaren van een POJO via LightCouc (De Client API verschillen zelf niet in rekening gebracht)?  "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/transacties/failures-rollbacks/",
	"title": "3. Failures-Rollbacks",
	"tags": [],
	"description": "",
	"content": "Voorbereidende CREATE statements (Dit is SQLite syntax!) Zie SQLite manual:\nDROP TABLE IF EXISTS student; CREATE TABLE student( studnr INT NOT NULL PRIMARY KEY, naam VARCHAR(200) NOT NULL, voornaam VARCHAR(200), goedbezig BOOL ); DROP TABLE IF EXISTS log; CREATE TABLE log( id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, date DATETIME DEFAULT CURRENT_TIMESTAMP, foreign_id INT NOT NULL, msg TEXT ); INSERT INTO student(studnr, naam, voornaam, goedbezig) VALUES (123, \u0026#39;Trekhaak\u0026#39;, \u0026#39;Jaak\u0026#39;, 0); INSERT INTO student(studnr, naam, voornaam, goedbezig) VALUES (456, \u0026#39;Peeters\u0026#39;, \u0026#39;Jos\u0026#39;, 0); INSERT INTO student(studnr, naam, voornaam, goedbezig) VALUES (890, \u0026#39;Dongmans\u0026#39;, \u0026#39;Ding\u0026#39;, 1); 1. System failure simulatie 1.1 In SQLite met DB Browser Gegeven een aantal SQL statements, waarvan niet alle statements kloppen, maar die wel allemaal bij elkaar horen als één atomaire transactie. Dat betekent dat als er één van die statements misloopt, de rest teruggedraait zou moeten worden. Het spreekt voor zich dat zonder speciale handelingen, zoals het beheren van transacties, dit niet gebeurt. Een eenvoudig voorbeeld demonstreert dit.\nUPDATE student SET voornaam = \u0026#39;Jaqueline\u0026#39; WHERE studnr = 123; INSERT INTO oeitiskapot; INSERT INTO log(foreign_id, msg) VALUES (123, \u0026#39;Voornaam vergissing\u0026#39;); INSERT INTO student(studnr, naam, voornaam, goedbezig) VALUES (445, \u0026#39;Klakmans\u0026#39;, \u0026#39;Jef\u0026#39;, 1); INSERT INTO log(foreign_id, msg) VALUES (445, \u0026#39;Nieuwe student registratie\u0026#39;); Plak dit in de \u0026ldquo;Execute SQL\u0026rdquo; tab van de SQLite DB Browser. Het resultaat is een foutboodschap:\nnear \u0026quot;;\u0026quot;: syntax error: INSERT INTO oeitiskapot; Maar: het eerste UPDATE statement, voor de foute regel, is wel uitgevoerd:\n   Oefeningen  Probeer bovenstaande voorbeeld zelf uit in de SQLite DB Browser. Als je jezelf ervan verzekerd hebt dat inderdaad het eerste UPDATE statement wordt uitgevoerd, terwijl wij dat in één ACID blok willen, ga dan over naar de volgende oefening. In SQLite is het starten van een transactie erg eenvoudig: zie SQLite transaction tutorials van tutorialspoint.com. BEGIN; en COMMIT; zijn voldoende. Probeer dit uit in bovenstaande voorbeeld om er voor te zorgen dat de voornaam van Jaak niet wordt gewijzigd. Om met een \u0026ldquo;clean slate\u0026rdquo; te herbeginnen kan je gewoon de voorbereidende SQL code copy/pasten en opnieuw uitvoeren. Merk op dat dit nog steeds het ongewenst effect heeft dat de student zijn/haar naam wordt gewijzigd. We moeten expliciet zelf ROLLBACK; aanroepen. Probeer een nieuwe student toe te voegen: eentje met studentennummer, en eentje zonder. Dat tweede kan in principe niet door de NOT NULL constraint. Wrap beide statements in een transactie.  Let Op: Het zou kunnen dat SQLite de volgende fout geeft: cannot start a transaction within a transaction: BEGIN;. Queries die geplakt worden in het \u0026ldquo;execute SQL\u0026rdquo; scherm worden meestal (onzichtbaar, achter de schermen) gewrapped in transacties. Stop de huidige transactie door COMMIT; uit te voeren met de knop \u0026ldquo;execute single SQL line\u0026rdquo;.\n1.2 In SQLite met Java/JDBC SQLite/JDBC uitleg: zie APIs - JDBC.\nGebruik nu connection.setAutoCommit(false). Deze regel is nodig omdat in JDBC standaard elke SQL statement aanschouwd wordt als een onafhankelijke transactie, die automatisch wordt gecommit:\n When a connection is created, it is in auto-commit mode. This means that each individual SQL statement is treated as a transaction and is automatically committed right after it is executed. (To be more precise, the default is for a SQL statement to be committed when it is completed, not when it is executed. A statement is completed when all of its result sets and update counts have been retrieved. In almost all cases, however, a statement is completed, and therefore committed, right after it is executed.)\n Zie JDBC Basics in Oracle docs: https://docs.oracle.com/javase/tutorial/jdbc/basics/transactions.html\nBegeleidende video:\n Oefeningen  Maak een nieuw Gradle project aan en connecteer naar je SQLite database. Merk op dat, bij connectionstring \u0026quot;jdbc:sqlite:sample.db\u0026quot;, automatisch een lege .db file wordt aangemaakt indien de database niet bestaat. Probeer met behulp van executeUpdate() en executeQuery() bovenstaande system failure te veroorzaken. Je kan de \u0026ldquo;foute SQL\u0026rdquo; (met \u0026ldquo;oeitiskapot\u0026rdquo;) gewoon in een string in java copy/pasten. executeUpdate() kan verschillende statements tegelijkertijd verwerken. Verifieer dat de naam foutief toch wordt gewijzigd met een SELECT() nadat je de fout hebt opgevangen in een try { } block. Het probleem is op te lossen met één welgeplaatste regel: connection.rollback(). De vraag is echter: waar plaatsen we die? En ja, rollback() throwt ook de checked SQLException\u0026hellip; Verifieer of je oplossing werkt door de naam na de rollback terug op te halen en te vergelijken met de juiste waarde: \u0026ldquo;Jaak\u0026rdquo;.  De DROP TABLE IF EXISTS statements kan je in je project in een aparte SQL file bewaren en als een String inlezen, om in één keer te laten uitvoeren na het openen van de connectie:\nfun initTables() { val sql = SomeClass::class.java.getResource(\u0026#34;dbcreate.sql\u0026#34;).readText() println(sql) connection.createStatement().use { it.executeUpdate(sql) } } private void initTables() throws Exception { var sql = new String(Files.readAllBytes(Paths.get(getClass().getResource(\u0026#34;dbcreate.sql\u0026#34;).toURI()))); System.out.println(sql); var s = connection.createStatement(); s.executeUpdate(sql); s.close(); }  De verwachte fout (met de ongeldige SQL regel) die SQLite doorgeeft aan Java genereert de volgende stacktrace:\norg.sqlite.SQLiteException: [SQLITE_ERROR] SQL error or missing database (near \u0026quot;;\u0026quot;: syntax error) at org.sqlite.core.DB.newSQLException(DB.java:1010) at org.sqlite.core.DB.newSQLException(DB.java:1022) at org.sqlite.core.DB.throwex(DB.java:987) at org.sqlite.core.NativeDB._exec_utf8(Native Method) at org.sqlite.core.NativeDB._exec(NativeDB.java:94) at org.sqlite.jdbc3.JDBC3Statement.executeUpdate(JDBC3Statement.java:109) at SQLiteTransactionTest.doStuff(SQLiteTransactionTest.java:54) at SQLiteMain.main(SQLiteMain.java:7) Denkvragen  De SQLite website beschrijft in detail hoe ze omgaan met \u0026ldquo;atomic commits\u0026rdquo; om aan de ACID regels te voldoen. Lees dit na op https://sqlite.org/atomiccommit.html Op welke manier gebruiken zij een rollback journal? Hoe is dat gelinkt aan de logfile van 14.2.3 op p.435? JDBC is vrij rudimentair, en het is vrij omslachtig om simpele statements te committen vanwege boilerplate code. Hoe zou je dit probleem verminderen door middel van enkele refactorings? Anders gezegd: welke patronen herken je (zie SES 2de bach.) en hoe kan je gebruik maken van die patronen om herhalende boilerplate code te verminderen?  "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/apis/jpa/",
	"title": "3. JPA en Hibernate",
	"tags": [],
	"description": "",
	"content": "2.1 Wat is JPA? JPA of de Java Persistence API is een deel van Java EE (Java Enterprise Platform), een set van specificaties die initiëel de JDK SE 8 versie uitbreidden met \u0026ldquo;enterprise\u0026rdquo; features zoals distributed computing en web services. J2EE wordt vooral ingezet als het gaat over grote applicaties die bedrijven ontwikkelen voor andere bedrijven (zogenaamde \u0026ldquo;B2B\u0026rdquo;, Business 2 Business, of Enterprise Software Development).\nOndertussen is J2EE omgevormd tot Jakarta EE. In principe staat JPA nu voor Jakarta Persistence API\u0026hellip; What\u0026rsquo;s in a name.\n2.1.1 Maar wat is de JPA API nu precies? De API, levend in de package javax.persistence, is een manier om relationele data voor te stellen in enterprise Java applicaties, door middel van Objecten. Het is dus een mapping tool die object/relationale (meta)data bewerkt en verwerkt. JPA heeft ook zijn eigen query language, JPQL, die het eenvoudiger moet maken om queries te schrijven in Java code zelf in plaats van in SQL, die vertaald worden naar SQL. Dit vereenvoudigt refactoring en vermindert mogelijke fouten in de SQL string die te laat naar boven komen (nu compiletime ipv runtime, aangezien Java statisch getypeerd is).\nJPA is niet meer dan een specificatie die de interfaces en annotaties voorziet. De implementatie, en de klasses, worden overgelaten aan vendors, waarvan voor JPA 2.2 de volgende vendors beschikbaar zijn:\n DataNucleus EclipseLink Hibernate OpenJPA  JPA 2.2 Gradle dependency: compile group: 'javax.persistence', name: 'javax.persistence-api', version: '2.2'\n2.2 Wat is Hibernate ORM? Volgens de hibernate.org website:\n Your relational data. Objectively.\n Hibernate is dé populairste object-relational mapper in Java die de JPA standaard implementeert. Hibernate heeft zowel een eigen API als een JPA specificatie, en kan dus overal waar JPA nodig is ingeschakeld worden. Het wordt vaak in omgevingen gebruikt waar performantie belangrijk is, en waar enorm veel data en gebruikers data transferreren.\nBelangrijk startpunt: Hibernate getting started guide Ook Hibernate werkt met modules, zoals Jdbi3. We gebruiken hibernate-core; via Gradle: compile group: 'org.hibernate', name: 'hibernate-core', version: '5.4.23.Final'\nHet gebruik van Hibernate geeft meestal een aantal mogelijkheden:\n Gebruik de Native Hibernate API en hbm.xml mapping (Zie \u0026ldquo;2. Tutorial Using Native Hibernate APIs and hbm.xml Mapping\u0026rdquo;) Gebruik de Native Hibernate API en annotaties (Zie \u0026ldquo;3. Tutorial Using Native Hibernate APIs and Annotation Mappings\u0026rdquo;) Gebruik de JPA interface (Zie \u0026ldquo;4. Tutorial Using the Java Persistence API (JPA)\u0026quot;)  Waarvan wij #3 gaan hanteren.\n2.2.1 Hibernate/JPA Bootstrapping JPA bootstrappen kan - net zoals JDBC en Jdbi - vrij eenvoudig met een statische klasse Persistence die een sessionFactory object aanmaakt. Elke session factory stelt een verbinding voor tussen de Java code en de Database zelf. Om te kunnen werken met objecten moet je vanuit de session factory de entity manager creëren. Vanaf dan kan er worden gewerkt met de database via de entity manager instantie.\nvar sessionFactory = Persistence.createEntityManagerFactory(\u0026#34;be.kuleuven.mijnmooiepackage\u0026#34;); var entityManager = sessionFactory.createEntityManager(); // do stuff with it! // entityManager.createQuery(...) javax.persistence.Persistence gaat op zoek naar een persistence.xml bestand in de map src/main/resources/META-INF. Die bevat alle connectiegegevens en instellingen. De persistence XML file is de belangrijkste file van je hele applicatie, waar caching strategie, driver management, table autocreation, \u0026hellip; allemaal in wordt bepaald!\nEen voorbeeld XML file:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;persistence version=\u0026#34;2.1\u0026#34; xmlns=\u0026#34;http://xmlns.jcp.org/xml/ns/persistence\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://xmlns.jcp.org/xml/ns/persistence http://xmlns.jcp.org/xml/ns/persistence/persistence_2_1.xsd\u0026#34;\u0026gt; \u0026lt;persistence-unit name=\u0026#34;be.kuleuven.studenthibernate.domain\u0026#34;\u0026gt; \u0026lt;description\u0026gt;Studenten JPA Test\u0026lt;/description\u0026gt; \u0026lt;provider\u0026gt;org.hibernate.jpa.HibernatePersistenceProvider\u0026lt;/provider\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;property name=\u0026#34;javax.persistence.jdbc.driver\u0026#34; value=\u0026#34;org.sqlite.JDBC\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;javax.persistence.jdbc.url\u0026#34; value=\u0026#34;jdbc:sqlite:studenten.db\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;javax.persistence.jdbc.user\u0026#34; value=\u0026#34;\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;javax.persistence.jdbc.password\u0026#34; value=\u0026#34;\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;javax.persistence.schema-generation.database.action\u0026#34; value=\u0026#34;drop-and-create\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;hibernate.dialect\u0026#34; value=\u0026#34;org.hibernate.dialect.SQLiteDialect\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;hibernate.connection.autocommit\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;hibernate.show_sql\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;hibernate.flushMode\u0026#34; value=\u0026#34;ALWAYS\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;hibernate.cache.use_second_level_cache\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;hibernate.cache.provider_class\u0026#34; value=\u0026#34;org.hibernate.cache.NoCacheProvider\u0026#34; /\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/persistence-unit\u0026gt; \u0026lt;/persistence\u0026gt; Bevat onder andere de volgende belangrijke properties:\n javax.persistence JDBC driver/url. Merk op dat achterliggend dus nog steeds JDBC wordt gebruikt! Dat betekent ook dat we de sqlite dependency sqlite-jdbc van de groep org.xerial nog steeds nodig hebben. schema-generation properties: drop-and-create betekent dat tabellen die niet bestaan automatisch worden aangemaakt. Geen CREATE TABLE statements meer nodig, dus. hibernate.dialect: voor vendor-specifieke queries te genereren moet Hibernate weten welke database wij hanteren. Dit staat los van de jdbc driver! Hiervoor gebruiken we het dialect van dependency compile group: 'com.zsoltfabok', name: 'sqlite-dialect', version: '1.0'. Flush modes, auto-commit instellingen, caching, e.a. Dit gaat ver buiten de scope van deze cursus. show_sql print de gegenereerde queries af in de console, handig om te zien hoe Hibernate intern werkt, en om te debuggen.  Er ontbreekt hierboven nog een belangrijk gegeven: elke entity (domein object dat een tabel voorstelt in de code) moet met fully qualified name in een \u0026lt;class/\u0026gt; tag onder \u0026lt;persistence-unit/\u0026gt; worden toegevoegd. Anders herkent JPA het object niet, en heeft hij geen idee welke kolommen te mappen op welke properties. Die metadata zit namelijk in de entity klasse zelf.\nMeer informatie: zie hibernate.org documentatie en A beginners guide to JPA persistence xml.\n2.2.2 Hibernate/JPA Peristence/querying Nu de verbinding tussen de DB en Hibernate/JPA tot stand werd gebracht, is het tijd om gebruik te maken van de kracht van de library.\nOm kolommen te kunnen mappen op properties voorziet JPA een aantal annotaties als meta-data op het domeinobject zelf. Dat betekent dat DB beschrijving netjes bij het object waar het hoort wordt geplaatst. Bijvoorbeeld:\n@Entity data class Huis( @Column(name = \u0026#34;beschr\u0026#34;) var beschrijving: String, @Column var prijs: Int? = null, @Column @Id @GeneratedValue var id: Int = 0) @Entity public class Huis { @Column @Id @GeneratedValue private int id; @Column(name = \u0026#34;beschr\u0026#34;) private String beschrijving; @Column private int prijs; }  In Kotlin zijn types standaard not-nullable. Denk goed na over de mogelijke waardes van elk type: kan er ooit null in komen? Indien ja werk je met Kotlin\u0026rsquo;s optional alternatief: suffixen met een ?. Not-nullable types die later dan de constructor een waarde krijgen toegewezen worden aangeduid met lateinit. Zie Null safety Kotlin docs. Om Kotlins data class te laten samenwerken met oudere Java APIs zoals JPA/Hibernate, die niet kunnen omgaan met immutability, moeten we nog een extra plugin installeren: de no-arg plugin: id(\u0026quot;org.jetbrains.kotlin.plugin.jpa\u0026quot;) version \u0026quot;1.5.21\u0026quot; in de gradle plugins block. Die plugin genereert de nodige no-arg constructoren die JPA nodig heeft.\n Het datatype kan ook worden ingesteld met @Column (merk op dat de kolomnaam van de tabel in de DB kan en mag wijzigen van de property name in Java), bijvoorbeeld voor temporele waardes waar enkel de tijd of datum wordt bijgehouden op DB niveau. Merk op dat @Id nodig is op een @Entity - zonder primary key kan JPA geen object persisteren. @GeneratedValue is er omdat wij niet telkens de ID willen verhogen, maar dat willen overlaten aan de database vanwege de AUTOINCREMENT. Bij elke persist() gaat Hibernate de juiste volgende ID ophalen, dat zich vertaalt in de volgende queries in sysout:\nHibernate: select next_val as id_val from hibernate_sequence Hibernate: update hibernate_sequence set next_val= ? where next_val=? Hibernate: insert into Student (goedBezig, naam, voornaam, studnr) values (?, ?, ?, ?) De tabelnaam kan je wijzigen met de @Table annotatie op klasse niveau.\nInserts/updates Hoe bewaar ik een entity? entityManager.persist(object). That\u0026rsquo;s it!\nHoe update ik een entity, als properties zijn gewijzigd? .merge(object)\nMerk op dat in de Sysout output geen query wordt gegenereerd. Hibernate houdt alles in zijn interne cache bij, en zal pas flushen naar de database wanneer hij acht dat dat nodig is. Dat kan je zelf triggeren door entityManager.flush() te gebruiken (kan alleen in een transactie) - of het commando te wrappen met een transactie:\nwith(entityManager) { getTransaction().begin() persist(dingdong) getTransaction().commit() } entityManager.getTransaction().begin(); entityManager.persist(dingdong); entityManager.getTransaction().commit();  Zonder dit, en met herbruik van dezelfde entity manager in SQLite, is er een kans dat je SELECT query niets teruggeeft, omdat de INSERT nog niet werd geflushed. De interne werking van combinatie JDBC+SQLite+JPA+Hibernate is zeer complex en zou een cursus van 20 studiepunten vereisen\u0026hellip;\nQueries Hoe query ik in JPA? Dit kan op verschillende manieren. We beperken ons hier tot de JPA Criteria API. Een voorbeeld. Gegeven een huizenlijst, waarvan we huizen willen teruggeven die onder de 200.000 kosten. In SQL zou dit SELECT * FROM huizen WHERE prijs \u0026lt; 200000 zijn. In Criteria API:\nval criteriaBuilder = entityManager.getCriteriaBuilder() val query = criteriaBuilder.createQuery(Huis::class.java) val root = query.from(Huis::class.java) query.where(criteriaBuilder.equal(root.get\u0026lt;Int\u0026gt;(\u0026#34;prijs\u0026#34;), 200000)) return entityManager.createQuery(query).getResultList() var criteriaBuilder = entityManager.getCriteriaBuilder(); var query = criteriaBuilder.createQuery(Huis.class); var root = query.from(Huis.class); query.where(criteriaBuilder.equal(root.get(\u0026#34;prijs\u0026#34;), 200000)); return entityManager.createQuery(query).getResultList();  Voor simpele queries zoals deze is dat inderdaad omslachtig, maar de API is zeer krachtig en kan automatisch complexe queries genereren zonder dat wij ons moe moeten maken. Merk op dat wij geen enkele letter SQL zelf schrijven. Alles is java code, wat het eenvoudig maakt om te refactoren, redesignen, statische code analyse op te doen, unit testen, \u0026hellip; Lees meer over criteria API:\n Voorbeeld 2 Programmatic Criteria Queries Voorbeeld 3 TutorialsPoint Criteria API Voorbeeld 4 Using \u0026ldquo;In\u0026rdquo; in Criteria API  Controleer in de sysout output welke query Hibernate uiteindelijk genereert. Dat ziet er zo uit:\nselect student0_.studnr as studnr1_0_, student0_.goedBezig as goedbezi2_0_, student0_.naam as naam3_0_, student0_.voornaam as voornaam4_0_ from Student student0_ where student0_.naam=? 2.2.3 Oefeningen Quickstart project: examples/hibernate-jpa-start in de cursus repository (download repo zip)\n Het is opnieuw tijd voor onze studentendatabase. Open of kopiëer het project van 1. jdbc en jdbi (of start met het quickstart project). We voorzien een derde implementatie van de StudentRepository interface, naast de JDBC en Jdbi3 versies: StudentRepositoryJpaImpl. Probeer een nieuwe student te bewaren én daarna dezelfde student op te halen en af te drukken in sysout. Wat heb je daar weer voor nodig? (Scroll up!)  Een configuratiebestand in resources/META-INF. Entities, zoals onze Student klasse. Bootstrappen van de EntityManager. Een repository implementatie die de EntityManager gebruikt (tip: constructor injectie!)   Modelleer ook de log tabel uit 1. Failures/rollbacks. Bewaar een log record bij elke wijziging van student (aanmaken, wijzigen). Vergeet geen \u0026lt;class/\u0026gt; entry toe te voegen in je persistence.xml! Anders krijg je de volgende fout:  Exception in thread \u0026quot;main\u0026quot; java.lang.IllegalArgumentException: Not an entity: class be.kuleuven.studenthibernate.domain.Student at org.hibernate.metamodel.internal.MetamodelImpl.entity(MetamodelImpl.java:566) at org.hibernate.query.criteria.internal.QueryStructure.from(QueryStructure.java:127) at org.hibernate.query.criteria.internal.CriteriaQueryImpl.from(CriteriaQueryImpl.java:158) 2.2.4 JDBC VS Jdbi3 VS JPA  JDBC: Low-level relationele mapping tussen Java en DB. Wordt door alle high-level API\u0026rsquo;s gebruikt. Omslachtig (checked Exceptions, beperkte interface), erg kort bij SQL. Functionaliteit: minimaal. Jdbi3: High-level relationele mapping no-nonsense API bovenop JDBC die in feite alle negatieve kenmerken van JDBC wegwerkt. Nog steeds kort bij SQL, maar meer object-friendly door Fluent/Declarative API. Functionaliteit: nog steeds basic, maar wel met gebruiksgemak. JPA en vendors: High-level object-relational mapper bovenop JDBC waarbij entities centraal staan en compatibiliteit met Java EE is ingebouwd. Genereert SQL (zelf raw queries schrijven kan nog steeds, maar wordt afgeraden). Functionaliteit: enorm uitgebreid.  Kies altijd bewust voor één bepaald framework in plaats van \u0026ldquo;random\u0026rdquo; of \u0026ldquo;uit ervaring\u0026rdquo;: JPA/Hibernate is vaak overkill voor simpele applicaties, JDBC is vaak té low-level en bevat veel boilerplating, terwijl Jdbi3 daartussen ligt.\nZijn er nog alternatieven? Uiteraard, en meer dan één\u0026hellip; Maar dat reikt buiten de scope van deze cursus.\n2.3 Many-to-one relaties in Hibernate/JPA De grootste kracht van JPA hebben we nog steeds niet gezien: in plaats van één of meerdere entiteiten onafhankelijk te mappen, kunnen we ook relaties mappen en Hibernate alles op SQL-niveau laten afhandelen. Nooit meer JOIN statements schrijven, hoera!\u0026hellip; Niet altijd. Soms wil je de queries anders aanpakken dan Hibernate ze genereert omwille van performantie redenen. In dat geval zal je nog steeds moeten teruggrijpen naar native SQL - of veel tijd investeren in de correcte configuratie van de Hibernate/JPA/JDBC installatie.\nEen concreet voorbeeld. Een Docent entiteit geeft les aan verschillende studenten:\n@Entity data class Docent( @Id @GeneratedValue var docentennummer: Int, @Column var naam: String, @OneToMany(mappedBy = \u0026#34;docent\u0026#34;) var studenten: List\u0026lt;Student\u0026gt; ) @Entity public class Docent { @Id @GeneratedValue private int docentennummer; @Column private String naam; @OneToMany(mappedBy = \u0026#34;docent\u0026#34;) private List\u0026lt;Student\u0026gt; studenten; }  De @OneToMany annotatie zorgt voor de link tussen de studenten- en docententabel: het is wel nog nodig om een omgekeerde mapping property genaamd docent toe te voegen op de Student klasse:\n@Entity data class Student( // ...  @ManyToOne(fetch = FetchType.LAZY) @JoinColumn(name = \u0026#34;docent_nr\u0026#34;) var docent: Docent? ) @Entity public class Student { // ...  @ManyToOne(fetch = FetchType.LAZY) @JoinColumn(name = \u0026#34;docent_nr\u0026#34;) private Docent docent; }  Op die manier kan je van docenten onmiddellijk zien aan wie ze lesgeven (one to many), en van een student van wie hij of zij les krijgt (many to one). De data wordt in de studententabel bewaard, in kolom docent_nr. Andere configuraties zoals tussentabellen zijn uiteraard ook mogelijk.\nPersisteren we nu een nieuwe docent waar een reeds bewaarde student in de lijst werd toegevoegd:\nprivate fun docentenTest(entityManager: EntityManager, student: Student) { val wouter: Docent(\u0026#34;Wouter\u0026#34;).apply { geefLesAan(student) } with(entityManager) { begin() persist(wouter) commit() } } private static void docentenTest(EntityManager entityManager, Student student) { var wouter = new Docent(\u0026#34;Wouter\u0026#34;); wouter.geefLesAan(student); entityManager.getTransaction().begin(); entityManager.persist(wouter); entityManager.getTransaction().commit(); }  Geeft in Hibernate:\nHibernate: select next_val as id_val from hibernate_sequence Hibernate: update hibernate_sequence set next_val= ? where next_val=? Hibernate: insert into Docent (naam, docentnummer) values (?, ?) SQLite browser:\n   Waar is onze docent_nr data? De methode geefLesAan voegt enkel toe aan de studentenlijst, maar de relatie moet voor beide entities kloppen:\nfun geefLesAan(student: Student) { studenten.add(student) student.docent = this } public void geefLesAan(Student student) { studenten.add(student); student.setDocent(this); }  Zonder de tweede regel wordt de kolom niet ingevuld. Geeft nu:\nHibernate: select next_val as id_val from hibernate_sequence Hibernate: update hibernate_sequence set next_val= ? where next_val=? Hibernate: insert into Docent (naam, docentnummer) values (?, ?) Hibernate: update Student set docent_nr=?, goedBezig=?, naam=?, voornaam=? where studnr=? Bingo, een UPDATE statement in de studententabel. SQLite Browser:\n   2.3.1 Oefeningen  Implementeer de Docent klasse zoals hierboven.  Wat gebeurt er als je studenten opvraagt? Wat gebeurt er als je een docent van een student opvraagt? De FetchType.LAZY schiet in gang. Verander dit naar EAGER. Kijk in de Hibernate output wat er verandert op SQL niveau en verifiëer dat er nu een LEFT OUTER JOIN in de SELECT van de student staat.    Pas op het moment dat de data van de docent effectief nodig is, zoals bij het afdrukken, wordt een SELECT query gelanceerd bij lazy-loading. Bijvoorbeeld:\nval student = entityManager.find(Student::class.java, jos.studentennummer) println(\u0026#34;student ${student.naam}\u0026#34;); println(\u0026#34; -- heeft als docent ${student.docent.naam}\u0026#34;) var student = entityManager.find(Student.class, jos.getStudentenNummer()); System.out.println(\u0026#34;student \u0026#34; + student.getNaam()); System.out.println(\u0026#34; -- heeft als docent \u0026#34; + student.getDocent().getNaam());  Geeft als sysout output:\nHibernate: select student0_.studnr as studnr1_1_0_, student0_.docent_nr as docent_n5_1_0_, student0_.goedBezig as goedbezi2_1_0_, student0_.naam as naam3_1_0_, student0_.voornaam as voornaam4_1_0_ from Student student0_ where student0_.studnr=? student Lowiemans Hibernate: select docent0_.docentnummer as docentnu1_0_0_, docent0_.naam as naam2_0_0_ from Docent docent0_ where docent0_.docentnummer=? -- heeft als docent Wouter Merk op dat de eerste System.out.println vóór de docenten SELECT query komt. Een eager-loaded docent geeft andere output:\nHibernate: select student0_.studnr as studnr1_1_0_, student0_.docent_nr as docent_n5_1_0_, student0_.goedBezig as goedbezi2_1_0_, student0_.naam as naam3_1_0_, student0_.voornaam as voornaam4_1_0_, docent1_.docentnummer as docentnu1_0_1_, docent1_.naam as naam2_0_1_ from Student student0_ left outer join Docent docent1_ on student0_.docent_nr=docent1_.docentnummer where student0_.studnr=? student Lowiemans -- heeft als docent Wouter Tip: entityManager.clear() of close() een nieuwe aanmaken kan helpen om de persistence context te flushen ter test.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/transacties/",
	"title": "3. RDBMS Transacties",
	"tags": [],
	"description": "",
	"content": "Transaction management Zie menu links.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/xml/xpath/",
	"title": "3. XPath",
	"tags": [],
	"description": "",
	"content": "XPath XPath is een taal die we gebruiken om specifieke elementen of attributen te vinden in een XML bestand. Zoals je in de voorbije oefeningen al hebt gemerkt zijn XML bestanden nogal groot en niet zo makkelijk in een oogopslag om alle informatie uit te halen.\nLaten we ons voorbeeldbestand nemen:\n\u0026lt;boeken\u0026gt; \u0026lt;boek genre=\u0026#34;Non-Fiction\u0026#34;\u0026gt; \u0026lt;titel\u0026gt;Mythos\u0026lt;/titel\u0026gt; \u0026lt;auteur\u0026gt;Stephen Fry\u0026lt;/auteur\u0026gt; \u0026lt;jaar\u0026gt;2017\u0026lt;/jaar\u0026gt; \u0026lt;/boek\u0026gt; \u0026lt;boek genre=\u0026#34;biography\u0026#34;\u0026gt; \u0026lt;titel\u0026gt;Scar Tissue\u0026lt;/titel\u0026gt; \u0026lt;auteur\u0026gt;Anthony Kiedis\u0026lt;/auteur\u0026gt; \u0026lt;jaar\u0026gt;2004\u0026lt;/jaar\u0026gt; \u0026lt;/boek\u0026gt; \u0026lt;boek genre=\u0026#34;fantasy\u0026#34;\u0026gt; \u0026lt;titel\u0026gt;The Lost Metal\u0026lt;/titel\u0026gt; \u0026lt;auteur\u0026gt;Brandon Sanderson\u0026lt;/auteur\u0026gt; \u0026lt;jaar\u0026gt;2022\u0026lt;/jaar\u0026gt; \u0026lt;/boek\u0026gt; \u0026lt;/boeken\u0026gt; XPath voorbeelden /\nDit selecteert het meest top level object. In de praktijk geeft dit dus het hele document terug.\n/boeken\nDit zou het boeken element teruggeven. Wat dus ook het hele bestand is.\n/boeken/boek/titel\nGeef alle titels die vallen in de hiërarchie boeken -\u0026gt; boek.\n//titel\nGeef alle titels, eender waar in het document.\n//boek/@genre\nGeef alle genre attributen die gekoppeld zijn aan een boek element.\n//boek[@genre='fantasy']\nGeef alle boek elementen terug die in het genre fantasy vallen.\n//boek/*\nGeef alle subelementen van het boek element.\nOefeningen Hieronder vind je een xml bestand waarop we de XPath oefeningen gaan uitvoeren. Je kan je XPath valideren op deze online XPath evaluator.\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;catalog\u0026gt; \u0026lt;book id=\u0026#34;bk101\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Gambardella, Matthew\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;XML Developer\u0026#39;s Guide\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Computer\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;XML\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;44.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-10-01\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;An in-depth look at creating applications with XML.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk102\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Ralls, Kim\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Midnight Rain\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Fantasy\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;Low Fantasy\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;5.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-12-16\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;A former architect battles corporate zombies, an evil sorceress, and her own childhood to become queen of the world.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk103\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Corets, Eva\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Maeve Ascendant\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Fantasy\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;Dystopian Fantasy\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;5.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-11-17\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;After the collapse of a nanotechnology society in England, the young survivors lay the foundation for a new society.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk104\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Corets, Eva\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Oberon\u0026#39;s Legacy\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Fantasy\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;Dystopian Fantasy\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;5.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2001-03-10\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;In post-apocalypse England, the mysterious agent known only as Oberon helps to create a new life for the inhabitants of London. Sequel to Maeve Ascendant.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk105\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Corets, Eva\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;The Sundered Grail\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Fantasy\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;Dystopian Fantasy\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;5.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2001-09-10\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;The two daughters of Maeve, half-sisters, battle one another for control of England. Sequel to Oberon\u0026#39;s Legacy.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk106\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Randall, Cynthia\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Lover Birds\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Romance\u0026lt;/maingenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;4.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-09-02\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;When Carla meets Paul at an ornithology conference, tempers fly as feathers get ruffled.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk107\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Thurman, Paula\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Splish Splash\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Romance\u0026lt;/maingenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;4.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-11-02\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;A deep sea diver finds true love twenty thousand leagues beneath the sea.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk108\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Knorr, Stefan\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Creepy Crawlies\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Horror\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;Short Stories\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;4.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-12-06\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;An anthology of horror stories about roaches, centipedes, scorpions and other insects.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk109\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Kress, Peter\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Paradox Lost\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Science Fiction\u0026lt;/maingenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;6.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-11-02\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;After an inadvertant trip through a Heisenberg Uncertainty Device, James Salway discovers the problems of being quantum.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk110\u0026#34;\u0026gt; \u0026lt;author\u0026gt;O\u0026#39;Brien, Tim\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Microsoft .NET: The Programming Bible\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Computer\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;.NET\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;36.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-12-09\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;Microsoft\u0026#39;s .NET initiative is explored in detail in this deep programmer\u0026#39;s reference.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk111\u0026#34;\u0026gt; \u0026lt;author\u0026gt;O\u0026#39;Brien, Tim\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;MSXML3: A Comprehensive Guide\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Computer\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;XML\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;36.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-12-01\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;The Microsoft MSXML3 parser is covered in detail, with attention to XML DOM interfaces, XSLT processing, SAX and more.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;bk112\u0026#34;\u0026gt; \u0026lt;author\u0026gt;Galos, Mike\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Visual Studio 7: A Comprehensive Guide\u0026lt;/title\u0026gt; \u0026lt;genre fiction=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;maingenre\u0026gt;Computer\u0026lt;/maingenre\u0026gt; \u0026lt;subgenre\u0026gt;Visual Studio\u0026lt;/subgenre\u0026gt; \u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;49.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2001-04-16\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;Microsoft Visual Studio 7 is explored in depth, looking at how Visual Basic, Visual C++, C#, and ASP+ are integrated into a comprehensive development environment.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;/catalog\u0026gt;  Geef alle prijzen weer. Schrijf hiervoor 2 verschillende XPath queries die hetzelfde resultaat geven. Geef de titel van het boek met id bk110. Geef de description van alle boeken. Geef alle non-fictie boeken Lijst alle subgenres van de fictie boeken op.  "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/nosql/mapreduce/",
	"title": "4. Advanced map-red. queries",
	"tags": [],
	"description": "",
	"content": "Deze oefeningen gaan verder op de database die je hebt opgezet in het stuk over document stores. Herinstalleer indien nodig en download de benodigde gegevens via de instructies (2.2 Oefeningen: voorbereidingswerk) in die link. Start voor onderstaande oefeningen de lokale CouchDB Server en de Admin Console (Project Fauxton) opnieuw op.\nZoals ook op de PouchDB docs vermeld staat; zijn mapreduce queries niet altijd nodig:\n Documenten op _id raadplegen gaat door middel van de Curl REST API Documenten sorteren of simpele queries uitvoeren gaat door middel van de Mango API, zoals reeds gezien. Dit zijn simpele queries, maar die volstaan meestal. Indien de DB store \u0026lt; 100.000 records bevat, zoals de onze, kan je ook simpelweg alles in-memory inladen (bijvoorbeeld in de browser), en met javascript zelf verder filteren:  const db = pouchdb.get(); // zoiets // ... const skillsOfBigCourses = db.filter(doc =\u0026gt; { return doc.ECTS \u0026gt; 6 }).map(doc =\u0026gt; { return skills }) // gebruik dit in een template HTML factory Emit Een mapreduce query is in PouchDB uitvoerbaar met db.query() en in CouchDB deel van de _view API. Klik dus op het plusje + bij All Documents en dan op \u0026ldquo;new view\u0026rdquo;:\n   Daar kan je een nieuwe \u0026ldquo;map\u0026rdquo; functie aanmaken:\nfunction (doc) { emit(doc._id, 1); } Merk op dat hier de JavaScript syntax geldt. emit() betekent \u0026ldquo;geef als key deze waarde terug voor elk gevonden document\u0026rdquo;. Als je dit verandert naar doc.title wordt er een view aangemaakt die documenten op titel bewaart, om daar zeer snel in te kunnen zoeken. Bovenstaande functie wordt uitgevoerd voor elk document, vandaar de \u0026ldquo;map\u0026rdquo; in de naam. Het zou kunnen dat je filtert, vandaar de \u0026ldquo;reduce\u0026rdquo; in de naam.\nIk kan dus gewoon if() gebruiken, en zo documenten filteren. Alle cursussen gegeven in het tweede jaar of later:\nfunction (doc) { if(doc.year \u0026gt; 1) { emit(doc.title, 1); } } Aggregeren Stel dat ik de totale ECTS punten wil verzamelen van alle Belgische vakken in de database. Dus: eerst filteren op country property, en daarna de som nemen van alle ECTS properties. Hoe doe je zoiets in SQL? Met SUM() en GROUP BY:\nSELECT SUM(ECTS) FROM courses WHERE country = \u0026#34;Belgium\u0026#34; GROUP BY country Hoe doe je zoiets in NoSQL/Mongo/CouchDB? Met Reduce Functions. Je kan in Fauxton bij het bewerken van je view een CUSTOM waarde in de Reduce combobox selecteren:\n   Wat is die derde rereduce parameter? Volgens de docs:\n Reduce functions take two required arguments of keys and values lists - the result of the related map function - and an optional third value which indicates if rereduce mode is active or not. Rereduce is used for additional reduce values list, so when it is true there is no information about related keys (first argument is null).\n Rereducen wordt typisch uitgevoerd bij een cluster met verschillende CouchDB Nodes die de data verdeelt. CouchDB ontvangt groepen van inputs in plaats van alles in één vanwege performantie optimalisatie. Dit systeem is visueel uitgelegd in deze primer, maar is voor ons niet van toepassing.\nDus, map functie om te filteren op België:\nfunction (doc) { if(doc.country == \u0026#34;Belgium\u0026#34;) { emit(doc._id, doc.ECTS); } } Door ECTS in emit() mee te geven (als VALUE!) kunnen we in de reduce functie de array values manipuleren. En de reduce functie om de ECTS punten op te tellen:\nfunction (keys, values, rereduce) { return sum(values); } sum() is een ingebouwde CouchDB functie. Dit kan ook manueel op de functionele JS reduce() manier:\nfunction (keys, values, rereduce) { return values.reduce((a, b) =\u0026gt; a + b); } Klik op \u0026ldquo;Run Query\u0026rdquo;. De resultaten zijn de resultaten van de MAP - de Reduce value moet je expliciet enablen door vanboven rechts op \u0026ldquo;Options\u0026rdquo; te klikken, en dan \u0026ldquo;Reduce\u0026rdquo; aan te vinken:\n   Merk op dat je met \u0026ldquo;Group Level\u0026rdquo; moet spelen (Op None zetten) om de groepering te doen werken, anders gaat de reduce functie de som nemen op elk indiviudeel document, wat uiteraard geen correct som is.\nMerk op dat reduce functies verschillende keren kunnen worden opgeroepen - en dat reduce reeds kan beginnen voordat map klaar is met zijn werk. Deze maatregelen zijn genomen om vlot om te kunnen gaan met miljarden records, verticaal verspreid over verschillende clusters.\nOefeningen  Maak een nieuwe view die documenten teruggeeft die in de titel het woord \u0026ldquo;project\u0026rdquo; bevatten. Werk case-insensistive. Vergeet niet dat het zou kunnen dat sommige documenten géén title property hebben, of deze null is. Wat dan? Schrijf een reduce query die voor alle bovenstaande titels het aantal cursussen weergeeft (enkel het aantal is voldoende) dat explicit op true heeft staan. Schrijf een view die de som neemt van alle ECTS punten van alle cursussen. Doe dit op drie manieren:  Met de ingebouwde _sum functie. Met een custom reduce en sum() zoals hierboven in het voorbeeld Met een custom reduce die values.reduce() gebruikt: zie docs Array.prototype.reduce(). Wat is volgens jou het fundamentele verschil tussen deze 3 opties? Op welk gebied?   Kopieer je LightCouch oefening van Document stores als een nieuw Java project. Programmeer nu in Java om de view die je hebt gemaakt in oefening 2 op te roepen met dbClient.view(). Zie LightCouch docs. Schrijf een view die het aantal optionele cursussen weergeeft waarvan \u0026ldquo;motivate others\u0026rdquo; een skill is.  Denkvragen  Waarom is het niet mogelijk in NoSQL databases om een simpele query uit te voeren die bijvoorbeeld auteurs opvraagt ouder dan een bepaalde leeftijd, en dan alle titels per auteur teruggeeft? (Hint: p. 321) Wat is het verschil tussen emit(doc._id, 1) en emit(doc._id, doc.year)? Wat is het verschil tussen map(), reduce() en filter() in Javascript? Hint: Zie Mozilla MDN Web Docs.  "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/transacties/concurrency-in-practice/",
	"title": "4. Concurrency in de Praktijk",
	"tags": [],
	"description": "",
	"content": "Meerdere threads met toegang tot de DB Quickstart project: examples/concurrency in de cursus repository (download repo zip). Het bevat een JDBC implementatie van de gekende studenten opgave, inclusief een Runnable thread worker die INSERT, UPDATE of DELETE statements issuen naar de database. Het probleem wat we hier proberen te simuleren is DIRTY READS.\nBegeleidend filmpje:\n Oefeningen  Inspecteer de huidige code van het project en vergewis je ervan dat je alle stappen begrijpt. Voer het een aantal keer uit. Wat zie je in de Stdout? Waarom wordt de student wel of niet in de SELECT teruggegeven? Speel met de parameter van setAutoCommit() in de ConnectionManager. Zie je een verschil? Speel met de parameter van setTransactionIsolation() op de connection. Merk op dat SQLite enkel SERIALIZABLE en READ_UNCOMMITED ondersteund, maar het onmogelijk is om dirty reads te simuleren. Zie ook https://github.com/changemyminds/Transaction-Isolation-Level-Issue en de Oracle docs voor het verschil tussen bijvoorbeeld READ_UNCOMMITTED en READ_COMMITTED? Kan je uit de context opmaken wat een \u0026ldquo;dirty read\u0026rdquo; is? Probeer naast een dirty read ook een PHANTOM READ te simuleren met de H2 setup van bovenstaand project. Maak in een for {} loop tientallen verschillende threads aan en laat ze verschillende acties op de DB uitvoeren (lezen, schrijven, updaten, \u0026hellip;). Loopt er iets mis? Wat kan je programmatorisch doen om de chaos tot het minimum te beperken?  Om concurrency problemen makkelijk te kunnen demonstreren gebruiken we géén SQLite vanwege SQLite\u0026rsquo;s shared cache mode. Let dus op je SQL syntax en connection string. Kleine verschillen kunnen SQL Exceptions veroorzaken bij andere database implementaties.  De H2 implementatie wordt ook gebruikt bij de SESsy library\u0026mdash;zie database APIs - extras.\n Connection Pooling Uit de code blijkt dat alle threads momenteel éénzelfde connection instance delen via de StudentRepository implementatie. In de praktijk wordt er voor client/server applicaties altijd connection pooling toegepast: een aantal connections zijn beschikbaar in een pool, waar de clients uit kunnen kiezen. Als er een beschikbaar is, kan deze verder gaan. Als dat niet zo is, moet die bepaalde request wachten, tot een andere klaar is met zijn database acties en de connection terug vrijgeeft, opnieuw in de pool. Op die manier kan je bijvoorbeeld 6 connections verdelen over 10+ client threads, zoals in deze figuur (bron: oracle docs):\n  Bron: oracle docs  Voor embedded single-file databases als SQLite is dit niet de gewoonte. Hibernate (zie 3. Database APIs) voorziet verschillende properties om connection pooling in te stellen, zoals aantal connections, aantal threads die kunnen requesten, timeout request, enzovoort. We gaan hier verder niet op in.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/apis/",
	"title": "4. Database APIs",
	"tags": [],
	"description": "",
	"content": "Database APIs Zie menu links.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/apis/extra-oefeningen/",
	"title": "4. Extra Oefeningen",
	"tags": [],
	"description": "",
	"content": "SESsy Library - Revisited Voorbereiding: Maak uzelf opnieuw vertrouwd met de SESsy Library applicatie, de geïntegreerde oefening uit het tweedejaarsvak Software Engineering Skills.\n   Het is interessant om de libraries die de app gebruikt eens in detail te inspecteren. Dat kan met gradlew dependencies. In context van het vak Databasess zien we dat de webapp gebouwd is met de volgende relevante tools en libraries:\n Als database endpoint wordt com.h2database.h2 gebruikt. De Dropwizard jdbi3 dependency verwijst op zijn beurt naar een variant van jdbc De sqlobject plugin van Jdbi3 wordt gebruikt.  Zoals een snippet van de dependency tree aangeeft:\n... +--- io.dropwizard:dropwizard-jdbi3:2.0.0-rc12 | +--- io.dropwizard:dropwizard-db:2.0.0-rc12 | | +--- io.dropwizard:dropwizard-core:2.0.0-rc12 (*) | | \\--- org.apache.tomcat:tomcat-jdbc:9.0.27 | | \\--- org.apache.tomcat:tomcat-juli:9.0.27 ... Oefeningen  Inspecteer de H2 Database Engine documentatie. Wat is het verschil tussen H2 en MySQL? En wat zijn de gelijkenissen tussen H2 en SQLite dat elders in deze cursus wordt gebruikt? Zoek in de SEssy code waar de Jdbi3 sqlobject annotaties worden gebruikt. Dit is dus de Jdbi Declarative API (zie docs). Wat zou je moeten doen om dit te refactoren naar de Fluent API? Voer de veranderingen door voor de methode findBooksByTitle(). Worden ergens transacties gebruikt? Wordt er ergens in de code bewaakt tegen concurrency? Indien niet, bouw dit in voor het uitlenen van boeken in de methode borrow(). Moet transactie beheer op niveau van Resource klasses staan, of behoort het volgens jou toe aan de Repository klasses? Welke code heb je specifiek nodig om in Jdbi3 transacties te hanteren? Stel dat ik in een nieuwe repository klasse een low-level SQL statement zelf wil schrijven en uitvoeren, rechtstreeks naar de database, in plaats van via Jdbi3. Hoe kan ik dat doen? Probeer dit zelf in de code door iets met de books tabel te doen (bijvoorbeeld een COUNT). Is er een manier om de queries die Jdbi3 uitvoert in H2 ook af te drukken, zoals Hibernate\u0026rsquo;s show_sql config flag? We zijn niet meer tevreden over de performantie en het gebruiksgemak van H2. We wensen in de plaats daarvan JPA + Hibernate te gebruiken. Voer de nodige veranderingen door. Test de applicatie ook uitvoerig door de webserver op te starten! De integratie testen die falen mag je negeren, dat valt buiten deze cursus om die ook te converteren. Denk eerst goed na over welke wijzigingen allemaal moeten gebeuren:  Welke config file wordt nu gebruikt om de database file/connectionstring op te geven? Hoe kan je dat vervangen door persistence.xml? Kan je interfaces, strategies, of facades gebruiken om eerst de H2 implementatie te verbergen, en dan te refactoren, of is dat niet meer nodig? Is er een manier in Dropwizard om eenvoudiger Hibernate session factories aan te maken? (ja dus!) \u0026hellip;    "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/nosql/",
	"title": "5. NoSQL",
	"tags": [],
	"description": "",
	"content": "NoSQL Databases Zie menu links.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/nosql/replication/",
	"title": "5. Replication",
	"tags": [],
	"description": "",
	"content": "   Met replication is het eenvoudig om clusters van clones te maken om de 99.9% uptime te kunnen garanderen, gegeven de juiste loadbalancing instellingen. Als voorbeeld gaan we een open-source JavaScript DB gebruiken genaamd PouchDB. PouchDB draait goed client-side in de browser, en interfacet heel gemakkelijk met zijn inspirator, CouchDB. Met Pouch is het een kwestie van een paar regeltjes code om replication aan te zetten tussen Pouch en de \u0026ldquo;master\u0026rdquo; Couch database, zoals ook zichtbaar op de Pouch website:\nvar db = new PouchDB(\u0026#39;dbname\u0026#39;); db.put({ _id: \u0026#39;dave@gmail.com\u0026#39;, name: \u0026#39;David\u0026#39;, age: 69 }); db.changes().on(\u0026#39;change\u0026#39;, function() { console.log(\u0026#39;Ch-Ch-Changes\u0026#39;); }); db.replicate.to(\u0026#39;http://example.com/mydb\u0026#39;); Replication opzetten Wat is het doel? Replication op te zetten tussen de cursussen database van 2. document stores en de PouchDB JS web-based client. Dat kan op verschillende manieren:\n Unidirectional replication\u0026mdash;1-way traffic master/slave. Eén database is de \u0026ldquo;master\u0026rdquo; waar men op werkt, en de andere is een mirror/backup. Bidirectional replication\u0026mdash;2-way traffic. Data die in beide databases verandert, wordt gesynchroniseerd naar beiden databases. Uiteraard zul je hier aan conflict management moeten doen. Live/Continuous replication\u0026mdash;2-way \u0026ldquo;live\u0026rdquo; traffic dat onmiddellijk zichtbaar is via JS callbacks.    Offline replication schematisch voorgesteld. src: pouchdb.com  Zie ook de PouchDB Docs: replication explained. Merk op dat de drie bovenstaande replication principes ook van toepassing zijn voor CouchDB. Om replication te demonstreren hebben we uiteraard een 2de database nodig, vandaar de introductie van PouchDB.\nInterne werking Hoe werkt replication intern? Elk document heeft een _rev property:\n   Elke change aan elk document wordt bijgehouden. In bovenstaande screenshot zie je als eerste document een _rev value van 3-82ac8d.... Dit is revisie 3. Je kan deze lijst van revisies van één bepaald document ook raadplegen via een REST: zie de documentatie, GET list of revisions.\nEen document ophalen in CouchDB kan via http://127.0.0.1:5984/[db]/[key]. Voeg aan deze url ?revs=true of ?revs_info=true toe en kijk wat er gebeurt.\nDemo JS code Je kan bovenstaande demo code onmiddellijk proberen op https://pouchdb.com: Druk op F12 of CTRL+SHIFT+J (Mac: OPT+CMD+J) of ga naar menu Developer -\u0026gt; Developer Tools van je favoriete browser. In de tab \u0026ldquo;Console\u0026rdquo; wordt je begroet door de PouchDB welkomsttekst. Daar kan je je test commando\u0026rsquo;s in uitvoeren: var db = .... Om te controleren of het record het tot in de database heeft gehaald, zie hieronder, bij tips.\nGebruik in de oefeningen de CDN versie om het jezelf gemakkelijk te maken. Maak een leeg .html bestand aan en kopieer de Quick Start code over:\n\u0026lt;script src=\u0026#34;//cdn.jsdelivr.net/npm/pouchdb@7.2.1/dist/pouchdb.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; var db = new PouchDB(\u0026#39;my_database\u0026#39;); \u0026lt;/script\u0026gt; Vergeet niet dat je lokale CouchDB waarschijnlijk draait op poort 5984.\nPouchDB, CouchDB, help, wat is het verschil? Pouch is een JavaScript client library voor Node en het Web. Beiden gebruiken Mango, MapReduce Replication, \u0026hellip; technieken. Beiden kan je clusteren, hebben conflict management, compacting, \u0026hellip; Bekijk het zo: Pouch is de (easy-to-setup) Couch van het web. Zie ook: Who\u0026rsquo;s using PouchDB?\n Een uitgewerkt voorbeeld in begeleidende video:\n Oefeningen  Start CouchDB opnieuw met de bestaande courses db. Stel PouchDB in op unidirectionele replication. Alle LOKALE wijzigingen worden nu bewaard in de remote DB. Schrijf in Javascript ter test een nieuw fictief document weg met db.put(). Vul alle JSON properties in: kijk naar een bestaand document in je Couch database. Maak een nieuw .html bestand aan, en stel een remote URL in om vanuit JS onmiddellijk op de remote DB te kunnen queryen.  Gebruik de Mango query API van Pouch om in CouchDB de oefeningen van 2. document stores te implementeren. Opgelet: hier moet je een extra JS file voor includen, pouchdb.find.js, zoals aangegeven in de link, downloadbaar hier en zorg ervoor dat zowel PouchDB als de find versies van dezelfde release komen! Gebruik de Mapreduce query API van Pouch om in CouchDB de oefeningen van 3. advanced map/red. queries te implementeren. Merk op dat voor map en reduce beiden uit te voeren, je een JSON object moet meegeven met beide functies: { map: function(doc) { emit(...); }, reduce: '_count}. Zie docs in link.   Maak een nieuw .html bestand aan, en stel continuous replication in. Voeg dan een nieuw document toe in de CouchDB Admin console. Maak in HTML een knop die gewoon records afdrukt via console.log(). Wordt het nieuwe document getoond? Gebruik deze boilerplate:  \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/pouchdb@7.2.1/dist/pouchdb.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;button id=\u0026#34;btn\u0026#34;\u0026gt;Print docs\u0026lt;/button\u0026gt; \u0026lt;pre id=\u0026#34;pre\u0026#34;\u0026gt; ... \u0026lt;/pre\u0026gt; \u0026lt;script\u0026gt; function print(doc) { document.querySelector(\u0026#39;#pre\u0026#39;).innerHTML = JSON.stringify(doc); } var db = new PouchDB(\u0026#39;my_database\u0026#39;); // do your setup here  function queryDocs() { // do your thing here  print(\u0026#39;goed bezig\u0026#39;); } document.querySelector(\u0026#34;#btn\u0026#34;).addEventListener(\u0026#34;click\u0026#34;, queryDocs); \u0026lt;/script\u0026gt; Tips: Wanneer je een item hebt toegevoegd aan je lokale JavaScript database met .put(), maar replication nog niet aan staat, kan het handig zijn om met Chrome/Opera/\u0026hellip; Dev Tools te kijken naar de local storage databases. Deze zijn terug te vinden in de tab \u0026ldquo;Application\u0026rdquo;, bij \u0026ldquo;IndexedDB\u0026rdquo;:\n   De volgende elementen zijn te herkennen in bovenstaande screenshot:\n Ik heb een \u0026ldquo;mydb\u0026rdquo; object aangemaakt (DB naam _pouch_mydb) Onder element \u0026ldquo;by-sequence\u0026rdquo; kan je de huidige elementen in de DB raadplegen, zoals bovenstaande demo code waarbij object met naam \u0026ldquo;David\u0026rdquo; werd toegevoegd.  Troubleshooting Cross site origin fouten? - Het kan zijn dat je browser, zoals een strict ingestelde Firefox, klaagt over Cross-Origin domains wanneer replication aan staat, omdat die naar 127.0.0.1 gaat, en je browser de .html file aanlevert vanuit file:/// wat technisch gezien niet dezelfde hostname is. Ga naar je CouchDB admin config (klik op tandwieltje), op CORS, en klik \u0026ldquo;enable\u0026rdquo; (all domains). Oplossing 1: gebruik een andere browser. Oplossing 2: disable CORS in de browser (zie artiel). Optie 3: gebruik een python3 webserver om je bestand te serven. Open een terminal en typ python -m http.server in de directory van je html bestand. Ga dan naar http://127.0.0.1:8000/oefening.html (Poort 8000). Indien niet opgelost, ga naar volgende troubleshooting puntje:\nConnecton errors? - Als Pouch bij replication connection errors geeft in de JS Console kan het zijn dat je Couch server te streng staat ingesteld, en hij de requests blokkeert. In dat geval ga je naar Fauxton, klik je op het \u0026ldquo;tandwieltje\u0026rdquo; linkqs, en enable je CORS (Cross Origin Requests):\n   Access denied? - Als je een admin username/password hebt ingesteld dien je dit ook mee te geven met de parameters: new PouchDb(\u0026quot;http://localhost:5984\u0026quot;, { auth: { username: \u0026quot;jef\u0026quot;, password: \u0026quot;lowie\u0026quot;} }). Zie options for remote databases in de PouchDb API manual.\nMijn find() doet niks? - Merk op dat eender welke actie een Promise object teruggeeft. Dat wil zeggen dat de query \u0026ldquo;onderweg\u0026rdquo; is, en als je iets wilt uitvoeren wanneer dit klaar is (een asynchroon proces), moet dit via de Promise API, zoals .then(). Lees hierover in de Mozilla MDN docs.\nIk krijg rare javascript errors? - Is je pouch.min.js en pouch.find.min.js versie dezelfde? D.w.z. zijn de major/minor/revision nummers hetzelfde? Dit staat aangeduid in de eerste regel van de source file. Indien niet, download de correcte versie via de PouchDB Github Releases pagina.\nIk krijg 404 object not found bij put? - Heb je je remote DB opgezet naar een onbestaande database, zoals /hallokes? Die moet je eerst zelf aanmaken in de CouchDB admin pagina! Anders kan je geen PUT commando\u0026rsquo;s op die URL opsturen.\nUncaught in Promise request PUT not supported? - In serviceWorker.js? Ben je op de pouchdb.com website in de console dingen aan het testen? Sommige scripts, zoals deze, vangen PUT commando\u0026rsquo;s op en crashen dan. Je object zal wel correct zijn bewaard, dit mag je negeren.\nDenkvragen  Heb je een verschil gemerkt tussen bidirectionele en live replication in PouchDB? Probeer beide instellingen uit en kijk in de Chrome/Opera/Mozilla Dev Tools van je browser naar de uitgaande HTTP requests. Op welk moment gebeurt dit? Welke POST/GET metadata wordt verstuurd? Wat is het verschil tussen in Pouch alle documenten op te vragen en daarna als array MapReduces toe te passen, of dit in de Mango query rechtstreeks te doen?  "
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/xml/",
	"title": "6. XML Data Storage",
	"tags": [],
	"description": "",
	"content": "XML Zie menu links.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/bigdata/",
	"title": "7. Big Data &amp; Analytics",
	"tags": [],
	"description": "",
	"content": "Big Data \u0026amp; Analytics Zie menu links.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/extra/software/",
	"title": "Gebruikte Software",
	"tags": [],
	"description": "",
	"content": "SQL SQL-gebaseerde oefeningen nemen plaats in de SQLite DB Browser omgeving, een visuele open source tool om eenvoudig database files te maken en bewerken die compatibel zijn met SQLite, een SQL variant.\nVanuit SQLiteBrowser kan je een nieuwe database aanmaken, een bestaande .SQL file openen en uitvoeren, of een bestaande .db SQLite database openen.\nVoor het hoofdstuk SQL DDL \u0026amp; DML gebruiken we het chinook.db bestand dat je hier kan downloaden: chinook.db.\nJava/Kotlin/Gradle Zie het 2dejaarsvak Software Engineering Skills, SES/Gebruikte software. Voor SQL API software development oefeningen gebruiken we dezelfde tools: dezelfde Java JDK, optioneel een Kotlin SDK, ook de IntelliJ IDE, en ook Gradle als build tool. Weet je niet meer hoe deze te gebruiken, volg dan de links om je geheugen te verfrissen.\nTijdens labo\u0026rsquo;s gebruiken we vaak Gradle dependencies om te experimenteren met nieuwe soorten databases zoals Memcached, SQLite, JDBI en Hibernate. Deze hoef je niet apart te downloaden en worden beheerd door de dependency manager.\nWe verwachten nog steeds dat je vlot kan werken met git\u0026mdash;als dit niet (meer) het geval is, zie de SES/versiebeheer labo noties. Alle voorbeeldoefeningen zitten in de \u0026ldquo;Course Git Repository\u0026rdquo; pagina (zie menu links, onder \u0026ldquo;More\u0026rdquo;).\nNoSQL CouchDB Installeer CouchDB 3.2.2 op je eigen systeem via https://couchdb.apache.org/#download.\nPouchDB Download de vereiste JavaScript files lokaal via https://pouchdb.com/download.html of gebruik gewoon de quick-start jsdeliver.net source:\n\u0026lt;script src=\u0026#34;//cdn.jsdelivr.net/npm/pouchdb@7.3.0/dist/pouchdb.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; Zie de PouchDB oefeningen labo noties.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/",
	"title": "Index",
	"tags": [],
	"description": "",
	"content": " Databases  Laatste aanpassingen voor academiejaar 2023\u0026mdash;2024.\n Planning    nr datum onderwerp     01 vr 22-09-2023 RDBMS \u0026amp; SQL: Basics, DB Componenten   02 vr 29-09-2023 ACID \u0026amp; SQL Deel 1   03 vr 06-10-2023 SQL deel 2   04 vr 13-10-2023 RDBMS transacties: basics, concurrency control   05 vr 20-10-2023 DB APIs: basics, JDBC, JDBI   06 vr 27-10-2023 DB APIs: JPA \u0026amp; Hibernate   07 vr 10-11-2023 Re Transacties: rollbacks, concurrency in practice   08 vr 14-11-2023 NoSQL 1: intro HC, key/value en document stores   09 vr 24-11-2023 NoSQL 2: advanced concepts, case studies (1)   10 vr 01-12-2023 NoSQL 3: map/reduce, replication, graph stores, case studies (2)   11 vr 13-12-2023 XML Data Storage, Big Data \u0026amp; Analytics    Cursus noties Er worden telkens blokken van 3 uur ingepland voor dit vak. Er zijn geen traditionele hoorcolleges voorzien. Alle noties zijn via deze website te raadplegen:\nInhoudsopgave  SQL:  Database Basics DB Componenten Transacties I: ACID SQL: DDL SQL: DML   SQL DB APIs:  API Basics \u0026amp; layered tiers JDBC en JDBI JPA en Hibernate Extra oefeningen   Transacties:  Transacties II: Management Basics Concurrency control Failures/Rollbacks Transacties III: in de praktijk   NoSQL:  NoSQL Basics Key/Value stores Document stores Advanced map/reduce queries Replication   XML \u0026amp; Big Data Storage  XML Basics XSD Schemas XPath Queries Big Data Basics Big Data: Warehousing \u0026amp; BI    Syllabus  Lesgevers:  Coördinerend Verantwoordelijke: prof. dr. Kris Aerts (kris.aerts@kuleuven.be) lesgever: dr. Wouter Groeneveld (wouter.groeneveld@kuleuven.be)   Kantoor: Technologiecentrum Diepenbeek, Groep ACRO, D.0.35.  Cursusbeschrijving Dit opleidingsonderdeel focust enerzijds op drie soorten databases:\n relationele databases de NoSQL-alternatieven XML databases  En anderzijds op twee toepassingen:\n programmeren van database-gestuurde applicaties via API\u0026rsquo;s een inleiding in Big Data  Vereiste voorkennis  Basiskennis van een Object-Geörienteerde programmeertaal als Java of C# Basiskennis van het UNIX systeem, werken met commandline  Doelstellingen Zie ook Studiegids UHasselt\nDe context en het overzicht worden aangereikt in de eerste lessen van dit vak.\nAls practicum wordt een grotere probleemstelling als project uitgewerkt. Alle aan te leren aspecten van databases komen in dit project aan bod. Studenten kunnen facultatief buiten het practicum extra thematische oefeningen oplossen.\nKalender Zie Mytimetable UHasselt.\n"
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://kuleuven-diepenbeek.github.io/db-course/extra/",
	"title": "X. Extras",
	"tags": [],
	"description": "",
	"content": "Extra informatie Zie menu links.\n"
}]